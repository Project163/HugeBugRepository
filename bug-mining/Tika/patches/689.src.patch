diff --git a/tika-app/src/main/java/org/apache/tika/cli/BatchCommandLineBuilder.java b/tika-app/src/main/java/org/apache/tika/cli/BatchCommandLineBuilder.java
index 5295bbdbc..0c1ac25ad 100644
--- a/tika-app/src/main/java/org/apache/tika/cli/BatchCommandLineBuilder.java
+++ b/tika-app/src/main/java/org/apache/tika/cli/BatchCommandLineBuilder.java
@@ -39,13 +39,13 @@ class BatchCommandLineBuilder {
     static Pattern JVM_OPTS_PATTERN = Pattern.compile("^(--?)J(.+)");
 
     protected static String[] build(String[] args) throws IOException {
-        Map<String, String> processArgs = new LinkedHashMap<String, String>();
-        Map<String, String> jvmOpts = new LinkedHashMap<String,String>();
-        //take the args, and divide them into process args and options for
-        //the child jvm process (i.e. log files, etc)
-        mapifyArgs(args, processArgs, jvmOpts);
-
-        //now modify processArgs in place
+        Map<String, String> processArgs = new LinkedHashMap<String, String>();
+        Map<String, String> jvmOpts = new LinkedHashMap<String,String>();
+        //take the args, and divide them into process args and options for
+        //the child jvm process (i.e. log files, etc)
+        mapifyArgs(args, processArgs, jvmOpts);
+
+        //now modify processArgs in place
         translateCommandLine(args, processArgs);
 
         //maybe the user specified a different classpath?!
@@ -56,23 +56,23 @@ class BatchCommandLineBuilder {
             if (cp.contains(" ")){
                 cp = "\""+cp+"\"";
             }
-            jvmOpts.put("-cp", cp);
-        }
-
-        boolean hasLog4j = false;
-        for (String k : jvmOpts.keySet()) {
-            if (k.startsWith("-Dlog4j.configuration=")) {
-                hasLog4j = true;
-                break;
-            }
-        }
-        //use the log4j config file inside the app /resources/log4j_batch_process.properties
-        if (! hasLog4j) {
-            jvmOpts.put("-Dlog4j.configuration=\"log4j_batch_process.properties\"", "");
-        }
-        //now build the full command line
-        List<String> fullCommand = new ArrayList<String>();
-        fullCommand.add("java");
+            jvmOpts.put("-cp", cp);
+        }
+
+        boolean hasLog4j = false;
+        for (String k : jvmOpts.keySet()) {
+            if (k.startsWith("-Dlog4j.configuration=")) {
+                hasLog4j = true;
+                break;
+            }
+        }
+        //use the log4j config file inside the app /resources/log4j_batch_process.properties
+        if (! hasLog4j) {
+            jvmOpts.put("-Dlog4j.configuration=\"log4j_batch_process.properties\"", "");
+        }
+        //now build the full command line
+        List<String> fullCommand = new ArrayList<String>();
+        fullCommand.add("java");
         for (Map.Entry<String, String> e : jvmOpts.entrySet()) {
             fullCommand.add(e.getKey());
             if (e.getValue().length() > 0) {
@@ -90,16 +90,16 @@ class BatchCommandLineBuilder {
         return fullCommand.toArray(new String[fullCommand.size()]);
     }
 
-
-    /**
-     * Take the input args and separate them into args that belong on the commandline
-     * and those that belong as jvm args for the child process.
-     * @param args -- literal args from TikaCLI commandline
-     * @param commandLine args that should be part of the batch commandline
-     * @param jvmArgs args that belong as jvm arguments for the child process
-     */
-    private static void mapifyArgs(final String[] args,
-                                   final Map<String, String> commandLine,
+
+    /**
+     * Take the input args and separate them into args that belong on the commandline
+     * and those that belong as jvm args for the child process.
+     * @param args -- literal args from TikaCLI commandline
+     * @param commandLine args that should be part of the batch commandline
+     * @param jvmArgs args that belong as jvm arguments for the child process
+     */
+    private static void mapifyArgs(final String[] args,
+                                   final Map<String, String> commandLine,
                                    final Map<String, String> jvmArgs) {
 
         if (args.length == 0) {
@@ -198,9 +198,9 @@ class BatchCommandLineBuilder {
         if (map.containsKey("--outputDir") || map.containsKey("-o")) {
             String v1 = map.remove("--outputDir");
             String v2 = map.remove("-o");
-            String v = (v1 == null) ? v2 : v1;
-            map.put("-outputDir", v);
-        }
-
-    }
-}
+            String v = (v1 == null) ? v2 : v1;
+            map.put("-outputDir", v);
+        }
+
+    }
+}
diff --git a/tika-app/src/main/resources/log4j.properties b/tika-app/src/main/resources/log4j.properties
index 1a7bbfd59..7d3b372cc 100644
--- a/tika-app/src/main/resources/log4j.properties
+++ b/tika-app/src/main/resources/log4j.properties
@@ -1,24 +1,24 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#info,debug, error,fatal ...
-log4j.rootLogger=info,stderr
-
-#console
-log4j.appender.stderr=org.apache.log4j.ConsoleAppender
-log4j.appender.stderr.layout=org.apache.log4j.PatternLayout
-log4j.appender.stderr.Target=System.err
-
-log4j.appender.stderr.layout.ConversionPattern= %-5p %m%n
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#info,debug, error,fatal ...
+log4j.rootLogger=info,stderr
+
+#console
+log4j.appender.stderr=org.apache.log4j.ConsoleAppender
+log4j.appender.stderr.layout=org.apache.log4j.PatternLayout
+log4j.appender.stderr.Target=System.err
+
+log4j.appender.stderr.layout.ConversionPattern= %-5p %m%n
diff --git a/tika-app/src/main/resources/log4j_batch_process.properties b/tika-app/src/main/resources/log4j_batch_process.properties
index 2a116c53b..9fc74fdce 100644
--- a/tika-app/src/main/resources/log4j_batch_process.properties
+++ b/tika-app/src/main/resources/log4j_batch_process.properties
@@ -1,24 +1,24 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#info,debug, error,fatal ...
-log4j.rootLogger=info,stdout
-
-#console
-log4j.appender.stdout=org.apache.log4j.ConsoleAppender
-log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
-
-
-log4j.appender.stdout.layout.ConversionPattern=%m%n
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#info,debug, error,fatal ...
+log4j.rootLogger=info,stdout
+
+#console
+log4j.appender.stdout=org.apache.log4j.ConsoleAppender
+log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
+
+
+log4j.appender.stdout.layout.ConversionPattern=%m%n
diff --git a/tika-app/src/test/java/org/apache/tika/cli/TikaCLIBatchIntegrationTest.java b/tika-app/src/test/java/org/apache/tika/cli/TikaCLIBatchIntegrationTest.java
index d42bc10cc..bf0efa29a 100644
--- a/tika-app/src/test/java/org/apache/tika/cli/TikaCLIBatchIntegrationTest.java
+++ b/tika-app/src/test/java/org/apache/tika/cli/TikaCLIBatchIntegrationTest.java
@@ -1,136 +1,136 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.cli;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.InputStreamReader;
-import java.io.OutputStream;
-import java.io.PrintStream;
-import java.io.Reader;
-import java.util.List;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.tika.io.IOUtils;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.metadata.serialization.JsonMetadataList;
-import org.apache.tika.parser.RecursiveParserWrapper;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.Test;
-
-public class TikaCLIBatchIntegrationTest {
-
-    private File testDataFile = new File("src/test/resources/test-data");
-
-    private File tempDir;
-    private OutputStream out = null;
-    private OutputStream err = null;
-    private ByteArrayOutputStream outBuffer = null;
-
-    @Before
-    public void setup() throws Exception {
-        tempDir = File.createTempFile("tika-cli-test-batch-", "");
-        tempDir.delete();
-        tempDir.mkdir();
-        outBuffer = new ByteArrayOutputStream();
-        PrintStream outWriter = new PrintStream(outBuffer, true, IOUtils.UTF_8.name());
-        ByteArrayOutputStream errBuffer = new ByteArrayOutputStream();
-        PrintStream errWriter = new PrintStream(errBuffer, true, IOUtils.UTF_8.name());
-        out = System.out;
-        err = System.err;
-        System.setOut(outWriter);
-        System.setErr(errWriter);
-    }
-
-    @After
-    public void tearDown() throws Exception {
-        System.setOut(new PrintStream(out, true, IOUtils.UTF_8.name()));
-        System.setErr(new PrintStream(err, true, IOUtils.UTF_8.name()));
-        FileUtils.deleteDirectory(tempDir);
-    }
-
-    @Test
-    public void testSimplestBatchIntegration() throws Exception {
-        String[] params = {escape(testDataFile.getAbsolutePath()),
-                escape(tempDir.getAbsolutePath())};
-        TikaCLI.main(params);
-
-        assertTrue("bad_xml.xml.xml", new File(tempDir, "bad_xml.xml.xml").isFile());
-        assertTrue("coffee.xls.xml", new File(tempDir, "coffee.xls.xml").exists());
-    }
-
-    @Test
-    public void testBasicBatchIntegration() throws Exception {
-        String[] params = {"-i", escape(testDataFile.getAbsolutePath()),
-                "-o", escape(tempDir.getAbsolutePath()),
-                "-numConsumers", "2"
-        };
-        TikaCLI.main(params);
-
-        assertTrue("bad_xml.xml.xml", new File(tempDir, "bad_xml.xml.xml").isFile());
-        assertTrue("coffee.xls.xml", new File(tempDir, "coffee.xls.xml").exists());
-    }
-
-    @Test
-    public void testJsonRecursiveBatchIntegration() throws Exception {
-        Reader reader = null;
-        try {
-            String[] params = {"-i", escape(testDataFile.getAbsolutePath()),
-                    "-o", escape(tempDir.getAbsolutePath()),
-                    "-numConsumers", "10",
-                    "-J", //recursive Json
-                    "-t" //plain text in content
-            };
-            TikaCLI.main(params);
-            reader = new InputStreamReader(
-                    new FileInputStream(new File(tempDir, "test_recursive_embedded.docx.json")), IOUtils.UTF_8);
-            List<Metadata> metadataList = JsonMetadataList.fromJson(reader);
-            assertEquals(12, metadataList.size());
-            assertTrue(metadataList.get(6).get(RecursiveParserWrapper.TIKA_CONTENT).contains("human events"));
-        } finally {
-            IOUtils.closeQuietly(reader);
-        }
-    }
-
-    @Test
-    public void testProcessLogFileConfig() throws Exception {
-        String[] params = {"-i", escape(testDataFile.getAbsolutePath()),
-                "-o", escape(tempDir.getAbsolutePath()),
-                "-numConsumers", "2",
-                "-JDlog4j.configuration=log4j_batch_process_test.properties"};
-        TikaCLI.main(params);
-
-        assertTrue("bad_xml.xml.xml", new File(tempDir, "bad_xml.xml.xml").isFile());
-        assertTrue("coffee.xls.xml", new File(tempDir, "coffee.xls.xml").exists());
-        String sysOutString = new String(outBuffer.toByteArray(), IOUtils.UTF_8);
-        assertTrue(sysOutString.contains("MY_CUSTOM_LOG_CONFIG"));
-    }
-
-    public static String escape(String path) {
-        if (path.indexOf(' ') > -1) {
-            return '"' + path + '"';
-        }
-        return path;
-    }
-
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.cli;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.InputStreamReader;
+import java.io.OutputStream;
+import java.io.PrintStream;
+import java.io.Reader;
+import java.util.List;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.tika.io.IOUtils;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.serialization.JsonMetadataList;
+import org.apache.tika.parser.RecursiveParserWrapper;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+public class TikaCLIBatchIntegrationTest {
+
+    private File testDataFile = new File("src/test/resources/test-data");
+
+    private File tempDir;
+    private OutputStream out = null;
+    private OutputStream err = null;
+    private ByteArrayOutputStream outBuffer = null;
+
+    @Before
+    public void setup() throws Exception {
+        tempDir = File.createTempFile("tika-cli-test-batch-", "");
+        tempDir.delete();
+        tempDir.mkdir();
+        outBuffer = new ByteArrayOutputStream();
+        PrintStream outWriter = new PrintStream(outBuffer, true, IOUtils.UTF_8.name());
+        ByteArrayOutputStream errBuffer = new ByteArrayOutputStream();
+        PrintStream errWriter = new PrintStream(errBuffer, true, IOUtils.UTF_8.name());
+        out = System.out;
+        err = System.err;
+        System.setOut(outWriter);
+        System.setErr(errWriter);
+    }
+
+    @After
+    public void tearDown() throws Exception {
+        System.setOut(new PrintStream(out, true, IOUtils.UTF_8.name()));
+        System.setErr(new PrintStream(err, true, IOUtils.UTF_8.name()));
+        FileUtils.deleteDirectory(tempDir);
+    }
+
+    @Test
+    public void testSimplestBatchIntegration() throws Exception {
+        String[] params = {escape(testDataFile.getAbsolutePath()),
+                escape(tempDir.getAbsolutePath())};
+        TikaCLI.main(params);
+
+        assertTrue("bad_xml.xml.xml", new File(tempDir, "bad_xml.xml.xml").isFile());
+        assertTrue("coffee.xls.xml", new File(tempDir, "coffee.xls.xml").exists());
+    }
+
+    @Test
+    public void testBasicBatchIntegration() throws Exception {
+        String[] params = {"-i", escape(testDataFile.getAbsolutePath()),
+                "-o", escape(tempDir.getAbsolutePath()),
+                "-numConsumers", "2"
+        };
+        TikaCLI.main(params);
+
+        assertTrue("bad_xml.xml.xml", new File(tempDir, "bad_xml.xml.xml").isFile());
+        assertTrue("coffee.xls.xml", new File(tempDir, "coffee.xls.xml").exists());
+    }
+
+    @Test
+    public void testJsonRecursiveBatchIntegration() throws Exception {
+        Reader reader = null;
+        try {
+            String[] params = {"-i", escape(testDataFile.getAbsolutePath()),
+                    "-o", escape(tempDir.getAbsolutePath()),
+                    "-numConsumers", "10",
+                    "-J", //recursive Json
+                    "-t" //plain text in content
+            };
+            TikaCLI.main(params);
+            reader = new InputStreamReader(
+                    new FileInputStream(new File(tempDir, "test_recursive_embedded.docx.json")), IOUtils.UTF_8);
+            List<Metadata> metadataList = JsonMetadataList.fromJson(reader);
+            assertEquals(12, metadataList.size());
+            assertTrue(metadataList.get(6).get(RecursiveParserWrapper.TIKA_CONTENT).contains("human events"));
+        } finally {
+            IOUtils.closeQuietly(reader);
+        }
+    }
+
+    @Test
+    public void testProcessLogFileConfig() throws Exception {
+        String[] params = {"-i", escape(testDataFile.getAbsolutePath()),
+                "-o", escape(tempDir.getAbsolutePath()),
+                "-numConsumers", "2",
+                "-JDlog4j.configuration=log4j_batch_process_test.properties"};
+        TikaCLI.main(params);
+
+        assertTrue("bad_xml.xml.xml", new File(tempDir, "bad_xml.xml.xml").isFile());
+        assertTrue("coffee.xls.xml", new File(tempDir, "coffee.xls.xml").exists());
+        String sysOutString = new String(outBuffer.toByteArray(), IOUtils.UTF_8);
+        assertTrue(sysOutString.contains("MY_CUSTOM_LOG_CONFIG"));
+    }
+
+    public static String escape(String path) {
+        if (path.indexOf(' ') > -1) {
+            return '"' + path + '"';
+        }
+        return path;
+    }
+
+}
diff --git a/tika-app/src/test/resources/log4j_batch_process_test.properties b/tika-app/src/test/resources/log4j_batch_process_test.properties
index 9f75aa9a7..87d398fed 100644
--- a/tika-app/src/test/resources/log4j_batch_process_test.properties
+++ b/tika-app/src/test/resources/log4j_batch_process_test.properties
@@ -1,24 +1,24 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#info,debug, error,fatal ...
-log4j.rootLogger=info,stdout
-
-#console
-log4j.appender.stdout=org.apache.log4j.ConsoleAppender
-log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
-
-
-log4j.appender.stdout.layout.ConversionPattern=MY_CUSTOM_LOG_CONFIG %m%n
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#info,debug, error,fatal ...
+log4j.rootLogger=info,stdout
+
+#console
+log4j.appender.stdout=org.apache.log4j.ConsoleAppender
+log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
+
+
+log4j.appender.stdout.layout.ConversionPattern=MY_CUSTOM_LOG_CONFIG %m%n
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/BatchProcess.java b/tika-batch/src/main/java/org/apache/tika/batch/BatchProcess.java
index 656a30ca8..5d29b6a60 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/BatchProcess.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/BatchProcess.java
@@ -28,15 +28,15 @@ import java.util.concurrent.ExecutionException;
 import java.util.concurrent.ExecutorCompletionService;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.tika.io.IOUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-
-/**
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.tika.io.IOUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+
+/**
  * This is the main processor class for a single process.
  * This class can only be run once.
  * <p/>
@@ -65,15 +65,15 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
         CRAWLER_TIMED_OUT,
         TIMED_OUT_CONSUMER,
         USER_INTERRUPTION,
-        BATCH_PROCESS_ALIVE_TOO_LONG,
-    }
-
-    private static final Logger logger;
-    static {
-        logger = LoggerFactory.getLogger(BatchProcess.class);
-    }
-
-    private PrintStream outputStreamWriter;
+        BATCH_PROCESS_ALIVE_TOO_LONG,
+    }
+
+    private static final Logger logger;
+    static {
+        logger = LoggerFactory.getLogger(BatchProcess.class);
+    }
+
+    private PrintStream outputStreamWriter;
 
     // If a file hasn't been processed in this amount of time,
     // report it to the console. When the directory crawler has stopped, the thread will
@@ -127,17 +127,17 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
      */
     public ParallelFileProcessingResult call()
             throws InterruptedException {
-        if (alreadyExecuted) {
-            throw new IllegalStateException("Can only execute BatchRunner once.");
-        }
-        //redirect streams; all organic warnings should go to System.err;
-        //System.err should be redirected to System.out
-        PrintStream sysErr = System.err;
-        try {
-            outputStreamWriter = new PrintStream(sysErr, true, IOUtils.UTF_8.toString());
-        } catch (IOException e) {
-            throw new RuntimeException("Can't redirect streams");
-        }
+        if (alreadyExecuted) {
+            throw new IllegalStateException("Can only execute BatchRunner once.");
+        }
+        //redirect streams; all organic warnings should go to System.err;
+        //System.err should be redirected to System.out
+        PrintStream sysErr = System.err;
+        try {
+            outputStreamWriter = new PrintStream(sysErr, true, IOUtils.UTF_8.toString());
+        } catch (IOException e) {
+            throw new RuntimeException("Can't redirect streams");
+        }
         System.setErr(System.out);
 
         ParallelFileProcessingResult result = null;
@@ -154,13 +154,13 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
             TimeoutChecker timeoutChecker = new TimeoutChecker();
 
             try {
-                startConsumersManager();
-            } catch (BatchNoRestartError e) {
-                return new
-                        ParallelFileProcessingResult(0, 0, 0, 0,
-                        0, BatchProcessDriverCLI.PROCESS_NO_RESTART_EXIT_CODE,
-                        CAUSE_FOR_TERMINATION.CONSUMERS_MANAGER_DIDNT_INIT_IN_TIME_NO_RESTART.toString());
-
+                startConsumersManager();
+            } catch (BatchNoRestartError e) {
+                return new
+                        ParallelFileProcessingResult(0, 0, 0, 0,
+                        0, BatchProcessDriverCLI.PROCESS_NO_RESTART_EXIT_CODE,
+                        CAUSE_FOR_TERMINATION.CONSUMERS_MANAGER_DIDNT_INIT_IN_TIME_NO_RESTART.toString());
+
             }
 
             State state = mainLoop(completionService, timeoutChecker);
@@ -200,12 +200,12 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
 
                 if (futureResult != null) {
                     state.removed++;
-                    IFileProcessorFutureResult result = futureResult.get();
-                    if (result instanceof FileConsumerFutureResult) {
-                        state.consumersRemoved++;
-                    } else if (result instanceof FileResourceCrawlerFutureResult) {
-                        state.crawlersRemoved++;
-                        if (fileResourceCrawler.wasTimedOut()) {
+                    IFileProcessorFutureResult result = futureResult.get();
+                    if (result instanceof FileConsumerFutureResult) {
+                        state.consumersRemoved++;
+                    } else if (result instanceof FileResourceCrawlerFutureResult) {
+                        state.crawlersRemoved++;
+                        if (fileResourceCrawler.wasTimedOut()) {
                             causeForTermination = CAUSE_FOR_TERMINATION.CRAWLER_TIMED_OUT;
                             break;
                         }
@@ -229,13 +229,13 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
             } catch (Throwable e) {
                 if (isNonRestart(e)) {
                     causeForTermination = CAUSE_FOR_TERMINATION.MAIN_LOOP_EXCEPTION_NO_RESTART;
-                } else {
-                    causeForTermination = CAUSE_FOR_TERMINATION.MAIN_LOOP_EXCEPTION;
-                }
-                logger.error("Main loop execution exception: " + e.getMessage());
-                break;
-            }
-        }
+                } else {
+                    causeForTermination = CAUSE_FOR_TERMINATION.MAIN_LOOP_EXCEPTION;
+                }
+                logger.error("Main loop execution exception: " + e.getMessage());
+                break;
+            }
+        }
         state.causeForTermination = causeForTermination;
         return state;
     }
@@ -291,12 +291,12 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
                 break;
             }
             try {
-                IFileProcessorFutureResult result = future.get();
-                if (result instanceof FileConsumerFutureResult) {
-                    FileConsumerFutureResult consumerResult = (FileConsumerFutureResult) result;
-                    FileStarted fileStarted = consumerResult.getFileStarted();
-                    if (fileStarted != null
-                            && fileStarted.getElapsedMillis() > timeoutThresholdMillis) {
+                IFileProcessorFutureResult result = future.get();
+                if (result instanceof FileConsumerFutureResult) {
+                    FileConsumerFutureResult consumerResult = (FileConsumerFutureResult) result;
+                    FileStarted fileStarted = consumerResult.getFileStarted();
+                    if (fileStarted != null
+                            && fileStarted.getElapsedMillis() > timeoutThresholdMillis) {
                         logger.warn(fileStarted.getResourceId()
                                 + "\t caused a file processor to hang or crash. You may need to remove "
                                 + "this file from your input set and rerun.");
@@ -338,30 +338,30 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
         int exitStatus = getExitStatus(state.causeForTermination, restartMsg);
 
         //need to re-check, report, mark timed out consumers
-        timeoutChecker.checkForTimedOutConsumers();
-
-        for (FileStarted fs : timedOuts) {
-            logger.warn("A parser was still working on >" + fs.getResourceId() +
-                    "< for " + fs.getElapsedMillis() + " milliseconds after it started." +
-                    " This exceeds the maxTimeoutMillis parameter");
-        }
-        double elapsed = ((double) new Date().getTime() - (double) state.start) / 1000.0;
-        int processed = 0;
-        int numExceptions = 0;
-        for (FileResourceConsumer c : consumersManager.getConsumers()) {
-            processed += c.getNumResourcesConsumed();
-            numExceptions += c.getNumHandledExceptions();
-        }
-        return new
-            ParallelFileProcessingResult(considered, added, processed, numExceptions,
-                elapsed, exitStatus, state.causeForTermination.toString());
-    }
-
-    private class State {
-        long start = -1;
-        int numConsumers = 0;
-        int numNonConsumers = 0;
-        int removed = 0;
+        timeoutChecker.checkForTimedOutConsumers();
+
+        for (FileStarted fs : timedOuts) {
+            logger.warn("A parser was still working on >" + fs.getResourceId() +
+                    "< for " + fs.getElapsedMillis() + " milliseconds after it started." +
+                    " This exceeds the maxTimeoutMillis parameter");
+        }
+        double elapsed = ((double) new Date().getTime() - (double) state.start) / 1000.0;
+        int processed = 0;
+        int numExceptions = 0;
+        for (FileResourceConsumer c : consumersManager.getConsumers()) {
+            processed += c.getNumResourcesConsumed();
+            numExceptions += c.getNumHandledExceptions();
+        }
+        return new
+            ParallelFileProcessingResult(considered, added, processed, numExceptions,
+                elapsed, exitStatus, state.causeForTermination.toString());
+    }
+
+    private class State {
+        long start = -1;
+        int numConsumers = 0;
+        int numNonConsumers = 0;
+        int removed = 0;
         int consumersRemoved = 0;
         int crawlersRemoved = 0;
         CAUSE_FOR_TERMINATION causeForTermination = null;
@@ -385,13 +385,13 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
         try {
             timed.join(consumersManagerMaxMillis);
         } catch (InterruptedException e) {
-            logger.warn("interruption exception during consumers manager shutdown");
-        }
-        if (timed.isAlive()) {
-            logger.error("ConsumersManager did not start within " + consumersManagerMaxMillis + "ms");
-            throw new BatchNoRestartError("ConsumersManager did not start within "+consumersManagerMaxMillis+"ms");
-        }
-    }
+            logger.warn("interruption exception during consumers manager shutdown");
+        }
+        if (timed.isAlive()) {
+            logger.error("ConsumersManager did not start within " + consumersManagerMaxMillis + "ms");
+            throw new BatchNoRestartError("ConsumersManager did not start within "+consumersManagerMaxMillis+"ms");
+        }
+    }
 
     private void shutdownConsumersManager() {
         if (consumersManagerMaxMillis < 0) {
@@ -454,21 +454,21 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
         Throwable cause = e.getCause();
         return cause != null && isNonRestart(cause);
     }
-
-    private int getExitStatus(CAUSE_FOR_TERMINATION causeForTermination, String restartMsg) {
-        if (causeForTermination == CAUSE_FOR_TERMINATION.MAIN_LOOP_EXCEPTION_NO_RESTART) {
-            logger.info(CAUSE_FOR_TERMINATION.MAIN_LOOP_EXCEPTION_NO_RESTART.name());
-            return BatchProcessDriverCLI.PROCESS_NO_RESTART_EXIT_CODE;
-        }
-
+
+    private int getExitStatus(CAUSE_FOR_TERMINATION causeForTermination, String restartMsg) {
+        if (causeForTermination == CAUSE_FOR_TERMINATION.MAIN_LOOP_EXCEPTION_NO_RESTART) {
+            logger.info(CAUSE_FOR_TERMINATION.MAIN_LOOP_EXCEPTION_NO_RESTART.name());
+            return BatchProcessDriverCLI.PROCESS_NO_RESTART_EXIT_CODE;
+        }
+
         if (restartMsg != null) {
-            if (restartMsg.equals(BATCH_CONSTANTS.BATCH_PROCESS_EXCEEDED_MAX_ALIVE_TIME.toString())) {
-                logger.warn(restartMsg);
-            } else {
-                logger.error(restartMsg);
-            }
-
-            //send over stdout wrapped in outputStreamWriter
+            if (restartMsg.equals(BATCH_CONSTANTS.BATCH_PROCESS_EXCEEDED_MAX_ALIVE_TIME.toString())) {
+                logger.warn(restartMsg);
+            } else {
+                logger.error(restartMsg);
+            }
+
+            //send over stdout wrapped in outputStreamWriter
             outputStreamWriter.println(
                     BATCH_CONSTANTS.BATCH_PROCESS_FATAL_MUST_RESTART.toString() +
                             " >> " + restartMsg);
@@ -579,14 +579,14 @@ public class BatchProcess implements Callable<ParallelFileProcessingResult> {
                 }
             }
         }
-    }
-
-    private class TimeoutFutureResult implements IFileProcessorFutureResult {
-        //used to be used when more than one timeout was allowed
-        //TODO: get rid of this?
-        private final int timedOutCount;
-
-        private TimeoutFutureResult(final int timedOutCount) {
+    }
+
+    private class TimeoutFutureResult implements IFileProcessorFutureResult {
+        //used to be used when more than one timeout was allowed
+        //TODO: get rid of this?
+        private final int timedOutCount;
+
+        private TimeoutFutureResult(final int timedOutCount) {
             this.timedOutCount = timedOutCount;
         }
 
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/BatchProcessDriverCLI.java b/tika-batch/src/main/java/org/apache/tika/batch/BatchProcessDriverCLI.java
index 704a38826..03205d513 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/BatchProcessDriverCLI.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/BatchProcessDriverCLI.java
@@ -26,15 +26,15 @@ import java.io.OutputStream;
 import java.io.OutputStreamWriter;
 import java.io.Writer;
 import java.util.ArrayList;
-import java.util.List;
-import java.util.Locale;
-
-import org.apache.tika.io.IOUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public class BatchProcessDriverCLI {
-
+import java.util.List;
+import java.util.Locale;
+
+import org.apache.tika.io.IOUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class BatchProcessDriverCLI {
+
     /**
      * This relies on an special exit values of 254 (do not restart),
      * 0 ended correctly, 253 ended with exception (do restart)
@@ -42,13 +42,13 @@ public class BatchProcessDriverCLI {
     public static final int PROCESS_RESTART_EXIT_CODE = 253;
     //make sure this is above 255 to avoid stopping on system errors
     //that is, if there is a system error (e.g. 143), you
-    //should restart the process.
-    public static final int PROCESS_NO_RESTART_EXIT_CODE = 254;
-    public static final int PROCESS_COMPLETED_SUCCESSFULLY = 0;
-    private static Logger logger = LoggerFactory.getLogger(BatchProcessDriverCLI.class);
-
-    private int maxProcessRestarts = -1;
-    private long pulseMillis = 1000;
+    //should restart the process.
+    public static final int PROCESS_NO_RESTART_EXIT_CODE = 254;
+    public static final int PROCESS_COMPLETED_SUCCESSFULLY = 0;
+    private static Logger logger = LoggerFactory.getLogger(BatchProcessDriverCLI.class);
+
+    private int maxProcessRestarts = -1;
+    private long pulseMillis = 1000;
 
     //how many times to wait pulseMillis milliseconds if a restart
     //message has been received through stdout, but the
@@ -102,21 +102,21 @@ public class BatchProcessDriverCLI {
     }
 
     public void execute() throws Exception {
-
-        interruptWatcherThread.setDaemon(true);
-        interruptWatcherThread.start();
-        logger.info("about to start driver");
-        start();
-        int loopsAfterRestartMessageReceived = 0;
-        while (!userInterrupted) {
+
+        interruptWatcherThread.setDaemon(true);
+        interruptWatcherThread.start();
+        logger.info("about to start driver");
+        start();
+        int loopsAfterRestartMessageReceived = 0;
+        while (!userInterrupted) {
             Integer exit = null;
-            try {
-                logger.trace("about to check exit value");
-                exit = process.exitValue();
-                logger.info("The child process has finished with an exit value of: "+exit);
-                stop();
-            } catch (IllegalThreadStateException e) {
-                //hasn't exited
+            try {
+                logger.trace("about to check exit value");
+                exit = process.exitValue();
+                logger.info("The child process has finished with an exit value of: "+exit);
+                stop();
+            } catch (IllegalThreadStateException e) {
+                //hasn't exited
                 logger.trace("process has not exited; IllegalThreadStateException");
             }
 
@@ -135,13 +135,13 @@ public class BatchProcessDriverCLI {
                     " exit=" + exit + " receivedRestartMsg=" + receivedRestartMsg);
             //if we've gotten the message via stdout to restart
             //but the process hasn't exited yet, give it another
-            //chance
-            if (receivedRestartMsg && exit == null) {
-                loopsAfterRestartMessageReceived++;
-                logger.warn("Must restart, still not exited; loops after restart: " +
-                            loopsAfterRestartMessageReceived);
-                continue;
-            }
+            //chance
+            if (receivedRestartMsg && exit == null) {
+                loopsAfterRestartMessageReceived++;
+                logger.warn("Must restart, still not exited; loops after restart: " +
+                            loopsAfterRestartMessageReceived);
+                continue;
+            }
             if (loopsAfterRestartMessageReceived > waitNumLoopsAfterRestartmessage) {
                 logger.trace("About to try to restart because:" +
                         " exit=" + exit + " receivedRestartMsg=" + receivedRestartMsg);
@@ -153,13 +153,13 @@ public class BatchProcessDriverCLI {
                 }
             } else if (exit != null && exit != BatchProcessDriverCLI.PROCESS_NO_RESTART_EXIT_CODE
                     && exit != BatchProcessDriverCLI.PROCESS_COMPLETED_SUCCESSFULLY) {
-                logger.trace("About to try to restart because:" +
-                            " exit=" + exit + " receivedRestartMsg=" + receivedRestartMsg);
-
-                if (exit == BatchProcessDriverCLI.PROCESS_RESTART_EXIT_CODE) {
-                    logger.info("Restarting on expected restart code");
-                } else {
-                    logger.warn("Restarting on unexpected restart code: "+exit);
+                logger.trace("About to try to restart because:" +
+                            " exit=" + exit + " receivedRestartMsg=" + receivedRestartMsg);
+
+                if (exit == BatchProcessDriverCLI.PROCESS_RESTART_EXIT_CODE) {
+                    logger.info("Restarting on expected restart code");
+                } else {
+                    logger.warn("Restarting on unexpected restart code: "+exit);
                 }
                 boolean restarted = restart(exit, receivedRestartMsg);
                 if (!restarted) {
@@ -170,18 +170,18 @@ public class BatchProcessDriverCLI {
                 logger.trace("Will not restart: "+exit);
                 break;
             }
-        }
-        logger.trace("about to call shutdown driver now");
-        shutdownDriverNow();
-        logger.info("Process driver has completed");
-    }
-
-    private void shutdownDriverNow() {
-        if (process != null) {
-            for (int i = 0; i < 60; i++) {
-
-                logger.trace("trying to shut down: "+i);
-                try {
+        }
+        logger.trace("about to call shutdown driver now");
+        shutdownDriverNow();
+        logger.info("Process driver has completed");
+    }
+
+    private void shutdownDriverNow() {
+        if (process != null) {
+            for (int i = 0; i < 60; i++) {
+
+                logger.trace("trying to shut down: "+i);
+                try {
                     int exit = process.exitValue();
                     logger.trace("trying to stop:"+exit);
                     stop();
@@ -193,13 +193,13 @@ public class BatchProcessDriverCLI {
                 try {
                     Thread.sleep(1000);
                 } catch (InterruptedException e) {
-                    //swallow
-                }
-            }
-            logger.error("Process didn't stop after 60 seconds after shutdown. " +
-                    "I am forcefully killing it.");
-        }
-        interruptWatcherThread.interrupt();
+                    //swallow
+                }
+            }
+            logger.error("Process didn't stop after 60 seconds after shutdown. " +
+                    "I am forcefully killing it.");
+        }
+        interruptWatcherThread.interrupt();
     }
 
     public int getNumRestarts() {
@@ -261,17 +261,17 @@ public class BatchProcessDriverCLI {
         interruptWriter = new InterruptWriter(process.getOutputStream());
         interruptWriterThread = new Thread(interruptWriter);
         interruptWriterThread.start();
-
-    }
-
-    /**
-     * Typically only used for testing.  This determines whether or not
-     * to redirect child process's stdOut to driver's stdout
-     * @param redirectChildProcessToStdOut should the driver redirect the child's stdout
-     */
-    public void setRedirectChildProcessToStdOut(boolean redirectChildProcessToStdOut) {
-        this.redirectChildProcessToStdOut = redirectChildProcessToStdOut;
-    }
+
+    }
+
+    /**
+     * Typically only used for testing.  This determines whether or not
+     * to redirect child process's stdOut to driver's stdout
+     * @param redirectChildProcessToStdOut should the driver redirect the child's stdout
+     */
+    public void setRedirectChildProcessToStdOut(boolean redirectChildProcessToStdOut) {
+        this.redirectChildProcessToStdOut = redirectChildProcessToStdOut;
+    }
 
     /**
      * Class to watch stdin from the driver for anything that is typed.
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/FileResourceCrawler.java b/tika-batch/src/main/java/org/apache/tika/batch/FileResourceCrawler.java
index 71b5c45c9..4dc4f2f21 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/FileResourceCrawler.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/FileResourceCrawler.java
@@ -19,16 +19,16 @@ package org.apache.tika.batch;
 
 import java.util.Date;
 import java.util.concurrent.ArrayBlockingQueue;
-import java.util.concurrent.Callable;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.tika.extractor.DocumentSelector;
-import org.apache.tika.metadata.Metadata;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public abstract class FileResourceCrawler implements Callable<IFileProcessorFutureResult> {
-
+import java.util.concurrent.Callable;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.tika.extractor.DocumentSelector;
+import org.apache.tika.metadata.Metadata;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public abstract class FileResourceCrawler implements Callable<IFileProcessorFutureResult> {
+
     protected final static int SKIPPED = 0;
     protected final static int ADDED = 1;
     protected final static int STOP_NOW = 2;
@@ -38,13 +38,13 @@ public abstract class FileResourceCrawler implements Callable<IFileProcessorFutu
     private volatile boolean isActive = true;
     private volatile boolean timedOut = false;
 
-    //how long to pause if can't add to queue
-    private static final long PAUSE_INCREMENT_MILLIS = 1000;
-
-    protected static Logger logger = LoggerFactory.getLogger(FileResourceCrawler.class.toString());
-
-    private int maxFilesToAdd = -1;
-    private int maxFilesToConsider = -1;
+    //how long to pause if can't add to queue
+    private static final long PAUSE_INCREMENT_MILLIS = 1000;
+
+    protected static Logger logger = LoggerFactory.getLogger(FileResourceCrawler.class.toString());
+
+    private int maxFilesToAdd = -1;
+    private int maxFilesToConsider = -1;
 
     private final ArrayBlockingQueue<FileResource> queue;
     private final int numConsumers;
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/Interrupter.java b/tika-batch/src/main/java/org/apache/tika/batch/Interrupter.java
index d023d33e3..672b497c1 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/Interrupter.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/Interrupter.java
@@ -19,27 +19,27 @@ package org.apache.tika.batch;
 
 import java.io.BufferedReader;
 import java.io.IOException;
-import java.io.InputStreamReader;
-import java.util.concurrent.Callable;
-
-import org.apache.tika.io.IOUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-
-/**
+import java.io.InputStreamReader;
+import java.util.concurrent.Callable;
+
+import org.apache.tika.io.IOUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+
+/**
  * Class that waits for input on System.in.  If the user enters a keystroke on 
  * System.in, this will send a signal to the FileResourceRunner to shutdown gracefully.
  *
  * <p>
  * In the future, this may implement a common IInterrupter interface for more flexibility.
- */
-public class Interrupter implements Callable<IFileProcessorFutureResult> {
-
-    private Logger logger = LoggerFactory.getLogger(Interrupter.class);
-	public IFileProcessorFutureResult call(){
-		try{
-			BufferedReader reader = new BufferedReader(new InputStreamReader(System.in, IOUtils.UTF_8));
+ */
+public class Interrupter implements Callable<IFileProcessorFutureResult> {
+
+    private Logger logger = LoggerFactory.getLogger(Interrupter.class);
+	public IFileProcessorFutureResult call(){
+		try{
+			BufferedReader reader = new BufferedReader(new InputStreamReader(System.in, IOUtils.UTF_8));
 			while (true){
 				if (reader.ready()){
 					reader.readLine();
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/ParallelFileProcessingResult.java b/tika-batch/src/main/java/org/apache/tika/batch/ParallelFileProcessingResult.java
index 759a2ac68..d446a80f8 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/ParallelFileProcessingResult.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/ParallelFileProcessingResult.java
@@ -18,26 +18,26 @@ package org.apache.tika.batch;
  */
 
 public class ParallelFileProcessingResult {
-    private final int considered;
-    private final int added;
-    private final int consumed;
-    private final int numberHandledExceptions;
-    private final double secondsElapsed;
-    private final int exitStatus;
-    private final String causeForTermination;
-
-    public ParallelFileProcessingResult(int considered, int added,
-                                        int consumed, int numberHandledExceptions,
-                                        double secondsElapsed,
-                                        int exitStatus,
-                                        String causeForTermination) {
-        this.considered = considered;
-        this.added = added;
-        this.consumed = consumed;
-        this.numberHandledExceptions = numberHandledExceptions;
-        this.secondsElapsed = secondsElapsed;
-        this.exitStatus = exitStatus;
-        this.causeForTermination = causeForTermination;
+    private final int considered;
+    private final int added;
+    private final int consumed;
+    private final int numberHandledExceptions;
+    private final double secondsElapsed;
+    private final int exitStatus;
+    private final String causeForTermination;
+
+    public ParallelFileProcessingResult(int considered, int added,
+                                        int consumed, int numberHandledExceptions,
+                                        double secondsElapsed,
+                                        int exitStatus,
+                                        String causeForTermination) {
+        this.considered = considered;
+        this.added = added;
+        this.consumed = consumed;
+        this.numberHandledExceptions = numberHandledExceptions;
+        this.secondsElapsed = secondsElapsed;
+        this.exitStatus = exitStatus;
+        this.causeForTermination = causeForTermination;
     }
 
     /**
@@ -79,16 +79,16 @@ public class ParallelFileProcessingResult {
      * @return seconds elapsed since the start of the batch processing
      */
     public double secondsElapsed() {
-        return secondsElapsed;
-    }
-
-    public int getNumberHandledExceptions() {
-        return numberHandledExceptions;
-    }
-
-    /**
-     *
-     * @return intendedExitStatus
+        return secondsElapsed;
+    }
+
+    public int getNumberHandledExceptions() {
+        return numberHandledExceptions;
+    }
+
+    /**
+     *
+     * @return intendedExitStatus
      */
     public int getExitStatus() {
         return exitStatus;
@@ -97,13 +97,13 @@ public class ParallelFileProcessingResult {
     @Override
     public String toString() {
         return "ParallelFileProcessingResult{" +
-                "considered=" + considered +
-                ", added=" + added +
-                ", consumed=" + consumed +
-                ", numberHandledExceptions=" + numberHandledExceptions +
-                ", secondsElapsed=" + secondsElapsed +
-                ", exitStatus=" + exitStatus +
-                ", causeForTermination='" + causeForTermination + '\'' +
+                "considered=" + considered +
+                ", added=" + added +
+                ", consumed=" + consumed +
+                ", numberHandledExceptions=" + numberHandledExceptions +
+                ", secondsElapsed=" + secondsElapsed +
+                ", exitStatus=" + exitStatus +
+                ", causeForTermination='" + causeForTermination + '\'' +
                 '}';
     }
 }
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/StatusReporter.java b/tika-batch/src/main/java/org/apache/tika/batch/StatusReporter.java
index 2958e16b4..6ce1a17a5 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/StatusReporter.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/StatusReporter.java
@@ -19,24 +19,24 @@ package org.apache.tika.batch;
 
 import java.text.NumberFormat;
 import java.util.Date;
-import java.util.Locale;
-import java.util.concurrent.Callable;
-
-import org.apache.tika.util.DurationFormatUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Basic class to use for reporting status from both the crawler and the consumers.
+import java.util.Locale;
+import java.util.concurrent.Callable;
+
+import org.apache.tika.util.DurationFormatUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Basic class to use for reporting status from both the crawler and the consumers.
  * This wakes up roughly every {@link #sleepMillis} and log.info's a status report.
  */
-
-public class StatusReporter implements Callable<IFileProcessorFutureResult> {
-
-    private final Logger logger = LoggerFactory.getLogger(StatusReporter.class);
-
-    //require references to these so that the
-    //StatusReporter can query them when it wakes up
+
+public class StatusReporter implements Callable<IFileProcessorFutureResult> {
+
+    private final Logger logger = LoggerFactory.getLogger(StatusReporter.class);
+
+    //require references to these so that the
+    //StatusReporter can query them when it wakes up
     private final ConsumersManager consumersManager;
     private final FileResourceCrawler crawler;
 
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/builders/SimpleLogReporterBuilder.java b/tika-batch/src/main/java/org/apache/tika/batch/builders/SimpleLogReporterBuilder.java
index 488b14c49..fd68ab945 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/builders/SimpleLogReporterBuilder.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/builders/SimpleLogReporterBuilder.java
@@ -30,13 +30,13 @@ public class SimpleLogReporterBuilder implements StatusReporterBuilder {
 
     @Override
     public StatusReporter build(FileResourceCrawler crawler, ConsumersManager consumersManager,
-                                Node n, Map<String, String> commandlineArguments) {
-
-        Map<String, String> attributes = XMLDOMUtil.mapifyAttrs(n, commandlineArguments);
-        long sleepMillis = PropsUtil.getLong(attributes.get("reporterSleepMillis"), 1000L);
-        long staleThresholdMillis = PropsUtil.getLong(attributes.get("reporterStaleThresholdMillis"), 500000L);
-        StatusReporter reporter = new StatusReporter(crawler, consumersManager);
-        reporter.setSleepMillis(sleepMillis);
+                                Node n, Map<String, String> commandlineArguments) {
+
+        Map<String, String> attributes = XMLDOMUtil.mapifyAttrs(n, commandlineArguments);
+        long sleepMillis = PropsUtil.getLong(attributes.get("reporterSleepMillis"), 1000L);
+        long staleThresholdMillis = PropsUtil.getLong(attributes.get("reporterStaleThresholdMillis"), 500000L);
+        StatusReporter reporter = new StatusReporter(crawler, consumersManager);
+        reporter.setSleepMillis(sleepMillis);
         reporter.setStaleThresholdMillis(staleThresholdMillis);
         return reporter;
     }
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/fs/AbstractFSConsumer.java b/tika-batch/src/main/java/org/apache/tika/batch/fs/AbstractFSConsumer.java
index 78b2f8dfb..78f56d040 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/fs/AbstractFSConsumer.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/fs/AbstractFSConsumer.java
@@ -19,12 +19,12 @@ package org.apache.tika.batch.fs;
 
 import java.io.IOException;
 import java.io.InputStream;
-import java.io.OutputStream;
-import java.util.concurrent.ArrayBlockingQueue;
-
-import org.apache.tika.batch.BatchNoRestartError;
-import org.apache.tika.batch.FileResource;
-import org.apache.tika.batch.FileResourceConsumer;
+import java.io.OutputStream;
+import java.util.concurrent.ArrayBlockingQueue;
+
+import org.apache.tika.batch.BatchNoRestartError;
+import org.apache.tika.batch.FileResource;
+import org.apache.tika.batch.FileResourceConsumer;
 import org.apache.tika.batch.OutputStreamFactory;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.parser.ParseContext;
@@ -51,32 +51,32 @@ public abstract class AbstractFSConsumer extends FileResourceConsumer {
         OutputStream os = null;
         try {
             os = fsOSFactory.getOutputStream(fileResource.getMetadata());
-        } catch (IOException e) {
-            //This can happen if the disk has run out of space,
-            //or if there was a failure with mkdirs in fsOSFactory
-            logger.error("{}", getXMLifiedLogMsg(IO_OS,
-                    fileResource.getResourceId(), e));
-            throw new BatchNoRestartError("IOException trying to open output stream for " +
-                    fileResource.getResourceId() + " :: " + e.getMessage());
-        }
-        return os;
-    }
-
-    /**
-     *
-     * @param fileResource
-     * @return inputStream, can be null if there is an exception opening IS
-     */
-    protected InputStream getInputStream(FileResource fileResource) {
-        InputStream is = null;
-        try {
-            is = fileResource.openInputStream();
-        } catch (IOException e) {
-            logger.warn("{}", getXMLifiedLogMsg(IO_IS,
-                    fileResource.getResourceId(), e));
-            flushAndClose(is);
-        }
-        return is;
-    }
-
-}
+        } catch (IOException e) {
+            //This can happen if the disk has run out of space,
+            //or if there was a failure with mkdirs in fsOSFactory
+            logger.error("{}", getXMLifiedLogMsg(IO_OS,
+                    fileResource.getResourceId(), e));
+            throw new BatchNoRestartError("IOException trying to open output stream for " +
+                    fileResource.getResourceId() + " :: " + e.getMessage());
+        }
+        return os;
+    }
+
+    /**
+     *
+     * @param fileResource
+     * @return inputStream, can be null if there is an exception opening IS
+     */
+    protected InputStream getInputStream(FileResource fileResource) {
+        InputStream is = null;
+        try {
+            is = fileResource.openInputStream();
+        } catch (IOException e) {
+            logger.warn("{}", getXMLifiedLogMsg(IO_IS,
+                    fileResource.getResourceId(), e));
+            flushAndClose(is);
+        }
+        return is;
+    }
+
+}
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/fs/BasicTikaFSConsumer.java b/tika-batch/src/main/java/org/apache/tika/batch/fs/BasicTikaFSConsumer.java
index beebc8008..5daf5e654 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/fs/BasicTikaFSConsumer.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/fs/BasicTikaFSConsumer.java
@@ -19,12 +19,12 @@ package org.apache.tika.batch.fs;
 
 import java.io.InputStream;
 import java.io.OutputStream;
-import java.io.UnsupportedEncodingException;
-import java.util.concurrent.ArrayBlockingQueue;
-
-import org.apache.tika.batch.FileResource;
-import org.apache.tika.batch.OutputStreamFactory;
-import org.apache.tika.batch.ParserFactory;
+import java.io.UnsupportedEncodingException;
+import java.util.concurrent.ArrayBlockingQueue;
+
+import org.apache.tika.batch.FileResource;
+import org.apache.tika.batch.OutputStreamFactory;
+import org.apache.tika.batch.ParserFactory;
 import org.apache.tika.config.TikaConfig;
 import org.apache.tika.io.IOUtils;
 import org.apache.tika.parser.ParseContext;
@@ -86,14 +86,14 @@ public class BasicTikaFSConsumer extends AbstractFSConsumer {
         }
         ContentHandler handler;
         try {
-            handler = contentHandlerFactory.getNewContentHandler(os, getOutputEncoding());
-        } catch (UnsupportedEncodingException e) {
-            incrementHandledExceptions();
-            logger.error(getXMLifiedLogMsg("output_encoding_ex",
-                    fileResource.getResourceId(), e));
-            flushAndClose(os);
-            throw new RuntimeException(e.getMessage());
-        }
+            handler = contentHandlerFactory.getNewContentHandler(os, getOutputEncoding());
+        } catch (UnsupportedEncodingException e) {
+            incrementHandledExceptions();
+            logger.error(getXMLifiedLogMsg("output_encoding_ex",
+                    fileResource.getResourceId(), e));
+            flushAndClose(os);
+            throw new RuntimeException(e.getMessage());
+        }
 
         //now actually call parse!
         Throwable thrown = null;
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/fs/FSBatchProcessCLI.java b/tika-batch/src/main/java/org/apache/tika/batch/fs/FSBatchProcessCLI.java
index 2f3dbb0f4..0227f7fd8 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/fs/FSBatchProcessCLI.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/fs/FSBatchProcessCLI.java
@@ -16,69 +16,69 @@ package org.apache.tika.batch.fs;
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-
-import java.io.File;
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.concurrent.ExecutorService;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
 
 import org.apache.commons.cli.CommandLine;
 import org.apache.commons.cli.CommandLineParser;
 import org.apache.commons.cli.GnuParser;
-import org.apache.commons.cli.HelpFormatter;
-import org.apache.commons.cli.Option;
-import org.apache.commons.cli.Options;
-import org.apache.tika.batch.BatchProcess;
-import org.apache.tika.batch.BatchProcessDriverCLI;
-import org.apache.tika.batch.ParallelFileProcessingResult;
+import org.apache.commons.cli.HelpFormatter;
+import org.apache.commons.cli.Option;
+import org.apache.commons.cli.Options;
+import org.apache.tika.batch.BatchProcess;
+import org.apache.tika.batch.BatchProcessDriverCLI;
+import org.apache.tika.batch.ParallelFileProcessingResult;
 import org.apache.tika.batch.builders.BatchProcessBuilder;
-import org.apache.tika.batch.builders.CommandLineParserBuilder;
-import org.apache.tika.io.IOUtils;
-import org.apache.tika.io.TikaInputStream;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.slf4j.MarkerFactory;
-
-public class FSBatchProcessCLI {
-
-    public static String FINISHED_STRING = "Main thread in TikaFSBatchCLI has finished processing.";
-
-    private static Logger logger = LoggerFactory.getLogger(FSBatchProcessCLI.class);
-    private final Options options;
-
-    public FSBatchProcessCLI(String[] args) throws IOException {
-        TikaInputStream configIs = null;
-        try {
-            configIs = getConfigInputStream(args, true);
-            CommandLineParserBuilder builder = new CommandLineParserBuilder();
-            options = builder.build(configIs);
-        } finally {
+import org.apache.tika.batch.builders.CommandLineParserBuilder;
+import org.apache.tika.io.IOUtils;
+import org.apache.tika.io.TikaInputStream;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.slf4j.MarkerFactory;
+
+public class FSBatchProcessCLI {
+
+    public static String FINISHED_STRING = "Main thread in TikaFSBatchCLI has finished processing.";
+
+    private static Logger logger = LoggerFactory.getLogger(FSBatchProcessCLI.class);
+    private final Options options;
+
+    public FSBatchProcessCLI(String[] args) throws IOException {
+        TikaInputStream configIs = null;
+        try {
+            configIs = getConfigInputStream(args, true);
+            CommandLineParserBuilder builder = new CommandLineParserBuilder();
+            options = builder.build(configIs);
+        } finally {
             IOUtils.closeQuietly(configIs);
         }
     }
 
     public void usage() {
         HelpFormatter helpFormatter = new HelpFormatter();
-        helpFormatter.printHelp("tika filesystem batch", options);
-    }
-
-    private TikaInputStream getConfigInputStream(String[] args, boolean logDefault) throws IOException {
-        TikaInputStream is = null;
-        File batchConfigFile = getConfigFile(args);
-        if (batchConfigFile != null) {
+        helpFormatter.printHelp("tika filesystem batch", options);
+    }
+
+    private TikaInputStream getConfigInputStream(String[] args, boolean logDefault) throws IOException {
+        TikaInputStream is = null;
+        File batchConfigFile = getConfigFile(args);
+        if (batchConfigFile != null) {
             //this will throw IOException if it can't find a specified config file
-            //better to throw an exception than silently back off to default.
-            is = TikaInputStream.get(batchConfigFile);
-        } else {
-            if (logDefault) {
-                logger.info("No config file set via -bc, relying on default-tika-batch-config.xml");
-            }
-            is = TikaInputStream.get(
-                    FSBatchProcessCLI.class.getResourceAsStream("default-tika-batch-config.xml"));
-        }
+            //better to throw an exception than silently back off to default.
+            is = TikaInputStream.get(batchConfigFile);
+        } else {
+            if (logDefault) {
+                logger.info("No config file set via -bc, relying on default-tika-batch-config.xml");
+            }
+            is = TikaInputStream.get(
+                    FSBatchProcessCLI.class.getResourceAsStream("default-tika-batch-config.xml"));
+        }
         return is;
     }
 
@@ -102,13 +102,13 @@ public class FSBatchProcessCLI {
         }
 
         BatchProcessBuilder b = new BatchProcessBuilder();
-        TikaInputStream is = null;
-        BatchProcess process = null;
-        try {
-            is = getConfigInputStream(args, false);
-            process = b.build(is, mapArgs);
-        } finally {
-            IOUtils.closeQuietly(is);
+        TikaInputStream is = null;
+        BatchProcess process = null;
+        try {
+            is = getConfigInputStream(args, false);
+            process = b.build(is, mapArgs);
+        } finally {
+            IOUtils.closeQuietly(is);
         }
         final Thread mainThread = Thread.currentThread();
 
@@ -132,20 +132,20 @@ public class FSBatchProcessCLI {
                 }
             }
         }
-        return configFile;
-    }
-
-    public static void main(String[] args) throws Exception {
-
-        try{
-            FSBatchProcessCLI cli = new FSBatchProcessCLI(args);
-            cli.execute(args);
-        } catch (Throwable t) {
-            t.printStackTrace();
-            logger.error(MarkerFactory.getMarker("FATAL"),
-                    "Fatal exception from FSBatchProcessCLI: " + t.getMessage(), t);
-            System.exit(BatchProcessDriverCLI.PROCESS_NO_RESTART_EXIT_CODE);
-        }
-    }
+        return configFile;
+    }
+
+    public static void main(String[] args) throws Exception {
+
+        try{
+            FSBatchProcessCLI cli = new FSBatchProcessCLI(args);
+            cli.execute(args);
+        } catch (Throwable t) {
+            t.printStackTrace();
+            logger.error(MarkerFactory.getMarker("FATAL"),
+                    "Fatal exception from FSBatchProcessCLI: " + t.getMessage(), t);
+            System.exit(BatchProcessDriverCLI.PROCESS_NO_RESTART_EXIT_CODE);
+        }
+    }
 
 }
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/fs/RecursiveParserWrapperFSConsumer.java b/tika-batch/src/main/java/org/apache/tika/batch/fs/RecursiveParserWrapperFSConsumer.java
index a43b06a6e..dff266b39 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/fs/RecursiveParserWrapperFSConsumer.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/fs/RecursiveParserWrapperFSConsumer.java
@@ -14,21 +14,21 @@ package org.apache.tika.batch.fs;
  * distributed under the License is distributed on an "AS IS" BASIS,
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.io.OutputStreamWriter;
+ * limitations under the License.
+ */
+
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.io.OutputStreamWriter;
 import java.io.Writer;
 import java.util.LinkedList;
-import java.util.List;
-import java.util.concurrent.ArrayBlockingQueue;
-
-import org.apache.tika.batch.FileResource;
-import org.apache.tika.batch.OutputStreamFactory;
-import org.apache.tika.batch.ParserFactory;
-import org.apache.tika.config.TikaConfig;
+import java.util.List;
+import java.util.concurrent.ArrayBlockingQueue;
+
+import org.apache.tika.batch.FileResource;
+import org.apache.tika.batch.OutputStreamFactory;
+import org.apache.tika.batch.ParserFactory;
+import org.apache.tika.config.TikaConfig;
 import org.apache.tika.io.IOUtils;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.TikaCoreProperties;
@@ -127,16 +127,16 @@ public class RecursiveParserWrapperFSConsumer extends AbstractFSConsumer {
         Writer writer = null;
 
         try {
-            writer = new OutputStreamWriter(os, getOutputEncoding());
-            JsonMetadataList.toJson(metadataList, writer);
-        } catch (Exception e) {
-            //this is a stop the world kind of thing
-            logger.error("{}", getXMLifiedLogMsg(IO_OS+"json",
-                    fileResource.getResourceId(), e));
-            throw new RuntimeException(e);
-        } finally {
-            flushAndClose(writer);
-        }
+            writer = new OutputStreamWriter(os, getOutputEncoding());
+            JsonMetadataList.toJson(metadataList, writer);
+        } catch (Exception e) {
+            //this is a stop the world kind of thing
+            logger.error("{}", getXMLifiedLogMsg(IO_OS+"json",
+                    fileResource.getResourceId(), e));
+            throw new RuntimeException(e);
+        } finally {
+            flushAndClose(writer);
+        }
 
         if (thrown != null) {
             if (thrown instanceof Error) {
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/fs/builders/BasicTikaFSConsumersBuilder.java b/tika-batch/src/main/java/org/apache/tika/batch/fs/builders/BasicTikaFSConsumersBuilder.java
index e0fb784e0..2adea61ac 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/fs/builders/BasicTikaFSConsumersBuilder.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/fs/builders/BasicTikaFSConsumersBuilder.java
@@ -66,13 +66,13 @@ public class BasicTikaFSConsumersBuilder extends AbstractConsumersBuilder {
         Long consumersManagerMaxMillis = null;
         String consumersManagerMaxMillisString = runtimeAttributes.get("consumersManagerMaxMillis");
         if (consumersManagerMaxMillisString != null){
-            consumersManagerMaxMillis = PropsUtil.getLong(consumersManagerMaxMillisString, null);
-        } else {
-            Node consumersManagerMaxMillisNode = node.getAttributes().getNamedItem("consumersManagerMaxMillis");
-            if (consumersManagerMaxMillis == null && consumersManagerMaxMillisNode != null) {
-                consumersManagerMaxMillis = PropsUtil.getLong(consumersManagerMaxMillisNode.getNodeValue(),
-                        null);
-            }
+            consumersManagerMaxMillis = PropsUtil.getLong(consumersManagerMaxMillisString, null);
+        } else {
+            Node consumersManagerMaxMillisNode = node.getAttributes().getNamedItem("consumersManagerMaxMillis");
+            if (consumersManagerMaxMillis == null && consumersManagerMaxMillisNode != null) {
+                consumersManagerMaxMillis = PropsUtil.getLong(consumersManagerMaxMillisNode.getNodeValue(),
+                        null);
+            }
         }
 
         TikaConfig config = null;
diff --git a/tika-batch/src/main/java/org/apache/tika/batch/fs/strawman/StrawManTikaAppDriver.java b/tika-batch/src/main/java/org/apache/tika/batch/fs/strawman/StrawManTikaAppDriver.java
index 6b6be776d..91fc0bae2 100644
--- a/tika-batch/src/main/java/org/apache/tika/batch/fs/strawman/StrawManTikaAppDriver.java
+++ b/tika-batch/src/main/java/org/apache/tika/batch/fs/strawman/StrawManTikaAppDriver.java
@@ -31,16 +31,16 @@ import java.util.concurrent.ExecutionException;
 import java.util.concurrent.ExecutorCompletionService;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-import java.util.concurrent.atomic.AtomicInteger;
-
-import org.apache.tika.io.IOUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.slf4j.MarkerFactory;
-
-/**
- * Simple single-threaded class that calls tika-app against every file in a directory.
+import java.util.concurrent.Future;
+import java.util.concurrent.atomic.AtomicInteger;
+
+import org.apache.tika.io.IOUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.slf4j.MarkerFactory;
+
+/**
+ * Simple single-threaded class that calls tika-app against every file in a directory.
  *
  * This is exceedingly robust.  One file per process.
  *
@@ -54,13 +54,13 @@ public class StrawManTikaAppDriver implements Callable<Integer> {
     private final int totalThreads;
     private final int threadNum;
     private int rootLen = -1;
-    private File inputDir = null;
-    private File outputDir = null;
-    private String[] args = null;
-    private Logger logger = LoggerFactory.getLogger(StrawManTikaAppDriver.class);
-
-
-    public StrawManTikaAppDriver(File inputDir, File outputDir, int totalThreads, String[] args) {
+    private File inputDir = null;
+    private File outputDir = null;
+    private String[] args = null;
+    private Logger logger = LoggerFactory.getLogger(StrawManTikaAppDriver.class);
+
+
+    public StrawManTikaAppDriver(File inputDir, File outputDir, int totalThreads, String[] args) {
         rootLen = inputDir.getAbsolutePath().length()+1;
         this.inputDir = inputDir;
         this.outputDir = outputDir;
@@ -97,14 +97,14 @@ public class StrawManTikaAppDriver implements Callable<Integer> {
                 return 0;
             }
         }
-        File outputFile = new File(outputDir, f.getAbsolutePath().substring(rootLen)+".txt");
-        outputFile.getAbsoluteFile().getParentFile().mkdirs();
-        if (! outputFile.getParentFile().exists()) {
-            logger.error(MarkerFactory.getMarker("FATAL"),
-                    "parent directory for "+ outputFile + " was not made!");
-            throw new RuntimeException("couldn't make parent file for " + outputFile);
-        }
-        List<String> commandLine = new ArrayList<String>();
+        File outputFile = new File(outputDir, f.getAbsolutePath().substring(rootLen)+".txt");
+        outputFile.getAbsoluteFile().getParentFile().mkdirs();
+        if (! outputFile.getParentFile().exists()) {
+            logger.error(MarkerFactory.getMarker("FATAL"),
+                    "parent directory for "+ outputFile + " was not made!");
+            throw new RuntimeException("couldn't make parent file for " + outputFile);
+        }
+        List<String> commandLine = new ArrayList<String>();
         for (String arg : args) {
             commandLine.add(arg);
         }
diff --git a/tika-batch/src/test/resources/log4j.properties b/tika-batch/src/test/resources/log4j.properties
index 215d68ebb..a4901bddd 100644
--- a/tika-batch/src/test/resources/log4j.properties
+++ b/tika-batch/src/test/resources/log4j.properties
@@ -1,22 +1,22 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-log4j.rootLogger=OFF
-
-#for debugging
-#log4j.rootLogger=TRACE,A1
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+log4j.rootLogger=OFF
+
+#for debugging
+#log4j.rootLogger=TRACE,A1
 
 log4j.appender.A1=org.apache.log4j.ConsoleAppender
 
diff --git a/tika-batch/src/test/resources/log4j_process.properties b/tika-batch/src/test/resources/log4j_process.properties
index e5abe7ed3..9b598a102 100644
--- a/tika-batch/src/test/resources/log4j_process.properties
+++ b/tika-batch/src/test/resources/log4j_process.properties
@@ -1,24 +1,24 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#This is used by the batch process; see log4j.properties for the driver
-
-log4j.rootLogger=OFF
-
-#for debugging
-#log4j.rootLogger=TRACE,A1
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#This is used by the batch process; see log4j.properties for the driver
+
+log4j.rootLogger=OFF
+
+#for debugging
+#log4j.rootLogger=TRACE,A1
 
 log4j.appender.A1=org.apache.log4j.ConsoleAppender
 
diff --git a/tika-batch/src/test/resources/tika-batch-config-MockConsumersBuilder.xml b/tika-batch/src/test/resources/tika-batch-config-MockConsumersBuilder.xml
index ea8d90ab5..a8ea12f8a 100644
--- a/tika-batch/src/test/resources/tika-batch-config-MockConsumersBuilder.xml
+++ b/tika-batch/src/test/resources/tika-batch-config-MockConsumersBuilder.xml
@@ -103,10 +103,10 @@
 
 		<outputstream class="FSOutputStreamFactory"
                 encoding="UTF-8" outputSuffix="xml"/>
-	</consumers>
-	
-	<!-- reporter and interrupter are optional -->
-	<reporter builderClass="org.apache.tika.batch.builders.SimpleLogReporterBuilder" reporterSleepMillis="1000"
-              reporterStaleThresholdMillis="500000"/>
-	<interrupter builderClass="org.apache.tika.batch.builders.InterrupterBuilder"/>
+	</consumers>
+	
+	<!-- reporter and interrupter are optional -->
+	<reporter builderClass="org.apache.tika.batch.builders.SimpleLogReporterBuilder" reporterSleepMillis="1000"
+              reporterStaleThresholdMillis="500000"/>
+	<interrupter builderClass="org.apache.tika.batch.builders.InterrupterBuilder"/>
 </tika-batch-config>
\ No newline at end of file
diff --git a/tika-batch/src/test/resources/tika-batch-config-broken.xml b/tika-batch/src/test/resources/tika-batch-config-broken.xml
index abb4f35ff..2c8f80bbd 100644
--- a/tika-batch/src/test/resources/tika-batch-config-broken.xml
+++ b/tika-batch/src/test/resources/tika-batch-config-broken.xml
@@ -96,10 +96,10 @@
 
 		<outputstream class="FSOutputStreamFactory"
                 encoding="UTF-8" outputSuffix="xml"/>
-	</consumers>
-	
-	<!-- reporter and interrupter are optional -->
-	<reporter builderClass="org.apache.tika.batch.builders.SimpleLogReporterBuilder" reporterSleepMillis="1000"
-              reporterStaleThresholdMillis="500000"/>
-	<interrupter builderClass="org.apache.tika.batch.builders.InterrupterBuilder"/>
+	</consumers>
+	
+	<!-- reporter and interrupter are optional -->
+	<reporter builderClass="org.apache.tika.batch.builders.SimpleLogReporterBuilder" reporterSleepMillis="1000"
+              reporterStaleThresholdMillis="500000"/>
+	<interrupter builderClass="org.apache.tika.batch.builders.InterrupterBuilder"/>
 </tika-batch-config>
\ No newline at end of file
diff --git a/tika-batch/src/test/resources/tika-batch-config-test.xml b/tika-batch/src/test/resources/tika-batch-config-test.xml
index ac4be02eb..452c2d1b2 100644
--- a/tika-batch/src/test/resources/tika-batch-config-test.xml
+++ b/tika-batch/src/test/resources/tika-batch-config-test.xml
@@ -102,10 +102,10 @@
 
 		<outputstream class="FSOutputStreamFactory"
                 encoding="UTF-8" outputSuffix="xml"/>
-	</consumers>
-	
-	<!-- reporter and interrupter are optional -->
-	<reporter builderClass="org.apache.tika.batch.builders.SimpleLogReporterBuilder" reporterSleepMillis="1000"
-              reporterStaleThresholdMillis="500000"/>
-	<interrupter builderClass="org.apache.tika.batch.builders.InterrupterBuilder"/>
+	</consumers>
+	
+	<!-- reporter and interrupter are optional -->
+	<reporter builderClass="org.apache.tika.batch.builders.SimpleLogReporterBuilder" reporterSleepMillis="1000"
+              reporterStaleThresholdMillis="500000"/>
+	<interrupter builderClass="org.apache.tika.batch.builders.InterrupterBuilder"/>
 </tika-batch-config>
\ No newline at end of file
diff --git a/tika-core/src/main/java/org/apache/tika/exception/AccessPermissionException.java b/tika-core/src/main/java/org/apache/tika/exception/AccessPermissionException.java
index 2e4a789f6..b5f2136ea 100644
--- a/tika-core/src/main/java/org/apache/tika/exception/AccessPermissionException.java
+++ b/tika-core/src/main/java/org/apache/tika/exception/AccessPermissionException.java
@@ -1,40 +1,40 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.exception;
-
-/**
- * Exception to be thrown when a document does not allow content extraction.
- * As of this writing, PDF documents are the only type of document that might
- * cause this type of exception.
- */
-public class AccessPermissionException extends TikaException {
-    public AccessPermissionException() {
-        super("Unable to process: content extraction is not allowed");
-    }
-
-    public AccessPermissionException(Throwable th) {
-        super("Unable to process: content extraction is not allowed", th);
-    }
-
-    public AccessPermissionException(String info) {
-        super(info);
-    }
-
-    public AccessPermissionException(String info, Throwable th) {
-        super(info, th);
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.exception;
+
+/**
+ * Exception to be thrown when a document does not allow content extraction.
+ * As of this writing, PDF documents are the only type of document that might
+ * cause this type of exception.
+ */
+public class AccessPermissionException extends TikaException {
+    public AccessPermissionException() {
+        super("Unable to process: content extraction is not allowed");
+    }
+
+    public AccessPermissionException(Throwable th) {
+        super("Unable to process: content extraction is not allowed", th);
+    }
+
+    public AccessPermissionException(String info) {
+        super(info);
+    }
+
+    public AccessPermissionException(String info, Throwable th) {
+        super(info, th);
+    }
+}
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/AccessPermissions.java b/tika-core/src/main/java/org/apache/tika/metadata/AccessPermissions.java
index 58cc497da..12ac0e582 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/AccessPermissions.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/AccessPermissions.java
@@ -1,71 +1,71 @@
-package org.apache.tika.metadata;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Until we can find a common standard, we'll use these options.  They
- * were mostly derived from PDFBox's AccessPermission, but some can
- * apply to other document formats, especially CAN_MODIFY and FILL_IN_FORM.
- */
-public interface AccessPermissions {
-
-    final static String PREFIX = "access_permission"+Metadata.NAMESPACE_PREFIX_DELIMITER;
-
-    /**
-     * Can any modifications be made to the document
-     */
-    Property CAN_MODIFY = Property.externalTextBag(PREFIX+"can_modify");
-
-    /**
-     * Should content be extracted, generally.
-     */
-    Property EXTRACT_CONTENT = Property.externalText(PREFIX+"extract_content");
-
-    /**
-     * Should content be extracted for the purposes
-     * of accessibility.
-     */
-    Property EXTRACT_FOR_ACCESSIBILITY = Property.externalText(PREFIX + "extract_for_accessibility");
-
-    /**
-     * Can the user insert/rotate/delete pages.
-     */
-    Property ASSEMBLE_DOCUMENT = Property.externalText(PREFIX+"assemble_document");
-
-
-    /**
-     * Can the user fill in a form
-     */
-    Property FILL_IN_FORM = Property.externalText(PREFIX+"fill_in_form");
-
-    /**
-     * Can the user modify annotations
-     */
-    Property CAN_MODIFY_ANNOTATIONS = Property.externalText(PREFIX+"modify_annotations");
-
-    /**
-     * Can the user print the document
-     */
-    Property CAN_PRINT = Property.externalText(PREFIX+"can_print");
-
-    /**
-     * Can the user print an image-degraded version of the document.
-     */
-    Property CAN_PRINT_DEGRADED = Property.externalText(PREFIX+"can_print_degraded");
-
-}
+package org.apache.tika.metadata;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Until we can find a common standard, we'll use these options.  They
+ * were mostly derived from PDFBox's AccessPermission, but some can
+ * apply to other document formats, especially CAN_MODIFY and FILL_IN_FORM.
+ */
+public interface AccessPermissions {
+
+    final static String PREFIX = "access_permission"+Metadata.NAMESPACE_PREFIX_DELIMITER;
+
+    /**
+     * Can any modifications be made to the document
+     */
+    Property CAN_MODIFY = Property.externalTextBag(PREFIX+"can_modify");
+
+    /**
+     * Should content be extracted, generally.
+     */
+    Property EXTRACT_CONTENT = Property.externalText(PREFIX+"extract_content");
+
+    /**
+     * Should content be extracted for the purposes
+     * of accessibility.
+     */
+    Property EXTRACT_FOR_ACCESSIBILITY = Property.externalText(PREFIX + "extract_for_accessibility");
+
+    /**
+     * Can the user insert/rotate/delete pages.
+     */
+    Property ASSEMBLE_DOCUMENT = Property.externalText(PREFIX+"assemble_document");
+
+
+    /**
+     * Can the user fill in a form
+     */
+    Property FILL_IN_FORM = Property.externalText(PREFIX+"fill_in_form");
+
+    /**
+     * Can the user modify annotations
+     */
+    Property CAN_MODIFY_ANNOTATIONS = Property.externalText(PREFIX+"modify_annotations");
+
+    /**
+     * Can the user print the document
+     */
+    Property CAN_PRINT = Property.externalText(PREFIX+"can_print");
+
+    /**
+     * Can the user print an image-degraded version of the document.
+     */
+    Property CAN_PRINT_DEGRADED = Property.externalText(PREFIX+"can_print_degraded");
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/sax/ToHTMLContentHandler.java b/tika-core/src/main/java/org/apache/tika/sax/ToHTMLContentHandler.java
index 4a9159a60..116d6c402 100755
--- a/tika-core/src/main/java/org/apache/tika/sax/ToHTMLContentHandler.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/ToHTMLContentHandler.java
@@ -1,70 +1,70 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.sax;
-
-import java.io.OutputStream;
-import java.io.UnsupportedEncodingException;
-import java.util.Arrays;
-import java.util.HashSet;
-import java.util.Set;
-
-import org.xml.sax.SAXException;
-
-/**
- * SAX event handler that serializes the HTML document to a character stream.
- * The incoming SAX events are expected to be well-formed (properly nested,
- * etc.) and valid HTML.
- *
- * @since Apache Tika 0.10
- */
-public class ToHTMLContentHandler extends ToXMLContentHandler {
-
-    private static final Set<String> EMPTY_ELEMENTS =
-        new HashSet<String>(Arrays.asList(
-            "area", "base", "basefont", "br", "col", "frame", "hr",
-            "img", "input", "isindex", "link", "meta", "param"));
-
-    public ToHTMLContentHandler(OutputStream stream, String encoding)
-            throws UnsupportedEncodingException {
-        super(stream, encoding);
-    }
-
-    public ToHTMLContentHandler() {
-        super();
-    }
-
-    @Override
-    public void startDocument() throws SAXException {
-    }
-
-    @Override
-    public void endElement(String uri, String localName, String qName)
-            throws SAXException {
-        if (inStartElement) {
-            write('>');
-            inStartElement = false;
-
-            if (EMPTY_ELEMENTS.contains(localName)) {
-                namespaces.clear();
-                return;
-            }
-        }
-
-        super.endElement(uri, localName, qName);
-    }
-
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.sax;
+
+import java.io.OutputStream;
+import java.io.UnsupportedEncodingException;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.xml.sax.SAXException;
+
+/**
+ * SAX event handler that serializes the HTML document to a character stream.
+ * The incoming SAX events are expected to be well-formed (properly nested,
+ * etc.) and valid HTML.
+ *
+ * @since Apache Tika 0.10
+ */
+public class ToHTMLContentHandler extends ToXMLContentHandler {
+
+    private static final Set<String> EMPTY_ELEMENTS =
+        new HashSet<String>(Arrays.asList(
+            "area", "base", "basefont", "br", "col", "frame", "hr",
+            "img", "input", "isindex", "link", "meta", "param"));
+
+    public ToHTMLContentHandler(OutputStream stream, String encoding)
+            throws UnsupportedEncodingException {
+        super(stream, encoding);
+    }
+
+    public ToHTMLContentHandler() {
+        super();
+    }
+
+    @Override
+    public void startDocument() throws SAXException {
+    }
+
+    @Override
+    public void endElement(String uri, String localName, String qName)
+            throws SAXException {
+        if (inStartElement) {
+            write('>');
+            inStartElement = false;
+
+            if (EMPTY_ELEMENTS.contains(localName)) {
+                namespaces.clear();
+                return;
+            }
+        }
+
+        super.endElement(uri, localName, qName);
+    }
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/sax/ToTextContentHandler.java b/tika-core/src/main/java/org/apache/tika/sax/ToTextContentHandler.java
index e4a4433e6..4fdeaf358 100755
--- a/tika-core/src/main/java/org/apache/tika/sax/ToTextContentHandler.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/ToTextContentHandler.java
@@ -1,140 +1,140 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.sax;
-
-import java.io.IOException;
-import java.io.OutputStream;
-import java.io.OutputStreamWriter;
-import java.io.StringWriter;
-import java.io.UnsupportedEncodingException;
-import java.io.Writer;
-import java.nio.charset.Charset;
-
-import org.xml.sax.SAXException;
-import org.xml.sax.helpers.DefaultHandler;
-
-/**
- * SAX event handler that writes all character content out to a character
- * stream. No escaping or other transformations are made on the character
- * content.
- *
- * @since Apache Tika 0.10
- */
-public class ToTextContentHandler extends DefaultHandler {
-
-    /**
-     * The character stream.
-     */
-    private final Writer writer;
-
-    /**
-     * Creates a content handler that writes character events to
-     * the given writer.
-     *
-     * @param writer writer
-     */
-    public ToTextContentHandler(Writer writer) {
-        this.writer = writer;
-    }
-
-    /**
-     * Creates a content handler that writes character events to
-     * the given output stream using the platform default encoding.
-     *
-     * @param stream output stream
-     */
-    public ToTextContentHandler(OutputStream stream) {
-        this(new OutputStreamWriter(stream, Charset.defaultCharset()));
-    }
-
-    /**
-     * Creates a content handler that writes character events to
-     * the given output stream using the given encoding.
-     *
-     * @param stream output stream
-     * @param encoding output encoding
-     * @throws UnsupportedEncodingException if the encoding is unsupported
-     */
-    public ToTextContentHandler(OutputStream stream, String encoding)
-            throws UnsupportedEncodingException {
-        this(new OutputStreamWriter(stream, encoding));
-    }
-
-    /**
-     * Creates a content handler that writes character events
-     * to an internal string buffer. Use the {@link #toString()}
-     * method to access the collected character content.
-     */
-    public ToTextContentHandler() {
-        this(new StringWriter());
-    }
-
-    /**
-     * Writes the given characters to the given character stream.
-     */
-    @Override
-    public void characters(char[] ch, int start, int length)
-            throws SAXException {
-        try {
-            writer.write(ch, start, length);
-        } catch (IOException e) {
-            throw new SAXException(
-                    "Error writing: " + new String(ch, start, length), e);
-        }
-    }
-
-
-    /**
-     * Writes the given ignorable characters to the given character stream.
-     * The default implementation simply forwards the call to the
-     * {@link #characters(char[], int, int)} method.
-     */
-    @Override
-    public void ignorableWhitespace(char[] ch, int start, int length)
-            throws SAXException {
-        characters(ch, start, length);
-    }
-
-    /**
-     * Flushes the character stream so that no characters are forgotten
-     * in internal buffers.
-     *
-     * @see <a href="https://issues.apache.org/jira/browse/TIKA-179">TIKA-179</a>
-     * @throws SAXException if the stream can not be flushed
-     */
-    @Override
-    public void endDocument() throws SAXException {
-        try {
-            writer.flush();
-        } catch (IOException e) {
-            throw new SAXException("Error flushing character output", e);
-        }
-    }
-
-    /**
-     * Returns the contents of the internal string buffer where
-     * all the received characters have been collected. Only works
-     * when this object was constructed using the empty default
-     * constructor or by passing a {@link StringWriter} to the
-     * other constructor.
-     */
-    @Override
-    public String toString() {
-        return writer.toString();
-    }
-
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.sax;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.io.OutputStreamWriter;
+import java.io.StringWriter;
+import java.io.UnsupportedEncodingException;
+import java.io.Writer;
+import java.nio.charset.Charset;
+
+import org.xml.sax.SAXException;
+import org.xml.sax.helpers.DefaultHandler;
+
+/**
+ * SAX event handler that writes all character content out to a character
+ * stream. No escaping or other transformations are made on the character
+ * content.
+ *
+ * @since Apache Tika 0.10
+ */
+public class ToTextContentHandler extends DefaultHandler {
+
+    /**
+     * The character stream.
+     */
+    private final Writer writer;
+
+    /**
+     * Creates a content handler that writes character events to
+     * the given writer.
+     *
+     * @param writer writer
+     */
+    public ToTextContentHandler(Writer writer) {
+        this.writer = writer;
+    }
+
+    /**
+     * Creates a content handler that writes character events to
+     * the given output stream using the platform default encoding.
+     *
+     * @param stream output stream
+     */
+    public ToTextContentHandler(OutputStream stream) {
+        this(new OutputStreamWriter(stream, Charset.defaultCharset()));
+    }
+
+    /**
+     * Creates a content handler that writes character events to
+     * the given output stream using the given encoding.
+     *
+     * @param stream output stream
+     * @param encoding output encoding
+     * @throws UnsupportedEncodingException if the encoding is unsupported
+     */
+    public ToTextContentHandler(OutputStream stream, String encoding)
+            throws UnsupportedEncodingException {
+        this(new OutputStreamWriter(stream, encoding));
+    }
+
+    /**
+     * Creates a content handler that writes character events
+     * to an internal string buffer. Use the {@link #toString()}
+     * method to access the collected character content.
+     */
+    public ToTextContentHandler() {
+        this(new StringWriter());
+    }
+
+    /**
+     * Writes the given characters to the given character stream.
+     */
+    @Override
+    public void characters(char[] ch, int start, int length)
+            throws SAXException {
+        try {
+            writer.write(ch, start, length);
+        } catch (IOException e) {
+            throw new SAXException(
+                    "Error writing: " + new String(ch, start, length), e);
+        }
+    }
+
+
+    /**
+     * Writes the given ignorable characters to the given character stream.
+     * The default implementation simply forwards the call to the
+     * {@link #characters(char[], int, int)} method.
+     */
+    @Override
+    public void ignorableWhitespace(char[] ch, int start, int length)
+            throws SAXException {
+        characters(ch, start, length);
+    }
+
+    /**
+     * Flushes the character stream so that no characters are forgotten
+     * in internal buffers.
+     *
+     * @see <a href="https://issues.apache.org/jira/browse/TIKA-179">TIKA-179</a>
+     * @throws SAXException if the stream can not be flushed
+     */
+    @Override
+    public void endDocument() throws SAXException {
+        try {
+            writer.flush();
+        } catch (IOException e) {
+            throw new SAXException("Error flushing character output", e);
+        }
+    }
+
+    /**
+     * Returns the contents of the internal string buffer where
+     * all the received characters have been collected. Only works
+     * when this object was constructed using the empty default
+     * constructor or by passing a {@link StringWriter} to the
+     * other constructor.
+     */
+    @Override
+    public String toString() {
+        return writer.toString();
+    }
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/sax/ToXMLContentHandler.java b/tika-core/src/main/java/org/apache/tika/sax/ToXMLContentHandler.java
index ae06da727..32352ea9c 100755
--- a/tika-core/src/main/java/org/apache/tika/sax/ToXMLContentHandler.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/ToXMLContentHandler.java
@@ -1,281 +1,281 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.sax;
-
-import java.io.OutputStream;
-import java.io.UnsupportedEncodingException;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.xml.sax.Attributes;
-import org.xml.sax.SAXException;
-
-/**
- * SAX event handler that serializes the XML document to a character stream.
- * The incoming SAX events are expected to be well-formed (properly nested,
- * etc.) and to explicitly include namespace declaration attributes and
- * corresponding namespace prefixes in element and attribute names.
- *
- * @since Apache Tika 0.10
- */
-public class ToXMLContentHandler extends ToTextContentHandler {
-
-    private static class ElementInfo {
-
-        private final ElementInfo parent;
-
-        private final Map<String, String> namespaces;
-
-        public ElementInfo(ElementInfo parent, Map<String, String> namespaces) {
-            this.parent = parent;
-            if (namespaces.isEmpty()) {
-                this.namespaces = Collections.emptyMap();
-            } else {
-                this.namespaces = new HashMap<String, String>(namespaces);
-            }
-        }
-
-        public String getPrefix(String uri) throws SAXException {
-            String prefix = namespaces.get(uri);
-            if (prefix != null) {
-                return prefix;
-            } else if (parent != null) {
-                return parent.getPrefix(uri);
-            } else if (uri == null || uri.length() == 0) {
-                return "";
-            } else {
-                throw new SAXException("Namespace " + uri + " not declared");
-            }
-        }
-
-        public String getQName(String uri, String localName)
-                throws SAXException {
-            String prefix = getPrefix(uri);
-            if (prefix.length() > 0) {
-                return prefix + ":" + localName;
-            } else {
-                return localName;
-            }
-        }
-
-    }
-
-    private final String encoding;
-
-    protected boolean inStartElement = false;
-
-    protected final Map<String, String> namespaces =
-        new HashMap<String, String>();
-
-    private ElementInfo currentElement;
-
-    /**
-     * Creates an XML serializer that writes to the given byte stream
-     * using the given character encoding.
-     *
-     * @param stream output stream
-     * @param encoding output encoding
-     * @throws UnsupportedEncodingException if the encoding is unsupported
-     */
-    public ToXMLContentHandler(OutputStream stream, String encoding)
-            throws UnsupportedEncodingException {
-        super(stream, encoding);
-        this.encoding = encoding;
-    }
-
-    public ToXMLContentHandler(String encoding) {
-        super();
-        this.encoding = encoding;
-    }
-
-    public ToXMLContentHandler() {
-        super();
-        this.encoding = null;
-    }
-
-    /**
-     * Writes the XML prefix.
-     */
-    @Override
-    public void startDocument() throws SAXException {
-        if (encoding != null) {
-            write("<?xml version=\"1.0\" encoding=\"");
-            write(encoding);
-            write("\"?>\n");
-        }
-
-        currentElement = null;
-        namespaces.clear();
-    }
-
-    @Override
-    public void startPrefixMapping(String prefix, String uri)
-            throws SAXException {
-        try {
-            if (currentElement != null
-                    && prefix.equals(currentElement.getPrefix(uri))) {
-                return;
-            }
-        } catch (SAXException ignore) {
-        }
-        namespaces.put(uri, prefix);
-    }
-
-    @Override
-    public void startElement(
-            String uri, String localName, String qName, Attributes atts)
-            throws SAXException {
-        lazyCloseStartElement();
-
-        currentElement = new ElementInfo(currentElement, namespaces);
-
-        write('<');
-        write(currentElement.getQName(uri, localName));
-
-        for (int i = 0; i < atts.getLength(); i++) {
-            write(' ');
-            write(currentElement.getQName(atts.getURI(i), atts.getLocalName(i)));
-            write('=');
-            write('"');
-            char[] ch = atts.getValue(i).toCharArray();
-            writeEscaped(ch, 0, ch.length, true);
-            write('"');
-        }
-
-        for (Map.Entry<String, String> entry : namespaces.entrySet()) {
-            write(' ');
-            write("xmlns");
-            String prefix = entry.getValue();
-            if (prefix.length() > 0) {
-                write(':');
-                write(prefix);
-            }
-            write('=');
-            write('"');
-            char[] ch = entry.getKey().toCharArray();
-            writeEscaped(ch, 0, ch.length, true);
-            write('"');
-        }
-        namespaces.clear();
-
-        inStartElement = true;
-    }
-
-    @Override
-    public void endElement(String uri, String localName, String qName)
-            throws SAXException {
-        if (inStartElement) {
-            write(" />");
-            inStartElement = false;
-        } else {
-            write("</");
-            write(qName);
-            write('>');
-        }
-
-        namespaces.clear();
-
-        // Reset the position in the tree, to avoid endless stack overflow
-        // chains (see TIKA-1070)
-        currentElement = currentElement.parent;
-    }
-
-    @Override
-    public void characters(char[] ch, int start, int length)
-            throws SAXException {
-        lazyCloseStartElement();
-        writeEscaped(ch, start, start + length, false);
-    }
-
-    private void lazyCloseStartElement() throws SAXException {
-        if (inStartElement) {
-            write('>');
-            inStartElement = false;
-        }
-    }
-
-    /**
-     * Writes the given character as-is.
-     *
-     * @param ch character to be written
-     * @throws SAXException if the character could not be written
-     */
-    protected void write(char ch) throws SAXException {
-        super.characters(new char[] { ch }, 0, 1);
-    }
-
-    /**
-     * Writes the given string of character as-is.
-     *
-     * @param string string of character to be written
-     * @throws SAXException if the character string could not be written
-     */
-    protected void write(String string) throws SAXException {
-        super.characters(string.toCharArray(), 0, string.length());
-    }
-
-    /**
-     * Writes the given characters as-is followed by the given entity.
-     *
-     * @param ch character array
-     * @param from start position in the array
-     * @param to end position in the array
-     * @param entity entity code
-     * @return next position in the array,
-     *         after the characters plus one entity
-     * @throws SAXException if the characters could not be written
-     */
-    private int writeCharsAndEntity(char[] ch, int from, int to, String entity)
-            throws SAXException {
-        super.characters(ch, from, to - from);
-        write('&');
-        write(entity);
-        write(';');
-        return to + 1;
-    }
-
-    /**
-     * Writes the given characters with XML meta characters escaped.
-     *
-     * @param ch character array
-     * @param from start position in the array
-     * @param to end position in the array
-     * @param attribute whether the characters should be escaped as
-     *                  an attribute value or normal character content
-     * @throws SAXException if the characters could not be written
-     */
-    private void writeEscaped(char[] ch, int from, int to, boolean attribute)
-            throws SAXException {
-        int pos = from;
-        while (pos < to) {
-            if (ch[pos] == '<') {
-                from = pos = writeCharsAndEntity(ch, from, pos, "lt");
-            } else if (ch[pos] == '>') {
-                from = pos = writeCharsAndEntity(ch, from, pos, "gt");
-            } else if (ch[pos] == '&') {
-                from = pos = writeCharsAndEntity(ch, from, pos, "amp");
-            } else if (attribute && ch[pos] == '"') {
-                from = pos = writeCharsAndEntity(ch, from, pos, "quot");
-            } else {
-                pos++;
-            }
-        }
-        super.characters(ch, from, to - from);
-    }
-
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.sax;
+
+import java.io.OutputStream;
+import java.io.UnsupportedEncodingException;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.xml.sax.Attributes;
+import org.xml.sax.SAXException;
+
+/**
+ * SAX event handler that serializes the XML document to a character stream.
+ * The incoming SAX events are expected to be well-formed (properly nested,
+ * etc.) and to explicitly include namespace declaration attributes and
+ * corresponding namespace prefixes in element and attribute names.
+ *
+ * @since Apache Tika 0.10
+ */
+public class ToXMLContentHandler extends ToTextContentHandler {
+
+    private static class ElementInfo {
+
+        private final ElementInfo parent;
+
+        private final Map<String, String> namespaces;
+
+        public ElementInfo(ElementInfo parent, Map<String, String> namespaces) {
+            this.parent = parent;
+            if (namespaces.isEmpty()) {
+                this.namespaces = Collections.emptyMap();
+            } else {
+                this.namespaces = new HashMap<String, String>(namespaces);
+            }
+        }
+
+        public String getPrefix(String uri) throws SAXException {
+            String prefix = namespaces.get(uri);
+            if (prefix != null) {
+                return prefix;
+            } else if (parent != null) {
+                return parent.getPrefix(uri);
+            } else if (uri == null || uri.length() == 0) {
+                return "";
+            } else {
+                throw new SAXException("Namespace " + uri + " not declared");
+            }
+        }
+
+        public String getQName(String uri, String localName)
+                throws SAXException {
+            String prefix = getPrefix(uri);
+            if (prefix.length() > 0) {
+                return prefix + ":" + localName;
+            } else {
+                return localName;
+            }
+        }
+
+    }
+
+    private final String encoding;
+
+    protected boolean inStartElement = false;
+
+    protected final Map<String, String> namespaces =
+        new HashMap<String, String>();
+
+    private ElementInfo currentElement;
+
+    /**
+     * Creates an XML serializer that writes to the given byte stream
+     * using the given character encoding.
+     *
+     * @param stream output stream
+     * @param encoding output encoding
+     * @throws UnsupportedEncodingException if the encoding is unsupported
+     */
+    public ToXMLContentHandler(OutputStream stream, String encoding)
+            throws UnsupportedEncodingException {
+        super(stream, encoding);
+        this.encoding = encoding;
+    }
+
+    public ToXMLContentHandler(String encoding) {
+        super();
+        this.encoding = encoding;
+    }
+
+    public ToXMLContentHandler() {
+        super();
+        this.encoding = null;
+    }
+
+    /**
+     * Writes the XML prefix.
+     */
+    @Override
+    public void startDocument() throws SAXException {
+        if (encoding != null) {
+            write("<?xml version=\"1.0\" encoding=\"");
+            write(encoding);
+            write("\"?>\n");
+        }
+
+        currentElement = null;
+        namespaces.clear();
+    }
+
+    @Override
+    public void startPrefixMapping(String prefix, String uri)
+            throws SAXException {
+        try {
+            if (currentElement != null
+                    && prefix.equals(currentElement.getPrefix(uri))) {
+                return;
+            }
+        } catch (SAXException ignore) {
+        }
+        namespaces.put(uri, prefix);
+    }
+
+    @Override
+    public void startElement(
+            String uri, String localName, String qName, Attributes atts)
+            throws SAXException {
+        lazyCloseStartElement();
+
+        currentElement = new ElementInfo(currentElement, namespaces);
+
+        write('<');
+        write(currentElement.getQName(uri, localName));
+
+        for (int i = 0; i < atts.getLength(); i++) {
+            write(' ');
+            write(currentElement.getQName(atts.getURI(i), atts.getLocalName(i)));
+            write('=');
+            write('"');
+            char[] ch = atts.getValue(i).toCharArray();
+            writeEscaped(ch, 0, ch.length, true);
+            write('"');
+        }
+
+        for (Map.Entry<String, String> entry : namespaces.entrySet()) {
+            write(' ');
+            write("xmlns");
+            String prefix = entry.getValue();
+            if (prefix.length() > 0) {
+                write(':');
+                write(prefix);
+            }
+            write('=');
+            write('"');
+            char[] ch = entry.getKey().toCharArray();
+            writeEscaped(ch, 0, ch.length, true);
+            write('"');
+        }
+        namespaces.clear();
+
+        inStartElement = true;
+    }
+
+    @Override
+    public void endElement(String uri, String localName, String qName)
+            throws SAXException {
+        if (inStartElement) {
+            write(" />");
+            inStartElement = false;
+        } else {
+            write("</");
+            write(qName);
+            write('>');
+        }
+
+        namespaces.clear();
+
+        // Reset the position in the tree, to avoid endless stack overflow
+        // chains (see TIKA-1070)
+        currentElement = currentElement.parent;
+    }
+
+    @Override
+    public void characters(char[] ch, int start, int length)
+            throws SAXException {
+        lazyCloseStartElement();
+        writeEscaped(ch, start, start + length, false);
+    }
+
+    private void lazyCloseStartElement() throws SAXException {
+        if (inStartElement) {
+            write('>');
+            inStartElement = false;
+        }
+    }
+
+    /**
+     * Writes the given character as-is.
+     *
+     * @param ch character to be written
+     * @throws SAXException if the character could not be written
+     */
+    protected void write(char ch) throws SAXException {
+        super.characters(new char[] { ch }, 0, 1);
+    }
+
+    /**
+     * Writes the given string of character as-is.
+     *
+     * @param string string of character to be written
+     * @throws SAXException if the character string could not be written
+     */
+    protected void write(String string) throws SAXException {
+        super.characters(string.toCharArray(), 0, string.length());
+    }
+
+    /**
+     * Writes the given characters as-is followed by the given entity.
+     *
+     * @param ch character array
+     * @param from start position in the array
+     * @param to end position in the array
+     * @param entity entity code
+     * @return next position in the array,
+     *         after the characters plus one entity
+     * @throws SAXException if the characters could not be written
+     */
+    private int writeCharsAndEntity(char[] ch, int from, int to, String entity)
+            throws SAXException {
+        super.characters(ch, from, to - from);
+        write('&');
+        write(entity);
+        write(';');
+        return to + 1;
+    }
+
+    /**
+     * Writes the given characters with XML meta characters escaped.
+     *
+     * @param ch character array
+     * @param from start position in the array
+     * @param to end position in the array
+     * @param attribute whether the characters should be escaped as
+     *                  an attribute value or normal character content
+     * @throws SAXException if the characters could not be written
+     */
+    private void writeEscaped(char[] ch, int from, int to, boolean attribute)
+            throws SAXException {
+        int pos = from;
+        while (pos < to) {
+            if (ch[pos] == '<') {
+                from = pos = writeCharsAndEntity(ch, from, pos, "lt");
+            } else if (ch[pos] == '>') {
+                from = pos = writeCharsAndEntity(ch, from, pos, "gt");
+            } else if (ch[pos] == '&') {
+                from = pos = writeCharsAndEntity(ch, from, pos, "amp");
+            } else if (attribute && ch[pos] == '"') {
+                from = pos = writeCharsAndEntity(ch, from, pos, "quot");
+            } else {
+                pos++;
+            }
+        }
+        super.characters(ch, from, to - from);
+    }
+
+}
diff --git a/tika-core/src/test/java/org/apache/tika/parser/mock/MockParser.java b/tika-core/src/test/java/org/apache/tika/parser/mock/MockParser.java
index 3ad5e1bca..f5c2bdccc 100644
--- a/tika-core/src/test/java/org/apache/tika/parser/mock/MockParser.java
+++ b/tika-core/src/test/java/org/apache/tika/parser/mock/MockParser.java
@@ -1,301 +1,301 @@
-package org.apache.tika.parser.mock;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-import javax.xml.parsers.DocumentBuilder;
-import javax.xml.parsers.DocumentBuilderFactory;
-import javax.xml.parsers.ParserConfigurationException;
-import java.io.IOException;
-import java.io.InputStream;
-import java.lang.reflect.Constructor;
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.parser.AbstractParser;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.sax.XHTMLContentHandler;
-import org.w3c.dom.Document;
-import org.w3c.dom.NamedNodeMap;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-
-/**
- * This class enables mocking of parser behavior for use in testing
- * wrappers and drivers of parsers.
- * <p>
- * See resources/test-documents/mock/example.xml in tika-parsers/test for the documentation
- * of all the options for this MockParser.
- * <p>
- * Tests for this class are in tika-parsers.
- * <p>
- * See also {@link org.apache.tika.parser.DummyParser} for another option.
- */
-
-public class MockParser extends AbstractParser {
-
-    private static final long serialVersionUID = 1L;
-
-    @Override
-    public Set<MediaType> getSupportedTypes(ParseContext context) {
-        Set<MediaType> types = new HashSet<MediaType>();
-        MediaType type = MediaType.application("mock+xml");
-        types.add(type);
-        return types;
-    }
-
-    @Override
-    public void parse(InputStream stream, ContentHandler handler,
-                      Metadata metadata, ParseContext context) throws IOException,
-            SAXException, TikaException {
-        Document doc = null;
-        DocumentBuilderFactory fact = DocumentBuilderFactory.newInstance();
-        DocumentBuilder docBuilder = null;
-        try {
-            docBuilder = fact.newDocumentBuilder();
-            doc = docBuilder.parse(stream);
-        } catch (ParserConfigurationException e) {
-            throw new IOException(e);
-        } catch (SAXException e) {
-            throw new IOException(e);
-        }
-        Node root = doc.getDocumentElement();
-        NodeList actions = root.getChildNodes();
-        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
-        xhtml.startDocument();
-        for (int i = 0; i < actions.getLength(); i++) {
-            executeAction(actions.item(i), metadata, xhtml);
-        }
-        xhtml.endDocument();
-    }
-
-    private void executeAction(Node action, Metadata metadata, XHTMLContentHandler xhtml) throws SAXException,
-            IOException, TikaException {
-
-        if (action.getNodeType() != 1) {
-            return;
-        }
-
-        String name = action.getNodeName();
-        if ("metadata".equals(name)) {
-            metadata(action, metadata);
-        } else if("write".equals(name)) {
-            write(action, xhtml);
-        } else if ("throw".equals(name)) {
-            throwIt(action);
-        } else if ("hang".equals(name)) {
-            hang(action);
-        } else if ("oom".equals(name)) {
-            kabOOM();
-        } else if ("print_out".equals(name) || "print_err".equals(name)){
-            print(action, name);
-        } else {
-            throw new IllegalArgumentException("Didn't recognize mock action: "+name);
-        }
-    }
-
-    private void print(Node action, String name) {
-        String content = action.getTextContent();
-        if ("print_out".equals(name)) {
-            System.out.println(content);
-        } else if ("print_err".equals(name)) {
-            System.err.println(content);
-        } else {
-            throw new IllegalArgumentException("must be print_out or print_err");
-        }
-    }
-    private void hang(Node action) {
-        boolean interruptible = true;
-        boolean heavy = false;
-        long millis = -1;
-        long pulseMillis = -1;
-        NamedNodeMap attrs = action.getAttributes();
-        Node iNode = attrs.getNamedItem("interruptible");
-        if (iNode != null) {
-            interruptible = ("true".equals(iNode.getNodeValue()));
-        }
-        Node hNode = attrs.getNamedItem("heavy");
-        if (hNode != null) {
-            heavy = ("true".equals(hNode.getNodeValue()));
-        }
-
-        Node mNode = attrs.getNamedItem("millis");
-        if (mNode == null) {
-            throw new RuntimeException("Must specify \"millis\" attribute for hang.");
-        }
-        String millisString = mNode.getNodeValue();
-        try {
-            millis = Long.parseLong(millisString);
-        } catch (NumberFormatException e) {
-            throw new RuntimeException("Value for \"millis\" attribute must be a long.");
-        }
-
-        if (heavy) {
-            Node pNode = attrs.getNamedItem("pulse_millis");
-            if (pNode == null) {
-                throw new RuntimeException("Must specify attribute \"pulse_millis\" if the hang is \"heavy\"");
-            }
-            String pulseMillisString = mNode.getNodeValue();
-            try {
-                pulseMillis = Long.parseLong(pulseMillisString);
-            } catch (NumberFormatException e) {
-                throw new RuntimeException("Value for \"millis\" attribute must be a long.");
-            }
-        }
-        if (heavy) {
-            hangHeavy(millis, pulseMillis, interruptible);
-        } else {
-            sleep(millis, interruptible);
-        }
-    }
-
-    private void throwIt(Node action) throws IOException,
-            SAXException, TikaException {
-        NamedNodeMap attrs = action.getAttributes();
-        String className = attrs.getNamedItem("class").getNodeValue();
-        String msg = action.getTextContent();
-        throwIt(className, msg);
-    }
-
-    private void metadata(Node action, Metadata metadata) {
-        NamedNodeMap attrs = action.getAttributes();
-        //throws npe unless there is a name
-        String name = attrs.getNamedItem("name").getNodeValue();
-        String value = action.getTextContent();
-        Node actionType = attrs.getNamedItem("action");
-        if (actionType == null) {
-            metadata.add(name, value);
-        } else {
-            if ("set".equals(actionType.getNodeValue())) {
-                metadata.set(name, value);
-            } else {
-                metadata.add(name, value);
-            }
-        }
-    }
-
-    private void write(Node action, XHTMLContentHandler xhtml) throws SAXException {
-        NamedNodeMap attrs = action.getAttributes();
-        Node eNode = attrs.getNamedItem("element");
-        String elementType = "p";
-        if (eNode != null) {
-            elementType = eNode.getTextContent();
-        }
-        String text = action.getTextContent();
-        xhtml.startElement(elementType);
-        xhtml.characters(text);
-        xhtml.endElement(elementType);
-    }
-
-
-    private void throwIt(String className, String msg) throws IOException,
-            SAXException, TikaException {
-        Throwable t = null;
-        if (msg == null || msg.equals("")) {
-            try {
-                t = (Throwable) Class.forName(className).newInstance();
-            } catch (Exception e) {
-                throw new RuntimeException("couldn't create throwable class:"+className, e);
-            }
-        } else {
-            try {
-                Class<?> clazz = Class.forName(className);
-                Constructor<?> con = clazz.getConstructor(String.class);
-                t = (Throwable) con.newInstance(msg);
-            } catch (Exception e) {
-                throw new RuntimeException("couldn't create throwable class:" + className, e);
-            }
-        }
-        if (t instanceof SAXException) {
-            throw (SAXException)t;
-        } else if (t instanceof IOException) {
-            throw (IOException) t;
-        } else if (t instanceof TikaException) {
-            throw (TikaException) t;
-        } else if (t instanceof Error) {
-            throw (Error) t;
-        } else if (t instanceof RuntimeException) {
-            throw (RuntimeException) t;
-        } else {
-            //wrap the throwable in a RuntimeException
-            throw new RuntimeException(t);
-        }
-    }
-
-    private void kabOOM() {
-        List<int[]> ints = new ArrayList<int[]>();
-
-        while (true) {
-            int[] intArr = new int[32000];
-            ints.add(intArr);
-        }
-    }
-
-    private void hangHeavy(long maxMillis, long pulseCheckMillis, boolean interruptible) {
-        //do some heavy computation and occasionally check for
-        //whether time has exceeded maxMillis (see TIKA-1132 for inspiration)
-        //or whether the thread was interrupted
-        long start = new Date().getTime();
-        int lastChecked = 0;
-        while (true) {
-            for (int i = 1; i < Integer.MAX_VALUE; i++) {
-                for (int j = 1; j < Integer.MAX_VALUE; j++) {
-                    double div = (double) i / (double) j;
-                    lastChecked++;
-                    if (lastChecked > pulseCheckMillis) {
-                        lastChecked = 0;
-                        if (interruptible && Thread.currentThread().isInterrupted()) {
-                            return;
-                        }
-                        long elapsed = new Date().getTime()-start;
-                        if (elapsed > maxMillis) {
-                            return;
-                        }
-                    }
-                }
-            }
-        }
-    }
-
-    private void sleep(long maxMillis, boolean isInterruptible) {
-        long start = new Date().getTime();
-        long millisRemaining = maxMillis;
-        while (true) {
-            try {
-                Thread.sleep(millisRemaining);
-            } catch (InterruptedException e) {
-                if (isInterruptible) {
-                    return;
-                }
-            }
-            long elapsed = new Date().getTime()-start;
-            millisRemaining = maxMillis - elapsed;
-            if (millisRemaining <= 0) {
-                break;
-            }
-        }
-    }
+package org.apache.tika.parser.mock;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+import javax.xml.parsers.DocumentBuilder;
+import javax.xml.parsers.DocumentBuilderFactory;
+import javax.xml.parsers.ParserConfigurationException;
+import java.io.IOException;
+import java.io.InputStream;
+import java.lang.reflect.Constructor;
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.w3c.dom.Document;
+import org.w3c.dom.NamedNodeMap;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * This class enables mocking of parser behavior for use in testing
+ * wrappers and drivers of parsers.
+ * <p>
+ * See resources/test-documents/mock/example.xml in tika-parsers/test for the documentation
+ * of all the options for this MockParser.
+ * <p>
+ * Tests for this class are in tika-parsers.
+ * <p>
+ * See also {@link org.apache.tika.parser.DummyParser} for another option.
+ */
+
+public class MockParser extends AbstractParser {
+
+    private static final long serialVersionUID = 1L;
+
+    @Override
+    public Set<MediaType> getSupportedTypes(ParseContext context) {
+        Set<MediaType> types = new HashSet<MediaType>();
+        MediaType type = MediaType.application("mock+xml");
+        types.add(type);
+        return types;
+    }
+
+    @Override
+    public void parse(InputStream stream, ContentHandler handler,
+                      Metadata metadata, ParseContext context) throws IOException,
+            SAXException, TikaException {
+        Document doc = null;
+        DocumentBuilderFactory fact = DocumentBuilderFactory.newInstance();
+        DocumentBuilder docBuilder = null;
+        try {
+            docBuilder = fact.newDocumentBuilder();
+            doc = docBuilder.parse(stream);
+        } catch (ParserConfigurationException e) {
+            throw new IOException(e);
+        } catch (SAXException e) {
+            throw new IOException(e);
+        }
+        Node root = doc.getDocumentElement();
+        NodeList actions = root.getChildNodes();
+        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
+        xhtml.startDocument();
+        for (int i = 0; i < actions.getLength(); i++) {
+            executeAction(actions.item(i), metadata, xhtml);
+        }
+        xhtml.endDocument();
+    }
+
+    private void executeAction(Node action, Metadata metadata, XHTMLContentHandler xhtml) throws SAXException,
+            IOException, TikaException {
+
+        if (action.getNodeType() != 1) {
+            return;
+        }
+
+        String name = action.getNodeName();
+        if ("metadata".equals(name)) {
+            metadata(action, metadata);
+        } else if("write".equals(name)) {
+            write(action, xhtml);
+        } else if ("throw".equals(name)) {
+            throwIt(action);
+        } else if ("hang".equals(name)) {
+            hang(action);
+        } else if ("oom".equals(name)) {
+            kabOOM();
+        } else if ("print_out".equals(name) || "print_err".equals(name)){
+            print(action, name);
+        } else {
+            throw new IllegalArgumentException("Didn't recognize mock action: "+name);
+        }
+    }
+
+    private void print(Node action, String name) {
+        String content = action.getTextContent();
+        if ("print_out".equals(name)) {
+            System.out.println(content);
+        } else if ("print_err".equals(name)) {
+            System.err.println(content);
+        } else {
+            throw new IllegalArgumentException("must be print_out or print_err");
+        }
+    }
+    private void hang(Node action) {
+        boolean interruptible = true;
+        boolean heavy = false;
+        long millis = -1;
+        long pulseMillis = -1;
+        NamedNodeMap attrs = action.getAttributes();
+        Node iNode = attrs.getNamedItem("interruptible");
+        if (iNode != null) {
+            interruptible = ("true".equals(iNode.getNodeValue()));
+        }
+        Node hNode = attrs.getNamedItem("heavy");
+        if (hNode != null) {
+            heavy = ("true".equals(hNode.getNodeValue()));
+        }
+
+        Node mNode = attrs.getNamedItem("millis");
+        if (mNode == null) {
+            throw new RuntimeException("Must specify \"millis\" attribute for hang.");
+        }
+        String millisString = mNode.getNodeValue();
+        try {
+            millis = Long.parseLong(millisString);
+        } catch (NumberFormatException e) {
+            throw new RuntimeException("Value for \"millis\" attribute must be a long.");
+        }
+
+        if (heavy) {
+            Node pNode = attrs.getNamedItem("pulse_millis");
+            if (pNode == null) {
+                throw new RuntimeException("Must specify attribute \"pulse_millis\" if the hang is \"heavy\"");
+            }
+            String pulseMillisString = mNode.getNodeValue();
+            try {
+                pulseMillis = Long.parseLong(pulseMillisString);
+            } catch (NumberFormatException e) {
+                throw new RuntimeException("Value for \"millis\" attribute must be a long.");
+            }
+        }
+        if (heavy) {
+            hangHeavy(millis, pulseMillis, interruptible);
+        } else {
+            sleep(millis, interruptible);
+        }
+    }
+
+    private void throwIt(Node action) throws IOException,
+            SAXException, TikaException {
+        NamedNodeMap attrs = action.getAttributes();
+        String className = attrs.getNamedItem("class").getNodeValue();
+        String msg = action.getTextContent();
+        throwIt(className, msg);
+    }
+
+    private void metadata(Node action, Metadata metadata) {
+        NamedNodeMap attrs = action.getAttributes();
+        //throws npe unless there is a name
+        String name = attrs.getNamedItem("name").getNodeValue();
+        String value = action.getTextContent();
+        Node actionType = attrs.getNamedItem("action");
+        if (actionType == null) {
+            metadata.add(name, value);
+        } else {
+            if ("set".equals(actionType.getNodeValue())) {
+                metadata.set(name, value);
+            } else {
+                metadata.add(name, value);
+            }
+        }
+    }
+
+    private void write(Node action, XHTMLContentHandler xhtml) throws SAXException {
+        NamedNodeMap attrs = action.getAttributes();
+        Node eNode = attrs.getNamedItem("element");
+        String elementType = "p";
+        if (eNode != null) {
+            elementType = eNode.getTextContent();
+        }
+        String text = action.getTextContent();
+        xhtml.startElement(elementType);
+        xhtml.characters(text);
+        xhtml.endElement(elementType);
+    }
+
+
+    private void throwIt(String className, String msg) throws IOException,
+            SAXException, TikaException {
+        Throwable t = null;
+        if (msg == null || msg.equals("")) {
+            try {
+                t = (Throwable) Class.forName(className).newInstance();
+            } catch (Exception e) {
+                throw new RuntimeException("couldn't create throwable class:"+className, e);
+            }
+        } else {
+            try {
+                Class<?> clazz = Class.forName(className);
+                Constructor<?> con = clazz.getConstructor(String.class);
+                t = (Throwable) con.newInstance(msg);
+            } catch (Exception e) {
+                throw new RuntimeException("couldn't create throwable class:" + className, e);
+            }
+        }
+        if (t instanceof SAXException) {
+            throw (SAXException)t;
+        } else if (t instanceof IOException) {
+            throw (IOException) t;
+        } else if (t instanceof TikaException) {
+            throw (TikaException) t;
+        } else if (t instanceof Error) {
+            throw (Error) t;
+        } else if (t instanceof RuntimeException) {
+            throw (RuntimeException) t;
+        } else {
+            //wrap the throwable in a RuntimeException
+            throw new RuntimeException(t);
+        }
+    }
+
+    private void kabOOM() {
+        List<int[]> ints = new ArrayList<int[]>();
+
+        while (true) {
+            int[] intArr = new int[32000];
+            ints.add(intArr);
+        }
+    }
+
+    private void hangHeavy(long maxMillis, long pulseCheckMillis, boolean interruptible) {
+        //do some heavy computation and occasionally check for
+        //whether time has exceeded maxMillis (see TIKA-1132 for inspiration)
+        //or whether the thread was interrupted
+        long start = new Date().getTime();
+        int lastChecked = 0;
+        while (true) {
+            for (int i = 1; i < Integer.MAX_VALUE; i++) {
+                for (int j = 1; j < Integer.MAX_VALUE; j++) {
+                    double div = (double) i / (double) j;
+                    lastChecked++;
+                    if (lastChecked > pulseCheckMillis) {
+                        lastChecked = 0;
+                        if (interruptible && Thread.currentThread().isInterrupted()) {
+                            return;
+                        }
+                        long elapsed = new Date().getTime()-start;
+                        if (elapsed > maxMillis) {
+                            return;
+                        }
+                    }
+                }
+            }
+        }
+    }
+
+    private void sleep(long maxMillis, boolean isInterruptible) {
+        long start = new Date().getTime();
+        long millisRemaining = maxMillis;
+        while (true) {
+            try {
+                Thread.sleep(millisRemaining);
+            } catch (InterruptedException e) {
+                if (isInterruptible) {
+                    return;
+                }
+            }
+            long elapsed = new Date().getTime()-start;
+            millisRemaining = maxMillis - elapsed;
+            if (millisRemaining <= 0) {
+                break;
+            }
+        }
+    }
 }
\ No newline at end of file
diff --git a/tika-core/src/test/java/org/apache/tika/sax/SerializerTest.java b/tika-core/src/test/java/org/apache/tika/sax/SerializerTest.java
index 1abbbd891..ac39b0dcf 100755
--- a/tika-core/src/test/java/org/apache/tika/sax/SerializerTest.java
+++ b/tika-core/src/test/java/org/apache/tika/sax/SerializerTest.java
@@ -1,150 +1,150 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.sax;
-
-import static org.junit.Assert.assertEquals;
-import org.junit.Test;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.helpers.AttributesImpl;
-
-public class SerializerTest {
-
-    @Test
-    public void testToTextContentHandler() throws Exception {
-        assertStartDocument("", new ToTextContentHandler());
-        assertCharacters("content", new ToTextContentHandler());
-        assertCharacterEscaping("<&\">", new ToTextContentHandler());
-        assertIgnorableWhitespace(" \t\r\n", new ToTextContentHandler());
-        assertEmptyElement("", new ToTextContentHandler());
-        assertEmptyElementWithAttributes("", new ToTextContentHandler());
-        assertEmptyElementWithAttributeEscaping("", new ToTextContentHandler());
-        assertElement("content", new ToTextContentHandler());
-        assertElementWithAttributes("content", new ToTextContentHandler());
-    }
-
-    @Test
-    public void testToXMLContentHandler() throws Exception {
-        assertStartDocument("", new ToXMLContentHandler());
-        assertStartDocument(
-                "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
-                new ToXMLContentHandler("UTF-8"));
-        assertCharacters("content", new ToXMLContentHandler());
-        assertCharacterEscaping("&lt;&amp;\"&gt;", new ToXMLContentHandler());
-        assertIgnorableWhitespace(" \t\r\n", new ToXMLContentHandler());
-        assertEmptyElement("<br />", new ToXMLContentHandler());
-        assertEmptyElementWithAttributes(
-                "<meta name=\"foo\" value=\"bar\" />",
-                new ToXMLContentHandler());
-        assertEmptyElementWithAttributeEscaping(
-                "<p class=\"&lt;&amp;&quot;&gt;\" />",
-                new ToXMLContentHandler());
-        assertElement("<p>content</p>", new ToXMLContentHandler());
-        assertElementWithAttributes(
-                "<p class=\"test\">content</p>",
-                new ToXMLContentHandler());
-    }
-
-    @Test
-    public void testToHTMLContentHandler() throws Exception {
-        assertStartDocument("", new ToHTMLContentHandler());
-        assertCharacters("content", new ToHTMLContentHandler());
-        assertCharacterEscaping("&lt;&amp;\"&gt;", new ToHTMLContentHandler());
-        assertIgnorableWhitespace(" \t\r\n", new ToHTMLContentHandler());
-        assertEmptyElement("<br>", new ToHTMLContentHandler());
-        assertEmptyElementWithAttributes(
-                "<meta name=\"foo\" value=\"bar\">",
-                new ToHTMLContentHandler());
-        assertEmptyElementWithAttributeEscaping(
-                "<p class=\"&lt;&amp;&quot;&gt;\"></p>",
-                new ToHTMLContentHandler());
-        assertElement("<p>content</p>", new ToHTMLContentHandler());
-        assertElementWithAttributes(
-                "<p class=\"test\">content</p>",
-                new ToHTMLContentHandler());
-    }
-
-    private void assertStartDocument(String expected, ContentHandler handler)
-            throws Exception {
-        handler.startDocument();
-        assertEquals(expected, handler.toString());
-    }
-
-    private void assertCharacters(String expected, ContentHandler handler)
-            throws Exception {
-        handler.characters("content".toCharArray(), 0, 7);
-        assertEquals(expected, handler.toString());
-    }
-
-    private void assertCharacterEscaping(
-            String expected, ContentHandler handler) throws Exception {
-        handler.characters("<&\">".toCharArray(), 0, 4);
-        assertEquals(expected, handler.toString());
-    }
-
-    private void assertIgnorableWhitespace(
-            String expected, ContentHandler handler) throws Exception {
-        handler.ignorableWhitespace(" \t\r\n".toCharArray(), 0, 4);
-        assertEquals(expected, handler.toString());
-    }
-
-    private void assertEmptyElement(String expected, ContentHandler handler)
-            throws Exception {
-        AttributesImpl attributes = new AttributesImpl();
-        handler.startElement("", "br", "br", attributes);
-        handler.endElement("", "br", "br");
-        assertEquals(expected, handler.toString());
-    }
-
-    private void assertEmptyElementWithAttributes(
-            String expected, ContentHandler handler) throws Exception {
-        AttributesImpl attributes = new AttributesImpl();
-        attributes.addAttribute("", "name", "name", "CDATA", "foo");
-        attributes.addAttribute("", "value", "value", "CDATA", "bar");
-        handler.startElement("", "meta", "meta", attributes);
-        handler.endElement("", "meta", "meta");
-        assertEquals(expected, handler.toString());
-    }
-
-    private void assertEmptyElementWithAttributeEscaping(
-            String expected, ContentHandler handler) throws Exception {
-        AttributesImpl attributes = new AttributesImpl();
-        attributes.addAttribute("", "class", "class", "CDATA", "<&\">");
-        handler.startElement("", "p", "p", attributes);
-        handler.endElement("", "p", "p");
-        assertEquals(expected, handler.toString());
-    }
-
-    private void assertElement(
-            String expected, ContentHandler handler) throws Exception {
-        AttributesImpl attributes = new AttributesImpl();
-        handler.startElement("", "p", "p", attributes);
-        handler.characters("content".toCharArray(), 0, 7);
-        handler.endElement("", "p", "p");
-        assertEquals(expected, handler.toString());
-    }
-
-    private void assertElementWithAttributes(
-            String expected, ContentHandler handler) throws Exception {
-        AttributesImpl attributes = new AttributesImpl();
-        attributes.addAttribute("", "class", "class", "CDATA", "test");
-        handler.startElement("", "p", "p", attributes);
-        handler.characters("content".toCharArray(), 0, 7);
-        handler.endElement("", "p", "p");
-        assertEquals(expected, handler.toString());
-    }
-
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.sax;
+
+import static org.junit.Assert.assertEquals;
+import org.junit.Test;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.helpers.AttributesImpl;
+
+public class SerializerTest {
+
+    @Test
+    public void testToTextContentHandler() throws Exception {
+        assertStartDocument("", new ToTextContentHandler());
+        assertCharacters("content", new ToTextContentHandler());
+        assertCharacterEscaping("<&\">", new ToTextContentHandler());
+        assertIgnorableWhitespace(" \t\r\n", new ToTextContentHandler());
+        assertEmptyElement("", new ToTextContentHandler());
+        assertEmptyElementWithAttributes("", new ToTextContentHandler());
+        assertEmptyElementWithAttributeEscaping("", new ToTextContentHandler());
+        assertElement("content", new ToTextContentHandler());
+        assertElementWithAttributes("content", new ToTextContentHandler());
+    }
+
+    @Test
+    public void testToXMLContentHandler() throws Exception {
+        assertStartDocument("", new ToXMLContentHandler());
+        assertStartDocument(
+                "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
+                new ToXMLContentHandler("UTF-8"));
+        assertCharacters("content", new ToXMLContentHandler());
+        assertCharacterEscaping("&lt;&amp;\"&gt;", new ToXMLContentHandler());
+        assertIgnorableWhitespace(" \t\r\n", new ToXMLContentHandler());
+        assertEmptyElement("<br />", new ToXMLContentHandler());
+        assertEmptyElementWithAttributes(
+                "<meta name=\"foo\" value=\"bar\" />",
+                new ToXMLContentHandler());
+        assertEmptyElementWithAttributeEscaping(
+                "<p class=\"&lt;&amp;&quot;&gt;\" />",
+                new ToXMLContentHandler());
+        assertElement("<p>content</p>", new ToXMLContentHandler());
+        assertElementWithAttributes(
+                "<p class=\"test\">content</p>",
+                new ToXMLContentHandler());
+    }
+
+    @Test
+    public void testToHTMLContentHandler() throws Exception {
+        assertStartDocument("", new ToHTMLContentHandler());
+        assertCharacters("content", new ToHTMLContentHandler());
+        assertCharacterEscaping("&lt;&amp;\"&gt;", new ToHTMLContentHandler());
+        assertIgnorableWhitespace(" \t\r\n", new ToHTMLContentHandler());
+        assertEmptyElement("<br>", new ToHTMLContentHandler());
+        assertEmptyElementWithAttributes(
+                "<meta name=\"foo\" value=\"bar\">",
+                new ToHTMLContentHandler());
+        assertEmptyElementWithAttributeEscaping(
+                "<p class=\"&lt;&amp;&quot;&gt;\"></p>",
+                new ToHTMLContentHandler());
+        assertElement("<p>content</p>", new ToHTMLContentHandler());
+        assertElementWithAttributes(
+                "<p class=\"test\">content</p>",
+                new ToHTMLContentHandler());
+    }
+
+    private void assertStartDocument(String expected, ContentHandler handler)
+            throws Exception {
+        handler.startDocument();
+        assertEquals(expected, handler.toString());
+    }
+
+    private void assertCharacters(String expected, ContentHandler handler)
+            throws Exception {
+        handler.characters("content".toCharArray(), 0, 7);
+        assertEquals(expected, handler.toString());
+    }
+
+    private void assertCharacterEscaping(
+            String expected, ContentHandler handler) throws Exception {
+        handler.characters("<&\">".toCharArray(), 0, 4);
+        assertEquals(expected, handler.toString());
+    }
+
+    private void assertIgnorableWhitespace(
+            String expected, ContentHandler handler) throws Exception {
+        handler.ignorableWhitespace(" \t\r\n".toCharArray(), 0, 4);
+        assertEquals(expected, handler.toString());
+    }
+
+    private void assertEmptyElement(String expected, ContentHandler handler)
+            throws Exception {
+        AttributesImpl attributes = new AttributesImpl();
+        handler.startElement("", "br", "br", attributes);
+        handler.endElement("", "br", "br");
+        assertEquals(expected, handler.toString());
+    }
+
+    private void assertEmptyElementWithAttributes(
+            String expected, ContentHandler handler) throws Exception {
+        AttributesImpl attributes = new AttributesImpl();
+        attributes.addAttribute("", "name", "name", "CDATA", "foo");
+        attributes.addAttribute("", "value", "value", "CDATA", "bar");
+        handler.startElement("", "meta", "meta", attributes);
+        handler.endElement("", "meta", "meta");
+        assertEquals(expected, handler.toString());
+    }
+
+    private void assertEmptyElementWithAttributeEscaping(
+            String expected, ContentHandler handler) throws Exception {
+        AttributesImpl attributes = new AttributesImpl();
+        attributes.addAttribute("", "class", "class", "CDATA", "<&\">");
+        handler.startElement("", "p", "p", attributes);
+        handler.endElement("", "p", "p");
+        assertEquals(expected, handler.toString());
+    }
+
+    private void assertElement(
+            String expected, ContentHandler handler) throws Exception {
+        AttributesImpl attributes = new AttributesImpl();
+        handler.startElement("", "p", "p", attributes);
+        handler.characters("content".toCharArray(), 0, 7);
+        handler.endElement("", "p", "p");
+        assertEquals(expected, handler.toString());
+    }
+
+    private void assertElementWithAttributes(
+            String expected, ContentHandler handler) throws Exception {
+        AttributesImpl attributes = new AttributesImpl();
+        attributes.addAttribute("", "class", "class", "CDATA", "test");
+        handler.startElement("", "p", "p", attributes);
+        handler.characters("content".toCharArray(), 0, 7);
+        handler.endElement("", "p", "p");
+        assertEquals(expected, handler.toString());
+    }
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/DescribeMetadata.java b/tika-example/src/main/java/org/apache/tika/example/DescribeMetadata.java
index ca871624d..856260b49 100755
--- a/tika-example/src/main/java/org/apache/tika/example/DescribeMetadata.java
+++ b/tika-example/src/main/java/org/apache/tika/example/DescribeMetadata.java
@@ -1,30 +1,30 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import org.apache.tika.cli.TikaCLI;
-
-/**
- *
- * Print the supported Tika Metadata models and their fields.
- *
- */
-public class DescribeMetadata {
-
-	public static void main(String[] args) throws Exception {
-		TikaCLI.main(new String[] { "--list-met-models" });
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import org.apache.tika.cli.TikaCLI;
+
+/**
+ *
+ * Print the supported Tika Metadata models and their fields.
+ *
+ */
+public class DescribeMetadata {
+
+	public static void main(String[] args) throws Exception {
+		TikaCLI.main(new String[] { "--list-met-models" });
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/DirListParser.java b/tika-example/src/main/java/org/apache/tika/example/DirListParser.java
index 9f6cb0019..f4d809137 100755
--- a/tika-example/src/main/java/org/apache/tika/example/DirListParser.java
+++ b/tika-example/src/main/java/org/apache/tika/example/DirListParser.java
@@ -1,139 +1,139 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.Arrays;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.io.TikaInputStream;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.sax.BodyContentHandler;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-
-/**
- * Parses the output of /bin/ls and counts the number of files and the number of
- * executables using Tika.
- */
-public class DirListParser implements Parser {
-
-	private static final long serialVersionUID = 2717930544410610735L;
-
-	private static Set<MediaType> SUPPORTED_TYPES = new HashSet<MediaType>(
-			Arrays.asList(MediaType.TEXT_PLAIN));
-
-	/*
-	 * (non-Javadoc)
-	 * 
-	 * @see org.apache.tika.parser.Parser#getSupportedTypes(
-	 * org.apache.tika.parser.ParseContext)
-	 */
-	public Set<MediaType> getSupportedTypes(ParseContext context) {
-		return SUPPORTED_TYPES;
-	}
-
-	/*
-	 * (non-Javadoc)
-	 * 
-	 * @see org.apache.tika.parser.Parser#parse(java.io.InputStream,
-	 * org.xml.sax.ContentHandler, org.apache.tika.metadata.Metadata)
-	 */
-	public void parse(InputStream is, ContentHandler handler, Metadata metadata)
-			throws IOException, SAXException, TikaException {
-		this.parse(is, handler, metadata, new ParseContext());
-	}
-
-	/*
-	 * (non-Javadoc)
-	 * 
-	 * @see org.apache.tika.parser.Parser#parse(java.io.InputStream,
-	 * org.xml.sax.ContentHandler, org.apache.tika.metadata.Metadata,
-	 * org.apache.tika.parser.ParseContext)
-	 */
-	public void parse(InputStream is, ContentHandler handler,
-			Metadata metadata, ParseContext context) throws IOException,
-			SAXException, TikaException {
-
-		List<String> lines = FileUtils.readLines(TikaInputStream.get(is)
-				.getFile());
-		for (String line : lines) {
-			String[] fileToks = line.split("\\s+");
-			if (fileToks.length < 8)
-				continue;
-			String filePermissions = fileToks[0];
-			String numHardLinks = fileToks[1];
-			String fileOwner = fileToks[2];
-			String fileOwnerGroup = fileToks[3];
-			String fileSize = fileToks[4];
-			StringBuffer lastModDate = new StringBuffer();
-			lastModDate.append(fileToks[5]);
-			lastModDate.append(" ");
-			lastModDate.append(fileToks[6]);
-			lastModDate.append(" ");
-			lastModDate.append(fileToks[7]);
-			StringBuffer fileName = new StringBuffer();
-			for (int i = 8; i < fileToks.length; i++) {
-				fileName.append(fileToks[i]);
-				fileName.append(" ");
-			}
-			fileName.deleteCharAt(fileName.length() - 1);
-			this.addMetadata(metadata, filePermissions, numHardLinks,
-					fileOwner, fileOwnerGroup, fileSize,
-					lastModDate.toString(), fileName.toString());
-		}
-	}
-
-	public static void main(String[] args) throws IOException, SAXException,
-			TikaException {
-		DirListParser parser = new DirListParser();
-		Metadata met = new Metadata();
-		parser.parse(System.in, new BodyContentHandler(), met);
-
-		System.out.println("Num files: " + met.getValues("Filename").length);
-		System.out.println("Num executables: " + met.get("NumExecutables"));
-	}
-
-	private void addMetadata(Metadata metadata, String filePerms,
-			String numHardLinks, String fileOwner, String fileOwnerGroup,
-			String fileSize, String lastModDate, String fileName) {
-		metadata.add("FilePermissions", filePerms);
-		metadata.add("NumHardLinks", numHardLinks);
-		metadata.add("FileOwner", fileOwner);
-		metadata.add("FileOwnerGroup", fileOwnerGroup);
-		metadata.add("FileSize", fileSize);
-		metadata.add("LastModifiedDate", lastModDate);
-		metadata.add("Filename", fileName);
-
-		if (filePerms.indexOf("x") != -1 && filePerms.indexOf("d") == -1) {
-			if (metadata.get("NumExecutables") != null) {
-				int numExecs = Integer.valueOf(metadata.get("NumExecutables"));
-				numExecs++;
-				metadata.set("NumExecutables", String.valueOf(numExecs));
-			} else {
-				metadata.set("NumExecutables", "1");
-			}
-		}
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.io.TikaInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * Parses the output of /bin/ls and counts the number of files and the number of
+ * executables using Tika.
+ */
+public class DirListParser implements Parser {
+
+	private static final long serialVersionUID = 2717930544410610735L;
+
+	private static Set<MediaType> SUPPORTED_TYPES = new HashSet<MediaType>(
+			Arrays.asList(MediaType.TEXT_PLAIN));
+
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see org.apache.tika.parser.Parser#getSupportedTypes(
+	 * org.apache.tika.parser.ParseContext)
+	 */
+	public Set<MediaType> getSupportedTypes(ParseContext context) {
+		return SUPPORTED_TYPES;
+	}
+
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see org.apache.tika.parser.Parser#parse(java.io.InputStream,
+	 * org.xml.sax.ContentHandler, org.apache.tika.metadata.Metadata)
+	 */
+	public void parse(InputStream is, ContentHandler handler, Metadata metadata)
+			throws IOException, SAXException, TikaException {
+		this.parse(is, handler, metadata, new ParseContext());
+	}
+
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see org.apache.tika.parser.Parser#parse(java.io.InputStream,
+	 * org.xml.sax.ContentHandler, org.apache.tika.metadata.Metadata,
+	 * org.apache.tika.parser.ParseContext)
+	 */
+	public void parse(InputStream is, ContentHandler handler,
+			Metadata metadata, ParseContext context) throws IOException,
+			SAXException, TikaException {
+
+		List<String> lines = FileUtils.readLines(TikaInputStream.get(is)
+				.getFile());
+		for (String line : lines) {
+			String[] fileToks = line.split("\\s+");
+			if (fileToks.length < 8)
+				continue;
+			String filePermissions = fileToks[0];
+			String numHardLinks = fileToks[1];
+			String fileOwner = fileToks[2];
+			String fileOwnerGroup = fileToks[3];
+			String fileSize = fileToks[4];
+			StringBuffer lastModDate = new StringBuffer();
+			lastModDate.append(fileToks[5]);
+			lastModDate.append(" ");
+			lastModDate.append(fileToks[6]);
+			lastModDate.append(" ");
+			lastModDate.append(fileToks[7]);
+			StringBuffer fileName = new StringBuffer();
+			for (int i = 8; i < fileToks.length; i++) {
+				fileName.append(fileToks[i]);
+				fileName.append(" ");
+			}
+			fileName.deleteCharAt(fileName.length() - 1);
+			this.addMetadata(metadata, filePermissions, numHardLinks,
+					fileOwner, fileOwnerGroup, fileSize,
+					lastModDate.toString(), fileName.toString());
+		}
+	}
+
+	public static void main(String[] args) throws IOException, SAXException,
+			TikaException {
+		DirListParser parser = new DirListParser();
+		Metadata met = new Metadata();
+		parser.parse(System.in, new BodyContentHandler(), met);
+
+		System.out.println("Num files: " + met.getValues("Filename").length);
+		System.out.println("Num executables: " + met.get("NumExecutables"));
+	}
+
+	private void addMetadata(Metadata metadata, String filePerms,
+			String numHardLinks, String fileOwner, String fileOwnerGroup,
+			String fileSize, String lastModDate, String fileName) {
+		metadata.add("FilePermissions", filePerms);
+		metadata.add("NumHardLinks", numHardLinks);
+		metadata.add("FileOwner", fileOwner);
+		metadata.add("FileOwnerGroup", fileOwnerGroup);
+		metadata.add("FileSize", fileSize);
+		metadata.add("LastModifiedDate", lastModDate);
+		metadata.add("Filename", fileName);
+
+		if (filePerms.indexOf("x") != -1 && filePerms.indexOf("d") == -1) {
+			if (metadata.get("NumExecutables") != null) {
+				int numExecs = Integer.valueOf(metadata.get("NumExecutables"));
+				numExecs++;
+				metadata.set("NumExecutables", String.valueOf(numExecs));
+			} else {
+				metadata.set("NumExecutables", "1");
+			}
+		}
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/DisplayMetInstance.java b/tika-example/src/main/java/org/apache/tika/example/DisplayMetInstance.java
index 3a155be2e..3012add23 100755
--- a/tika-example/src/main/java/org/apache/tika/example/DisplayMetInstance.java
+++ b/tika-example/src/main/java/org/apache/tika/example/DisplayMetInstance.java
@@ -1,46 +1,46 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.IOException;
-import java.net.URL;
-
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.pdf.PDFParser;
-import org.apache.tika.sax.BodyContentHandler;
-import org.xml.sax.SAXException;
-
-/**
- * Grabs a PDF file from a URL and prints its {@link Metadata}
- */
-public class DisplayMetInstance {
-
-	public static Metadata getMet(URL url) throws IOException, SAXException,
-			TikaException {
-		Metadata met = new Metadata();
-		PDFParser parser = new PDFParser();
-		parser.parse(url.openStream(), new BodyContentHandler(), met,
-				new ParseContext());
-		return met;
-	}
-
-	public static void main(String[] args) throws Exception {
-		Metadata met = DisplayMetInstance.getMet(new URL(args[0]));
-		System.out.println(met);
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.IOException;
+import java.net.URL;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.pdf.PDFParser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * Grabs a PDF file from a URL and prints its {@link Metadata}
+ */
+public class DisplayMetInstance {
+
+	public static Metadata getMet(URL url) throws IOException, SAXException,
+			TikaException {
+		Metadata met = new Metadata();
+		PDFParser parser = new PDFParser();
+		parser.parse(url.openStream(), new BodyContentHandler(), met,
+				new ParseContext());
+		return met;
+	}
+
+	public static void main(String[] args) throws Exception {
+		Metadata met = DisplayMetInstance.getMet(new URL(args[0]));
+		System.out.println(met);
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/EncryptedPrescriptionDetector.java b/tika-example/src/main/java/org/apache/tika/example/EncryptedPrescriptionDetector.java
index b19097b3a..762c07745 100755
--- a/tika-example/src/main/java/org/apache/tika/example/EncryptedPrescriptionDetector.java
+++ b/tika-example/src/main/java/org/apache/tika/example/EncryptedPrescriptionDetector.java
@@ -1,62 +1,62 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.security.GeneralSecurityException;
-import java.security.Key;
-
-import javax.crypto.Cipher;
-import javax.crypto.CipherInputStream;
-import javax.xml.namespace.QName;
-
-import org.apache.tika.detect.Detector;
-import org.apache.tika.detect.XmlRootExtractor;
-import org.apache.tika.io.LookaheadInputStream;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-
-public class EncryptedPrescriptionDetector implements Detector {
-
-	private static final long serialVersionUID = -1709652690773421147L;
-
-	public MediaType detect(InputStream stream, Metadata metadata)
-			throws IOException {
-		Key key = Pharmacy.getKey();
-		MediaType type = MediaType.OCTET_STREAM;
-
-		InputStream lookahead = new LookaheadInputStream(stream, 1024);
-		try {
-			Cipher cipher = Cipher.getInstance("RSA");
-
-			cipher.init(Cipher.DECRYPT_MODE, key);
-			InputStream decrypted = new CipherInputStream(lookahead, cipher);
-
-			QName name = new XmlRootExtractor().extractRootElement(decrypted);
-			if (name != null
-					&& "http://example.com/xpd".equals(name.getNamespaceURI())
-					&& "prescription".equals(name.getLocalPart())) {
-				type = MediaType.application("x-prescription");
-			}
-		} catch (GeneralSecurityException e) {
-			// unable to decrypt, fall through
-		} finally {
-			lookahead.close();
-		}
-		return type;
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.security.GeneralSecurityException;
+import java.security.Key;
+
+import javax.crypto.Cipher;
+import javax.crypto.CipherInputStream;
+import javax.xml.namespace.QName;
+
+import org.apache.tika.detect.Detector;
+import org.apache.tika.detect.XmlRootExtractor;
+import org.apache.tika.io.LookaheadInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+
+public class EncryptedPrescriptionDetector implements Detector {
+
+	private static final long serialVersionUID = -1709652690773421147L;
+
+	public MediaType detect(InputStream stream, Metadata metadata)
+			throws IOException {
+		Key key = Pharmacy.getKey();
+		MediaType type = MediaType.OCTET_STREAM;
+
+		InputStream lookahead = new LookaheadInputStream(stream, 1024);
+		try {
+			Cipher cipher = Cipher.getInstance("RSA");
+
+			cipher.init(Cipher.DECRYPT_MODE, key);
+			InputStream decrypted = new CipherInputStream(lookahead, cipher);
+
+			QName name = new XmlRootExtractor().extractRootElement(decrypted);
+			if (name != null
+					&& "http://example.com/xpd".equals(name.getNamespaceURI())
+					&& "prescription".equals(name.getLocalPart())) {
+				type = MediaType.application("x-prescription");
+			}
+		} catch (GeneralSecurityException e) {
+			// unable to decrypt, fall through
+		} finally {
+			lookahead.close();
+		}
+		return type;
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/EncryptedPrescriptionParser.java b/tika-example/src/main/java/org/apache/tika/example/EncryptedPrescriptionParser.java
index 56685f5d0..3e7d6513a 100755
--- a/tika-example/src/main/java/org/apache/tika/example/EncryptedPrescriptionParser.java
+++ b/tika-example/src/main/java/org/apache/tika/example/EncryptedPrescriptionParser.java
@@ -1,60 +1,60 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.security.GeneralSecurityException;
-import java.security.Key;
-import java.util.Collections;
-import java.util.Set;
-
-import javax.crypto.Cipher;
-import javax.crypto.CipherInputStream;
-
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.parser.AbstractParser;
-import org.apache.tika.parser.ParseContext;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-
-public class EncryptedPrescriptionParser extends AbstractParser {
-
-	private static final long serialVersionUID = -7816987249611278541L;
-
-	public void parse(InputStream stream, ContentHandler handler,
-			Metadata metadata, ParseContext context) throws IOException,
-			SAXException, TikaException {
-		try {
-			Key key = Pharmacy.getKey();
-			Cipher cipher = Cipher.getInstance("RSA");
-			cipher.init(Cipher.DECRYPT_MODE, key);
-			InputStream decrypted = new CipherInputStream(stream, cipher);
-
-			new PrescriptionParser().parse(decrypted, handler, metadata,
-					context);
-		} catch (GeneralSecurityException e) {
-			throw new TikaException("Unable to decrypt a digital prescription",
-					e);
-		}
-	}
-
-	public Set<MediaType> getSupportedTypes(ParseContext context) {
-		return Collections.singleton(MediaType.application("x-prescription"));
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.security.GeneralSecurityException;
+import java.security.Key;
+import java.util.Collections;
+import java.util.Set;
+
+import javax.crypto.Cipher;
+import javax.crypto.CipherInputStream;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.ParseContext;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+public class EncryptedPrescriptionParser extends AbstractParser {
+
+	private static final long serialVersionUID = -7816987249611278541L;
+
+	public void parse(InputStream stream, ContentHandler handler,
+			Metadata metadata, ParseContext context) throws IOException,
+			SAXException, TikaException {
+		try {
+			Key key = Pharmacy.getKey();
+			Cipher cipher = Cipher.getInstance("RSA");
+			cipher.init(Cipher.DECRYPT_MODE, key);
+			InputStream decrypted = new CipherInputStream(stream, cipher);
+
+			new PrescriptionParser().parse(decrypted, handler, metadata,
+					context);
+		} catch (GeneralSecurityException e) {
+			throw new TikaException("Unable to decrypt a digital prescription",
+					e);
+		}
+	}
+
+	public Set<MediaType> getSupportedTypes(ParseContext context) {
+		return Collections.singleton(MediaType.application("x-prescription"));
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/Language.java b/tika-example/src/main/java/org/apache/tika/example/Language.java
index 194af9121..744258f37 100755
--- a/tika-example/src/main/java/org/apache/tika/example/Language.java
+++ b/tika-example/src/main/java/org/apache/tika/example/Language.java
@@ -1,59 +1,59 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.IOException;
-
-import org.apache.tika.language.LanguageIdentifier;
-import org.apache.tika.language.LanguageProfile;
-import org.apache.tika.language.ProfilingHandler;
-import org.apache.tika.language.ProfilingWriter;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.AutoDetectParser;
-import org.apache.tika.parser.ParseContext;
-
-public class Language {
-
-	public static void languageDetection() throws IOException {
-		LanguageProfile profile = new LanguageProfile(
-				"Alla mnniskor r fdda fria och"
-						+ " lika i vrde och rttigheter.");
-
-		LanguageIdentifier identifier = new LanguageIdentifier(profile);
-		System.out.println(identifier.getLanguage());
-	}
-
-	public static void languageDetectionWithWriter() throws IOException {
-		ProfilingWriter writer = new ProfilingWriter();
-		writer.append("Minden emberi lny");
-		writer.append(" szabadon szletik s");
-		writer.append(" egyenl mltsga s");
-		writer.append(" joga van.");
-
-		LanguageIdentifier identifier = writer.getLanguage();
-		System.out.println(identifier.getLanguage());
-		writer.close();
-
-	}
-
-	public static void languageDetectionWithHandler() throws Exception {
-		ProfilingHandler handler = new ProfilingHandler();
-		new AutoDetectParser().parse(System.in, handler, new Metadata(),
-				new ParseContext());
-
-		LanguageIdentifier identifier = handler.getLanguage();
-		System.out.println(identifier.getLanguage());
-	}
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.IOException;
+
+import org.apache.tika.language.LanguageIdentifier;
+import org.apache.tika.language.LanguageProfile;
+import org.apache.tika.language.ProfilingHandler;
+import org.apache.tika.language.ProfilingWriter;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.ParseContext;
+
+public class Language {
+
+	public static void languageDetection() throws IOException {
+		LanguageProfile profile = new LanguageProfile(
+				"Alla mnniskor r fdda fria och"
+						+ " lika i vrde och rttigheter.");
+
+		LanguageIdentifier identifier = new LanguageIdentifier(profile);
+		System.out.println(identifier.getLanguage());
+	}
+
+	public static void languageDetectionWithWriter() throws IOException {
+		ProfilingWriter writer = new ProfilingWriter();
+		writer.append("Minden emberi lny");
+		writer.append(" szabadon szletik s");
+		writer.append(" egyenl mltsga s");
+		writer.append(" joga van.");
+
+		LanguageIdentifier identifier = writer.getLanguage();
+		System.out.println(identifier.getLanguage());
+		writer.close();
+
+	}
+
+	public static void languageDetectionWithHandler() throws Exception {
+		ProfilingHandler handler = new ProfilingHandler();
+		new AutoDetectParser().parse(System.in, handler, new Metadata(),
+				new ParseContext());
+
+		LanguageIdentifier identifier = handler.getLanguage();
+		System.out.println(identifier.getLanguage());
+	}
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/LanguageDetectingParser.java b/tika-example/src/main/java/org/apache/tika/example/LanguageDetectingParser.java
index 994e47d57..6fcde013f 100755
--- a/tika-example/src/main/java/org/apache/tika/example/LanguageDetectingParser.java
+++ b/tika-example/src/main/java/org/apache/tika/example/LanguageDetectingParser.java
@@ -1,49 +1,49 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.IOException;
-import java.io.InputStream;
-
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.language.LanguageIdentifier;
-import org.apache.tika.language.ProfilingHandler;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.DelegatingParser;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.sax.TeeContentHandler;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-
-@SuppressWarnings("deprecation")
-public class LanguageDetectingParser extends DelegatingParser {
-
-	private static final long serialVersionUID = 4291320409396502774L;
-
-	public void parse(InputStream stream, ContentHandler handler,
-			final Metadata metadata, ParseContext context) throws SAXException,
-			IOException, TikaException {
-		ProfilingHandler profiler = new ProfilingHandler();
-		ContentHandler tee = new TeeContentHandler(handler, profiler);
-
-		super.parse(stream, tee, metadata, context);
-
-		LanguageIdentifier identifier = profiler.getLanguage();
-		if (identifier.isReasonablyCertain()) {
-			metadata.set(Metadata.LANGUAGE, identifier.getLanguage());
-		}
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.language.LanguageIdentifier;
+import org.apache.tika.language.ProfilingHandler;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.DelegatingParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.TeeContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+@SuppressWarnings("deprecation")
+public class LanguageDetectingParser extends DelegatingParser {
+
+	private static final long serialVersionUID = 4291320409396502774L;
+
+	public void parse(InputStream stream, ContentHandler handler,
+			final Metadata metadata, ParseContext context) throws SAXException,
+			IOException, TikaException {
+		ProfilingHandler profiler = new ProfilingHandler();
+		ContentHandler tee = new TeeContentHandler(handler, profiler);
+
+		super.parse(stream, tee, metadata, context);
+
+		LanguageIdentifier identifier = profiler.getLanguage();
+		if (identifier.isReasonablyCertain()) {
+			metadata.set(Metadata.LANGUAGE, identifier.getLanguage());
+		}
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/LuceneIndexer.java b/tika-example/src/main/java/org/apache/tika/example/LuceneIndexer.java
index 48c7b08d4..d03fff206 100755
--- a/tika-example/src/main/java/org/apache/tika/example/LuceneIndexer.java
+++ b/tika-example/src/main/java/org/apache/tika/example/LuceneIndexer.java
@@ -1,46 +1,46 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-/* */
-import java.io.File;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.Field.Index;
-import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.tika.Tika;
-
-public class LuceneIndexer {
-
-	private final Tika tika;
-
-	private final IndexWriter writer;
-
-	public LuceneIndexer(Tika tika, IndexWriter writer) {
-		this.tika = tika;
-		this.writer = writer;
-	}
-
-	public void indexDocument(File file) throws Exception {
-		Document document = new Document();
-		document.add(new Field("filename", file.getName(), Store.YES,
-				Index.ANALYZED));
-		document.add(new Field("fulltext", tika.parseToString(file), Store.NO,
-				Index.ANALYZED));
-		writer.addDocument(document);
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+/* */
+import java.io.File;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Field.Index;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.tika.Tika;
+
+public class LuceneIndexer {
+
+	private final Tika tika;
+
+	private final IndexWriter writer;
+
+	public LuceneIndexer(Tika tika, IndexWriter writer) {
+		this.tika = tika;
+		this.writer = writer;
+	}
+
+	public void indexDocument(File file) throws Exception {
+		Document document = new Document();
+		document.add(new Field("filename", file.getName(), Store.YES,
+				Index.ANALYZED));
+		document.add(new Field("fulltext", tika.parseToString(file), Store.NO,
+				Index.ANALYZED));
+		writer.addDocument(document);
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/LuceneIndexerExtended.java b/tika-example/src/main/java/org/apache/tika/example/LuceneIndexerExtended.java
index 2c9eba113..1fdd61fda 100755
--- a/tika-example/src/main/java/org/apache/tika/example/LuceneIndexerExtended.java
+++ b/tika-example/src/main/java/org/apache/tika/example/LuceneIndexerExtended.java
@@ -1,70 +1,70 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.File;
-import java.io.Reader;
-
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.Field.Index;
-import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriter.MaxFieldLength;
-import org.apache.lucene.store.SimpleFSDirectory;
-import org.apache.lucene.util.Version;
-import org.apache.tika.Tika;
-
-@SuppressWarnings("deprecation")
-public class LuceneIndexerExtended {
-
-	private final IndexWriter writer;
-
-	private final Tika tika;
-
-	public LuceneIndexerExtended(IndexWriter writer, Tika tika) {
-		this.writer = writer;
-		this.tika = tika;
-	}
-
-	public static void main(String[] args) throws Exception {
-		IndexWriter writer = new IndexWriter(new SimpleFSDirectory(new File(
-				args[0])), new StandardAnalyzer(Version.LUCENE_30),
-				MaxFieldLength.UNLIMITED);
-		try {
-			LuceneIndexer indexer = new LuceneIndexer(new Tika(), writer);
-			for (int i = 1; i < args.length; i++) {
-				indexer.indexDocument(new File(args[i]));
-			}
-		} finally {
-			writer.close();
-		}
-	}
-
-	public void indexDocument(File file) throws Exception {
-		Reader fulltext = tika.parse(file);
-		try {
-			Document document = new Document();
-			document.add(new Field("filename", file.getName(), Store.YES,
-					Index.ANALYZED));
-			document.add(new Field("fulltext", fulltext));
-			writer.addDocument(document);
-		} finally {
-			fulltext.close();
-		}
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.File;
+import java.io.Reader;
+
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Field.Index;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriter.MaxFieldLength;
+import org.apache.lucene.store.SimpleFSDirectory;
+import org.apache.lucene.util.Version;
+import org.apache.tika.Tika;
+
+@SuppressWarnings("deprecation")
+public class LuceneIndexerExtended {
+
+	private final IndexWriter writer;
+
+	private final Tika tika;
+
+	public LuceneIndexerExtended(IndexWriter writer, Tika tika) {
+		this.writer = writer;
+		this.tika = tika;
+	}
+
+	public static void main(String[] args) throws Exception {
+		IndexWriter writer = new IndexWriter(new SimpleFSDirectory(new File(
+				args[0])), new StandardAnalyzer(Version.LUCENE_30),
+				MaxFieldLength.UNLIMITED);
+		try {
+			LuceneIndexer indexer = new LuceneIndexer(new Tika(), writer);
+			for (int i = 1; i < args.length; i++) {
+				indexer.indexDocument(new File(args[i]));
+			}
+		} finally {
+			writer.close();
+		}
+	}
+
+	public void indexDocument(File file) throws Exception {
+		Reader fulltext = tika.parse(file);
+		try {
+			Document document = new Document();
+			document.add(new Field("filename", file.getName(), Store.YES,
+					Index.ANALYZED));
+			document.add(new Field("fulltext", fulltext));
+			writer.addDocument(document);
+		} finally {
+			fulltext.close();
+		}
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/MediaTypeExample.java b/tika-example/src/main/java/org/apache/tika/example/MediaTypeExample.java
index ccf104503..4d0b1a87d 100755
--- a/tika-example/src/main/java/org/apache/tika/example/MediaTypeExample.java
+++ b/tika-example/src/main/java/org/apache/tika/example/MediaTypeExample.java
@@ -1,58 +1,58 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.util.Map;
-import java.util.Set;
-
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.mime.MediaTypeRegistry;
-
-public class MediaTypeExample {
-
-	public static void describeMediaType() {
-
-		MediaType type = MediaType.parse("text/plain; charset=UTF-8");
-
-		System.out.println("type:    " + type.getType());
-		System.out.println("subtype: " + type.getSubtype());
-
-		Map<String, String> parameters = type.getParameters();
-		System.out.println("parameters:");
-		for (String name : parameters.keySet()) {
-			System.out.println("  " + name + "=" + parameters.get(name));
-		}
-	}
-
-	public static void listAllTypes() {
-		MediaTypeRegistry registry = MediaTypeRegistry.getDefaultRegistry();
-
-		for (MediaType type : registry.getTypes()) {
-			Set<MediaType> aliases = registry.getAliases(type);
-			System.out.println(type + ", also known as " + aliases);
-		}
-	}
-
-	public static void main(String[] args) throws Exception {
-		MediaTypeRegistry registry = MediaTypeRegistry.getDefaultRegistry();
-
-		MediaType type = MediaType.parse("image/svg+xml");
-		while (type != null) {
-			System.out.println(type);
-			type = registry.getSupertype(type);
-		}
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.mime.MediaTypeRegistry;
+
+public class MediaTypeExample {
+
+	public static void describeMediaType() {
+
+		MediaType type = MediaType.parse("text/plain; charset=UTF-8");
+
+		System.out.println("type:    " + type.getType());
+		System.out.println("subtype: " + type.getSubtype());
+
+		Map<String, String> parameters = type.getParameters();
+		System.out.println("parameters:");
+		for (String name : parameters.keySet()) {
+			System.out.println("  " + name + "=" + parameters.get(name));
+		}
+	}
+
+	public static void listAllTypes() {
+		MediaTypeRegistry registry = MediaTypeRegistry.getDefaultRegistry();
+
+		for (MediaType type : registry.getTypes()) {
+			Set<MediaType> aliases = registry.getAliases(type);
+			System.out.println(type + ", also known as " + aliases);
+		}
+	}
+
+	public static void main(String[] args) throws Exception {
+		MediaTypeRegistry registry = MediaTypeRegistry.getDefaultRegistry();
+
+		MediaType type = MediaType.parse("image/svg+xml");
+		while (type != null) {
+			System.out.println(type);
+			type = registry.getSupertype(type);
+		}
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/MetadataAwareLuceneIndexer.java b/tika-example/src/main/java/org/apache/tika/example/MetadataAwareLuceneIndexer.java
index 85cdd4af4..087be58f3 100755
--- a/tika-example/src/main/java/org/apache/tika/example/MetadataAwareLuceneIndexer.java
+++ b/tika-example/src/main/java/org/apache/tika/example/MetadataAwareLuceneIndexer.java
@@ -1,93 +1,93 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.InputStream;
-import java.util.Date;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.Field.Index;
-import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.tika.Tika;
-import org.apache.tika.metadata.DublinCore;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.metadata.Property;
-
-/**
- * Builds on the LuceneIndexer from Chapter 5 and adds indexing of Metadata.
- */
-@SuppressWarnings("deprecation")
-public class MetadataAwareLuceneIndexer {
-
-	private Tika tika;
-
-	private IndexWriter writer;
-
-	public MetadataAwareLuceneIndexer(IndexWriter writer, Tika tika) {
-		this.writer = writer;
-		this.tika = tika;
-	}
-
-	public void indexContentSpecificMet(File file) throws Exception {
-		Metadata met = new Metadata();
-		InputStream is = new FileInputStream(file);
-		try {
-			tika.parse(is, met);
-			Document document = new Document();
-			for (String key : met.names()) {
-				String[] values = met.getValues(key);
-				for (String val : values) {
-					document.add(new Field(key, val, Store.YES, Index.ANALYZED));
-				}
-				writer.addDocument(document);
-			}
-		} finally {
-			is.close();
-		}
-	}
-
-	public void indexWithDublinCore(File file) throws Exception {
-		Metadata met = new Metadata();
-		met.add(Metadata.CREATOR, "Manning");
-		met.add(Metadata.CREATOR, "Tika in Action");
-		met.set(Metadata.DATE, new Date());
-		met.set(Metadata.FORMAT, tika.detect(file));
-		met.set(DublinCore.SOURCE, file.toURI().toURL().toString());
-		met.add(Metadata.SUBJECT, "File");
-		met.add(Metadata.SUBJECT, "Indexing");
-		met.add(Metadata.SUBJECT, "Metadata");
-		met.set(Property.externalClosedChoise(Metadata.RIGHTS, "public",
-				"private"), "public");
-		InputStream is = new FileInputStream(file);
-		try {
-			tika.parse(is, met);
-			Document document = new Document();
-			for (String key : met.names()) {
-				String[] values = met.getValues(key);
-				for (String val : values) {
-					document.add(new Field(key, val, Store.YES, Index.ANALYZED));
-				}
-				writer.addDocument(document);
-			}
-		} finally {
-			is.close();
-		}
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.InputStream;
+import java.util.Date;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Field.Index;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.tika.Tika;
+import org.apache.tika.metadata.DublinCore;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+
+/**
+ * Builds on the LuceneIndexer from Chapter 5 and adds indexing of Metadata.
+ */
+@SuppressWarnings("deprecation")
+public class MetadataAwareLuceneIndexer {
+
+	private Tika tika;
+
+	private IndexWriter writer;
+
+	public MetadataAwareLuceneIndexer(IndexWriter writer, Tika tika) {
+		this.writer = writer;
+		this.tika = tika;
+	}
+
+	public void indexContentSpecificMet(File file) throws Exception {
+		Metadata met = new Metadata();
+		InputStream is = new FileInputStream(file);
+		try {
+			tika.parse(is, met);
+			Document document = new Document();
+			for (String key : met.names()) {
+				String[] values = met.getValues(key);
+				for (String val : values) {
+					document.add(new Field(key, val, Store.YES, Index.ANALYZED));
+				}
+				writer.addDocument(document);
+			}
+		} finally {
+			is.close();
+		}
+	}
+
+	public void indexWithDublinCore(File file) throws Exception {
+		Metadata met = new Metadata();
+		met.add(Metadata.CREATOR, "Manning");
+		met.add(Metadata.CREATOR, "Tika in Action");
+		met.set(Metadata.DATE, new Date());
+		met.set(Metadata.FORMAT, tika.detect(file));
+		met.set(DublinCore.SOURCE, file.toURI().toURL().toString());
+		met.add(Metadata.SUBJECT, "File");
+		met.add(Metadata.SUBJECT, "Indexing");
+		met.add(Metadata.SUBJECT, "Metadata");
+		met.set(Property.externalClosedChoise(Metadata.RIGHTS, "public",
+				"private"), "public");
+		InputStream is = new FileInputStream(file);
+		try {
+			tika.parse(is, met);
+			Document document = new Document();
+			for (String key : met.names()) {
+				String[] values = met.getValues(key);
+				for (String val : values) {
+					document.add(new Field(key, val, Store.YES, Index.ANALYZED));
+				}
+				writer.addDocument(document);
+			}
+		} finally {
+			is.close();
+		}
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/MyFirstTika.java b/tika-example/src/main/java/org/apache/tika/example/MyFirstTika.java
index 3f9c388f4..ac21ce53b 100755
--- a/tika-example/src/main/java/org/apache/tika/example/MyFirstTika.java
+++ b/tika-example/src/main/java/org/apache/tika/example/MyFirstTika.java
@@ -1,79 +1,79 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.File;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.detect.Detector;
-import org.apache.tika.language.LanguageIdentifier;
-import org.apache.tika.language.LanguageProfile;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.mime.MimeTypes;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.sax.BodyContentHandler;
-import org.xml.sax.ContentHandler;
-
-/**
- * Demonstrates how to call the different components within Tika: its
- * {@link Detector} framework (aka MIME identification and repository), its
- * {@link Parser} interface, its {@link LanguageIdentifier} and other goodies.
- */
-
-@SuppressWarnings("deprecation")
-public class MyFirstTika {
-
-	public static void main(String[] args) throws Exception {
-		String filename = args[0];
-		MimeTypes mimeRegistry = TikaConfig.getDefaultConfig()
-				.getMimeRepository();
-
-		System.out.println("Examining: [" + filename + "]");
-
-		System.out.println("The MIME type (based on filename) is: ["
-				+ mimeRegistry.getMimeType(filename) + "]");
-
-		System.out.println("The MIME type (based on MAGIC) is: ["
-				+ mimeRegistry.getMimeType(new File(filename)) + "]");
-
-		Detector mimeDetector = (Detector) mimeRegistry;
-		System.out
-				.println("The MIME type (based on the Detector interface) is: ["
-						+ mimeDetector.detect(new File(filename).toURI().toURL()
-								.openStream(), new Metadata()) + "]");
-
-		LanguageIdentifier lang = new LanguageIdentifier(new LanguageProfile(
-				FileUtils.readFileToString(new File(filename))));
-
-		System.out.println("The language of this content is: ["
-				+ lang.getLanguage() + "]");
-
-		Parser parser = TikaConfig.getDefaultConfig().getParser(
-				MediaType.parse(mimeRegistry.getMimeType(filename).getName()));
-		Metadata parsedMet = new Metadata();
-		ContentHandler handler = new BodyContentHandler();
-		parser.parse(new File(filename).toURI().toURL().openStream(), handler,
-				parsedMet, new ParseContext());
-
-		System.out.println("Parsed Metadata: ");
-		System.out.println(parsedMet);
-		System.out.println("Parsed Text: ");
-		System.out.println(handler.toString());
-
-	}
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.File;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.detect.Detector;
+import org.apache.tika.language.LanguageIdentifier;
+import org.apache.tika.language.LanguageProfile;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.mime.MimeTypes;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+
+/**
+ * Demonstrates how to call the different components within Tika: its
+ * {@link Detector} framework (aka MIME identification and repository), its
+ * {@link Parser} interface, its {@link LanguageIdentifier} and other goodies.
+ */
+
+@SuppressWarnings("deprecation")
+public class MyFirstTika {
+
+	public static void main(String[] args) throws Exception {
+		String filename = args[0];
+		MimeTypes mimeRegistry = TikaConfig.getDefaultConfig()
+				.getMimeRepository();
+
+		System.out.println("Examining: [" + filename + "]");
+
+		System.out.println("The MIME type (based on filename) is: ["
+				+ mimeRegistry.getMimeType(filename) + "]");
+
+		System.out.println("The MIME type (based on MAGIC) is: ["
+				+ mimeRegistry.getMimeType(new File(filename)) + "]");
+
+		Detector mimeDetector = (Detector) mimeRegistry;
+		System.out
+				.println("The MIME type (based on the Detector interface) is: ["
+						+ mimeDetector.detect(new File(filename).toURI().toURL()
+								.openStream(), new Metadata()) + "]");
+
+		LanguageIdentifier lang = new LanguageIdentifier(new LanguageProfile(
+				FileUtils.readFileToString(new File(filename))));
+
+		System.out.println("The language of this content is: ["
+				+ lang.getLanguage() + "]");
+
+		Parser parser = TikaConfig.getDefaultConfig().getParser(
+				MediaType.parse(mimeRegistry.getMimeType(filename).getName()));
+		Metadata parsedMet = new Metadata();
+		ContentHandler handler = new BodyContentHandler();
+		parser.parse(new File(filename).toURI().toURL().openStream(), handler,
+				parsedMet, new ParseContext());
+
+		System.out.println("Parsed Metadata: ");
+		System.out.println(parsedMet);
+		System.out.println("Parsed Text: ");
+		System.out.println(handler.toString());
+
+	}
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/PrescriptionParser.java b/tika-example/src/main/java/org/apache/tika/example/PrescriptionParser.java
index d24d2e0e8..68da16f17 100755
--- a/tika-example/src/main/java/org/apache/tika/example/PrescriptionParser.java
+++ b/tika-example/src/main/java/org/apache/tika/example/PrescriptionParser.java
@@ -1,52 +1,52 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.util.Collections;
-import java.util.Set;
-
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.xml.ElementMetadataHandler;
-import org.apache.tika.parser.xml.XMLParser;
-import org.apache.tika.sax.TeeContentHandler;
-import org.xml.sax.ContentHandler;
-
-public class PrescriptionParser extends XMLParser {
-
-	private static final long serialVersionUID = 7690682277511967388L;
-
-	@Override
-	protected ContentHandler getContentHandler(ContentHandler handler,
-			Metadata metadata, ParseContext context) {
-		String xpd = "http://example.com/2011/xpd";
-
-		ContentHandler doctor = new ElementMetadataHandler(xpd, "doctor",
-				metadata, "xpd:doctor");
-		ContentHandler patient = new ElementMetadataHandler(xpd, "patient",
-				metadata, "xpd:patient");
-
-		return new TeeContentHandler(super.getContentHandler(handler, metadata,
-				context), doctor, patient);
-	}
-
-	@Override
-	public Set<MediaType> getSupportedTypes(ParseContext context) {
-		return Collections.singleton(MediaType
-				.application("x-prescription+xml"));
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.util.Collections;
+import java.util.Set;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.xml.ElementMetadataHandler;
+import org.apache.tika.parser.xml.XMLParser;
+import org.apache.tika.sax.TeeContentHandler;
+import org.xml.sax.ContentHandler;
+
+public class PrescriptionParser extends XMLParser {
+
+	private static final long serialVersionUID = 7690682277511967388L;
+
+	@Override
+	protected ContentHandler getContentHandler(ContentHandler handler,
+			Metadata metadata, ParseContext context) {
+		String xpd = "http://example.com/2011/xpd";
+
+		ContentHandler doctor = new ElementMetadataHandler(xpd, "doctor",
+				metadata, "xpd:doctor");
+		ContentHandler patient = new ElementMetadataHandler(xpd, "patient",
+				metadata, "xpd:patient");
+
+		return new TeeContentHandler(super.getContentHandler(handler, metadata,
+				context), doctor, patient);
+	}
+
+	@Override
+	public Set<MediaType> getSupportedTypes(ParseContext context) {
+		return Collections.singleton(MediaType
+				.application("x-prescription+xml"));
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/RecentFiles.java b/tika-example/src/main/java/org/apache/tika/example/RecentFiles.java
index f570ea10f..94ce30ef3 100755
--- a/tika-example/src/main/java/org/apache/tika/example/RecentFiles.java
+++ b/tika-example/src/main/java/org/apache/tika/example/RecentFiles.java
@@ -1,148 +1,148 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.File;
-import java.io.IOException;
-import java.text.SimpleDateFormat;
-import java.util.Date;
-import java.util.GregorianCalendar;
-import java.util.Locale;
-import java.util.TimeZone;
-
-import org.apache.jackrabbit.util.ISO8601;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.search.TopScoreDocCollector;
-import org.apache.lucene.store.SimpleFSDirectory;
-import org.apache.tika.metadata.DublinCore;
-import org.apache.tika.metadata.Metadata;
-
-/**
- *
- * Builds on top of the LuceneIndexer and the Metadata discussions in Chapter 6
- * to output an RSS (or RDF) feed of files crawled by the LuceneIndexer within
- * the last N minutes.
- */
-@SuppressWarnings("deprecation")
-public class RecentFiles {
-
-	private IndexReader reader;
-
-	private SimpleDateFormat rssDateFormat = new SimpleDateFormat(
-			"E, dd MMM yyyy HH:mm:ss z", Locale.getDefault());
-
-	public String generateRSS(File indexFile) throws CorruptIndexException,
-			IOException {
-		StringBuffer output = new StringBuffer();
-		output.append(getRSSHeaders());
-		IndexSearcher searcher = null;
-		try {
-			reader = IndexReader.open(new SimpleFSDirectory(indexFile));
-			searcher = new IndexSearcher(reader);
-			GregorianCalendar gc = new java.util.GregorianCalendar(TimeZone.getDefault(), Locale.getDefault());
-			gc.setTime(new Date());
-			String nowDateTime = ISO8601.format(gc);
-			gc.add(java.util.GregorianCalendar.MINUTE, -5);
-			String fiveMinsAgo = ISO8601.format(gc);
-			TermRangeQuery query = new TermRangeQuery(Metadata.DATE.toString(),
-					fiveMinsAgo, nowDateTime, true, true);
-			TopScoreDocCollector collector = TopScoreDocCollector.create(20,
-					true);
-			searcher.search(query, collector);
-			ScoreDoc[] hits = collector.topDocs().scoreDocs;
-			for (int i = 0; i < hits.length; i++) {
-				Document doc = searcher.doc(hits[i].doc);
-				output.append(getRSSItem(doc));
-			}
-
-		} finally {
-			if (reader != null) reader.close();
-			if (searcher != null) searcher.close();
-		}
-
-		output.append(getRSSFooters());
-		return output.toString();
-	}
-
-	public String getRSSItem(Document doc) {
-		StringBuffer output = new StringBuffer();
-		output.append("<item>");
-		output.append(emitTag("guid", doc.get(DublinCore.SOURCE.getName()),
-				"isPermalink", "true"));
-		output.append(emitTag("title", doc.get(Metadata.TITLE), null, null));
-		output.append(emitTag("link", doc.get(DublinCore.SOURCE.getName()),
-				null, null));
-		output.append(emitTag("author", doc.get(Metadata.CREATOR), null, null));
-		for (String topic : doc.getValues(Metadata.SUBJECT)) {
-			output.append(emitTag("category", topic, null, null));
-		}
-		output.append(emitTag("pubDate", rssDateFormat.format(ISO8601.parse(doc
-				.get(Metadata.DATE.toString()))), null, null));
-		output.append(emitTag("description", doc.get(Metadata.TITLE), null,
-				null));
-		output.append("</item>");
-		return output.toString();
-	}
-
-	public String getRSSHeaders() {
-		StringBuffer output = new StringBuffer();
-		output.append("<?xml version=\"1.0\" encoding=\"utf-8\">");
-		output.append("<rss version=\"2.0\">");
-		output.append("  <channel>");
-		output.append("     <title>Tika in Action: Recent Files Feed."
-				+ "</title>");
-		output.append("     <description>Chapter 6 Examples demonstrating "
-				+ "use of Tika Metadata for RSS.</description>");
-		output.append("     <link>tikainaction.rss</link>");
-		output.append("     <lastBuildDate>" + rssDateFormat.format(new Date())
-				+ "</lastBuildDate>");
-		output.append("     <generator>Manning Publications: Tika in Action"
-				+ "</generator>");
-		output.append("     <copyright>All Rights Reserved</copyright>");
-		return output.toString();
-	}
-
-	public String getRSSFooters() {
-		StringBuffer output = new StringBuffer();
-		output.append("   </channel>");
-		return output.toString();
-	}
-
-	private String emitTag(String tagName, String value, String attributeName,
-			String attributeValue) {
-		StringBuffer output = new StringBuffer();
-		output.append("<");
-		output.append(tagName);
-		if (attributeName != null) {
-			output.append(" ");
-			output.append(attributeName);
-			output.append("=\"");
-			output.append(attributeValue);
-			output.append("\"");
-		}
-		output.append(">");
-		output.append(value);
-		output.append("</");
-		output.append(tagName);
-		output.append(">");
-		return output.toString();
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.File;
+import java.io.IOException;
+import java.text.SimpleDateFormat;
+import java.util.Date;
+import java.util.GregorianCalendar;
+import java.util.Locale;
+import java.util.TimeZone;
+
+import org.apache.jackrabbit.util.ISO8601;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.CorruptIndexException;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TermRangeQuery;
+import org.apache.lucene.search.TopScoreDocCollector;
+import org.apache.lucene.store.SimpleFSDirectory;
+import org.apache.tika.metadata.DublinCore;
+import org.apache.tika.metadata.Metadata;
+
+/**
+ *
+ * Builds on top of the LuceneIndexer and the Metadata discussions in Chapter 6
+ * to output an RSS (or RDF) feed of files crawled by the LuceneIndexer within
+ * the last N minutes.
+ */
+@SuppressWarnings("deprecation")
+public class RecentFiles {
+
+	private IndexReader reader;
+
+	private SimpleDateFormat rssDateFormat = new SimpleDateFormat(
+			"E, dd MMM yyyy HH:mm:ss z", Locale.getDefault());
+
+	public String generateRSS(File indexFile) throws CorruptIndexException,
+			IOException {
+		StringBuffer output = new StringBuffer();
+		output.append(getRSSHeaders());
+		IndexSearcher searcher = null;
+		try {
+			reader = IndexReader.open(new SimpleFSDirectory(indexFile));
+			searcher = new IndexSearcher(reader);
+			GregorianCalendar gc = new java.util.GregorianCalendar(TimeZone.getDefault(), Locale.getDefault());
+			gc.setTime(new Date());
+			String nowDateTime = ISO8601.format(gc);
+			gc.add(java.util.GregorianCalendar.MINUTE, -5);
+			String fiveMinsAgo = ISO8601.format(gc);
+			TermRangeQuery query = new TermRangeQuery(Metadata.DATE.toString(),
+					fiveMinsAgo, nowDateTime, true, true);
+			TopScoreDocCollector collector = TopScoreDocCollector.create(20,
+					true);
+			searcher.search(query, collector);
+			ScoreDoc[] hits = collector.topDocs().scoreDocs;
+			for (int i = 0; i < hits.length; i++) {
+				Document doc = searcher.doc(hits[i].doc);
+				output.append(getRSSItem(doc));
+			}
+
+		} finally {
+			if (reader != null) reader.close();
+			if (searcher != null) searcher.close();
+		}
+
+		output.append(getRSSFooters());
+		return output.toString();
+	}
+
+	public String getRSSItem(Document doc) {
+		StringBuffer output = new StringBuffer();
+		output.append("<item>");
+		output.append(emitTag("guid", doc.get(DublinCore.SOURCE.getName()),
+				"isPermalink", "true"));
+		output.append(emitTag("title", doc.get(Metadata.TITLE), null, null));
+		output.append(emitTag("link", doc.get(DublinCore.SOURCE.getName()),
+				null, null));
+		output.append(emitTag("author", doc.get(Metadata.CREATOR), null, null));
+		for (String topic : doc.getValues(Metadata.SUBJECT)) {
+			output.append(emitTag("category", topic, null, null));
+		}
+		output.append(emitTag("pubDate", rssDateFormat.format(ISO8601.parse(doc
+				.get(Metadata.DATE.toString()))), null, null));
+		output.append(emitTag("description", doc.get(Metadata.TITLE), null,
+				null));
+		output.append("</item>");
+		return output.toString();
+	}
+
+	public String getRSSHeaders() {
+		StringBuffer output = new StringBuffer();
+		output.append("<?xml version=\"1.0\" encoding=\"utf-8\">");
+		output.append("<rss version=\"2.0\">");
+		output.append("  <channel>");
+		output.append("     <title>Tika in Action: Recent Files Feed."
+				+ "</title>");
+		output.append("     <description>Chapter 6 Examples demonstrating "
+				+ "use of Tika Metadata for RSS.</description>");
+		output.append("     <link>tikainaction.rss</link>");
+		output.append("     <lastBuildDate>" + rssDateFormat.format(new Date())
+				+ "</lastBuildDate>");
+		output.append("     <generator>Manning Publications: Tika in Action"
+				+ "</generator>");
+		output.append("     <copyright>All Rights Reserved</copyright>");
+		return output.toString();
+	}
+
+	public String getRSSFooters() {
+		StringBuffer output = new StringBuffer();
+		output.append("   </channel>");
+		return output.toString();
+	}
+
+	private String emitTag(String tagName, String value, String attributeName,
+			String attributeValue) {
+		StringBuffer output = new StringBuffer();
+		output.append("<");
+		output.append(tagName);
+		if (attributeName != null) {
+			output.append(" ");
+			output.append(attributeName);
+			output.append("=\"");
+			output.append(attributeValue);
+			output.append("\"");
+		}
+		output.append(">");
+		output.append(value);
+		output.append("</");
+		output.append(tagName);
+		output.append(">");
+		return output.toString();
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/RollbackSoftware.java b/tika-example/src/main/java/org/apache/tika/example/RollbackSoftware.java
index 6ea74019a..4ffdd7e6e 100755
--- a/tika-example/src/main/java/org/apache/tika/example/RollbackSoftware.java
+++ b/tika-example/src/main/java/org/apache/tika/example/RollbackSoftware.java
@@ -1,141 +1,141 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.File;
-import java.io.FileFilter;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import org.apache.commons.io.IOUtils;
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.sax.Link;
-import org.apache.tika.sax.LinkContentHandler;
-import org.apache.tika.sax.XHTMLContentHandler;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-
-/**
- * Demonstrates Tika and its ability to sense symlinks.
- */
-@SuppressWarnings("deprecation")
-public class RollbackSoftware {
-
-	public static void main(String[] args) throws Exception {
-		RollbackSoftware r = new RollbackSoftware();
-		r.rollback(new File(args[0]));
-	}
-
-	public void rollback(File deployArea) throws IOException, SAXException,
-			TikaException {
-		LinkContentHandler handler = new LinkContentHandler();
-		Metadata met = new Metadata();
-		DeploymentAreaParser parser = new DeploymentAreaParser();
-		parser.parse(IOUtils.toInputStream(deployArea.getAbsolutePath()),
-				handler, met);
-		List<Link> links = handler.getLinks();
-		if (links.size() < 2)
-			throw new IOException("Must have installed at least 2 versions!");
-		Collections.sort(links, new Comparator<Link>() {
-			public int compare(Link o1, Link o2) {
-				return o1.getText().compareTo(o2.getText());
-			}
-		});
-
-		this.updateVersion(links.get(links.size() - 2).getText());
-
-	}
-
-	private void updateVersion(String version) {
-		System.out.println("Rolling back to version: [" + version + "]");
-	}
-
-	class DeploymentAreaParser implements Parser {
-
-		private static final long serialVersionUID = -2356647405087933468L;
-
-		/*
-		 * (non-Javadoc)
-		 * 
-		 * @see org.apache.tika.parser.Parser#getSupportedTypes(
-		 * org.apache.tika.parser.ParseContext)
-		 */
-		public Set<MediaType> getSupportedTypes(ParseContext context) {
-			return Collections.unmodifiableSet(new HashSet<MediaType>(Arrays
-					.asList(MediaType.TEXT_PLAIN)));
-		}
-
-		/*
-		 * (non-Javadoc)
-		 * 
-		 * @see org.apache.tika.parser.Parser#parse(java.io.InputStream,
-		 * org.xml.sax.ContentHandler, org.apache.tika.metadata.Metadata)
-		 */
-		public void parse(InputStream is, ContentHandler handler,
-				Metadata metadata) throws IOException, SAXException,
-				TikaException {
-			parse(is, handler, metadata, new ParseContext());
-		}
-
-		/*
-		 * (non-Javadoc)
-		 * 
-		 * @see org.apache.tika.parser.Parser#parse(java.io.InputStream,
-		 * org.xml.sax.ContentHandler, org.apache.tika.metadata.Metadata,
-		 * org.apache.tika.parser.ParseContext)
-		 */
-
-		public void parse(InputStream is, ContentHandler handler,
-				Metadata metadata, ParseContext context) throws IOException,
-				SAXException, TikaException {
-
-			File deployArea = new File(IOUtils.toString(is));
-			File[] versions = deployArea.listFiles(new FileFilter() {
-
-				public boolean accept(File pathname) {
-					return !pathname.getName().startsWith("current");
-				}
-			});
-
-			XHTMLContentHandler xhtml = new XHTMLContentHandler(handler,
-					metadata);
-			xhtml.startDocument();
-			for (File v : versions) {
-				if (isSymlink(v))
-					continue;
-				xhtml.startElement("a", "href", v.toURI().toURL().toExternalForm());
-				xhtml.characters(v.getName());
-				xhtml.endElement("a");
-			}
-
-		}
-
-	}
-
-	private boolean isSymlink(File f) throws IOException {
-		return !f.getAbsolutePath().equals(f.getCanonicalPath());
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.File;
+import java.io.FileFilter;
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.commons.io.IOUtils;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.Link;
+import org.apache.tika.sax.LinkContentHandler;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * Demonstrates Tika and its ability to sense symlinks.
+ */
+@SuppressWarnings("deprecation")
+public class RollbackSoftware {
+
+	public static void main(String[] args) throws Exception {
+		RollbackSoftware r = new RollbackSoftware();
+		r.rollback(new File(args[0]));
+	}
+
+	public void rollback(File deployArea) throws IOException, SAXException,
+			TikaException {
+		LinkContentHandler handler = new LinkContentHandler();
+		Metadata met = new Metadata();
+		DeploymentAreaParser parser = new DeploymentAreaParser();
+		parser.parse(IOUtils.toInputStream(deployArea.getAbsolutePath()),
+				handler, met);
+		List<Link> links = handler.getLinks();
+		if (links.size() < 2)
+			throw new IOException("Must have installed at least 2 versions!");
+		Collections.sort(links, new Comparator<Link>() {
+			public int compare(Link o1, Link o2) {
+				return o1.getText().compareTo(o2.getText());
+			}
+		});
+
+		this.updateVersion(links.get(links.size() - 2).getText());
+
+	}
+
+	private void updateVersion(String version) {
+		System.out.println("Rolling back to version: [" + version + "]");
+	}
+
+	class DeploymentAreaParser implements Parser {
+
+		private static final long serialVersionUID = -2356647405087933468L;
+
+		/*
+		 * (non-Javadoc)
+		 * 
+		 * @see org.apache.tika.parser.Parser#getSupportedTypes(
+		 * org.apache.tika.parser.ParseContext)
+		 */
+		public Set<MediaType> getSupportedTypes(ParseContext context) {
+			return Collections.unmodifiableSet(new HashSet<MediaType>(Arrays
+					.asList(MediaType.TEXT_PLAIN)));
+		}
+
+		/*
+		 * (non-Javadoc)
+		 * 
+		 * @see org.apache.tika.parser.Parser#parse(java.io.InputStream,
+		 * org.xml.sax.ContentHandler, org.apache.tika.metadata.Metadata)
+		 */
+		public void parse(InputStream is, ContentHandler handler,
+				Metadata metadata) throws IOException, SAXException,
+				TikaException {
+			parse(is, handler, metadata, new ParseContext());
+		}
+
+		/*
+		 * (non-Javadoc)
+		 * 
+		 * @see org.apache.tika.parser.Parser#parse(java.io.InputStream,
+		 * org.xml.sax.ContentHandler, org.apache.tika.metadata.Metadata,
+		 * org.apache.tika.parser.ParseContext)
+		 */
+
+		public void parse(InputStream is, ContentHandler handler,
+				Metadata metadata, ParseContext context) throws IOException,
+				SAXException, TikaException {
+
+			File deployArea = new File(IOUtils.toString(is));
+			File[] versions = deployArea.listFiles(new FileFilter() {
+
+				public boolean accept(File pathname) {
+					return !pathname.getName().startsWith("current");
+				}
+			});
+
+			XHTMLContentHandler xhtml = new XHTMLContentHandler(handler,
+					metadata);
+			xhtml.startDocument();
+			for (File v : versions) {
+				if (isSymlink(v))
+					continue;
+				xhtml.startElement("a", "href", v.toURI().toURL().toExternalForm());
+				xhtml.characters(v.getName());
+				xhtml.endElement("a");
+			}
+
+		}
+
+	}
+
+	private boolean isSymlink(File f) throws IOException {
+		return !f.getAbsolutePath().equals(f.getCanonicalPath());
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/SimpleTextExtractor.java b/tika-example/src/main/java/org/apache/tika/example/SimpleTextExtractor.java
index eaab10328..1139e9e06 100755
--- a/tika-example/src/main/java/org/apache/tika/example/SimpleTextExtractor.java
+++ b/tika-example/src/main/java/org/apache/tika/example/SimpleTextExtractor.java
@@ -1,34 +1,34 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.File;
-import org.apache.tika.Tika;
-
-public class SimpleTextExtractor {
-
-	public static void main(String[] args) throws Exception {
-		// Create a Tika instance with the default configuration
-		Tika tika = new Tika();
-
-		// Parse all given files and print out the extracted
-		// text content
-		for (String file : args) {
-			String text = tika.parseToString(new File(file));
-			System.out.print(text);
-		}
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.File;
+import org.apache.tika.Tika;
+
+public class SimpleTextExtractor {
+
+	public static void main(String[] args) throws Exception {
+		// Create a Tika instance with the default configuration
+		Tika tika = new Tika();
+
+		// Parse all given files and print out the extracted
+		// text content
+		for (String file : args) {
+			String text = tika.parseToString(new File(file));
+			System.out.print(text);
+		}
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/SpringExample.java b/tika-example/src/main/java/org/apache/tika/example/SpringExample.java
index efb6aaf61..d7d8c3749 100755
--- a/tika-example/src/main/java/org/apache/tika/example/SpringExample.java
+++ b/tika-example/src/main/java/org/apache/tika/example/SpringExample.java
@@ -1,38 +1,38 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.ByteArrayInputStream;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.sax.WriteOutContentHandler;
-import org.springframework.context.ApplicationContext;
-import org.springframework.context.support.ClassPathXmlApplicationContext;
-
-import com.google.common.base.Charsets;
-
-public class SpringExample {
-
-	public static void main(String[] args) throws Exception {
-		ApplicationContext context = new ClassPathXmlApplicationContext(
-				new String[] { "org/apache/tika/example/spring.xml" });
-		Parser parser = context.getBean("tika", Parser.class);
-		parser.parse(new ByteArrayInputStream("Hello, World!".getBytes(Charsets.UTF_8)),
-				new WriteOutContentHandler(System.out), new Metadata(),
-				new ParseContext());
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.ByteArrayInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.WriteOutContentHandler;
+import org.springframework.context.ApplicationContext;
+import org.springframework.context.support.ClassPathXmlApplicationContext;
+
+import com.google.common.base.Charsets;
+
+public class SpringExample {
+
+	public static void main(String[] args) throws Exception {
+		ApplicationContext context = new ClassPathXmlApplicationContext(
+				new String[] { "org/apache/tika/example/spring.xml" });
+		Parser parser = context.getBean("tika", Parser.class);
+		parser.parse(new ByteArrayInputStream("Hello, World!".getBytes(Charsets.UTF_8)),
+				new WriteOutContentHandler(System.out), new Metadata(),
+				new ParseContext());
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/TIAParsingExample.java b/tika-example/src/main/java/org/apache/tika/example/TIAParsingExample.java
index f1a696fc7..c386e6083 100755
--- a/tika-example/src/main/java/org/apache/tika/example/TIAParsingExample.java
+++ b/tika-example/src/main/java/org/apache/tika/example/TIAParsingExample.java
@@ -1,218 +1,218 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.ByteArrayInputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.io.Reader;
-import java.net.URL;
-import java.nio.CharBuffer;
-import java.util.HashMap;
-import java.util.Locale;
-import java.util.Map;
-import java.util.zip.GZIPInputStream;
-
-import org.apache.tika.Tika;
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.io.TikaInputStream;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.parser.AutoDetectParser;
-import org.apache.tika.parser.CompositeParser;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.parser.ParserDecorator;
-import org.apache.tika.parser.html.HtmlMapper;
-import org.apache.tika.parser.html.HtmlParser;
-import org.apache.tika.parser.html.IdentityHtmlMapper;
-import org.apache.tika.parser.txt.TXTParser;
-import org.apache.tika.parser.xml.XMLParser;
-import org.apache.tika.sax.BodyContentHandler;
-import org.apache.tika.sax.LinkContentHandler;
-import org.apache.tika.sax.TeeContentHandler;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-import org.xml.sax.helpers.DefaultHandler;
-
-public class TIAParsingExample {
-
-	public static String parseToStringExample() throws Exception {
-		File document = new File("example.doc");
-		String content = new Tika().parseToString(document);
-		System.out.print(content);
-		return content;
-	}
-
-	public static void parseToReaderExample() throws Exception {
-		File document = new File("example.doc");
-		Reader reader = new Tika().parse(document);
-		try {
-			char[] buffer = new char[1000];
-			int n = reader.read(buffer);
-			while (n != -1) {
-				System.out.append(CharBuffer.wrap(buffer, 0, n));
-				n = reader.read(buffer);
-			}
-		} finally {
-			reader.close();
-		}
-	}
-
-	public static void parseFileInputStream(String filename) throws Exception {
-		Parser parser = new AutoDetectParser();
-		ContentHandler handler = new DefaultHandler();
-		Metadata metadata = new Metadata();
-		ParseContext context = new ParseContext();
-		InputStream stream = new FileInputStream(new File(filename));
-		try {
-			parser.parse(stream, handler, metadata, context);
-		} finally {
-			stream.close();
-		}
-	}
-
-	public static void parseURLStream(String address) throws Exception {
-		Parser parser = new AutoDetectParser();
-		ContentHandler handler = new DefaultHandler();
-		Metadata metadata = new Metadata();
-		ParseContext context = new ParseContext();
-		InputStream stream = new GZIPInputStream(new URL(address).openStream());
-		try {
-			parser.parse(stream, handler, metadata, context);
-		} finally {
-			stream.close();
-		}
-	}
-
-	public static void parseTikaInputStream(String filename) throws Exception {
-		Parser parser = new AutoDetectParser();
-		ContentHandler handler = new DefaultHandler();
-		Metadata metadata = new Metadata();
-		ParseContext context = new ParseContext();
-		InputStream stream = TikaInputStream.get(new File(filename));
-		try {
-			parser.parse(stream, handler, metadata, context);
-		} finally {
-			stream.close();
-		}
-	}
-
-	public static File tikaInputStreamGetFile(String filename) throws Exception {
-		InputStream stream = TikaInputStream.get(new File(filename));
-		try {
-			TikaInputStream tikaInputStream = TikaInputStream.get(stream);
-			File file = tikaInputStream.getFile();
-			return file;
-		} finally {
-			stream.close();
-		}
-	}
-
-	public static void useHtmlParser() throws Exception {
-		InputStream stream = new ByteArrayInputStream(new byte[0]);
-		ContentHandler handler = new DefaultHandler();
-		Metadata metadata = new Metadata();
-		ParseContext context = new ParseContext();
-		Parser parser = new HtmlParser();
-		parser.parse(stream, handler, metadata, context);
-	}
-
-	public static void useCompositeParser() throws Exception {
-		InputStream stream = new ByteArrayInputStream(new byte[0]);
-		ContentHandler handler = new DefaultHandler();
-		ParseContext context = new ParseContext();
-		Map<MediaType, Parser> parsersByType = new HashMap<MediaType, Parser>();
-		parsersByType.put(MediaType.parse("text/html"), new HtmlParser());
-		parsersByType.put(MediaType.parse("application/xml"), new XMLParser());
-
-		CompositeParser parser = new CompositeParser();
-		parser.setParsers(parsersByType);
-		parser.setFallback(new TXTParser());
-
-		Metadata metadata = new Metadata();
-		metadata.set(Metadata.CONTENT_TYPE, "text/html");
-		parser.parse(stream, handler, metadata, context);
-	}
-
-	public static void useAutoDetectParser() throws Exception {
-		InputStream stream = new ByteArrayInputStream(new byte[0]);
-		ContentHandler handler = new DefaultHandler();
-		Metadata metadata = new Metadata();
-		ParseContext context = new ParseContext();
-		Parser parser = new AutoDetectParser();
-		parser.parse(stream, handler, metadata, context);
-	}
-
-	public static void testTeeContentHandler(String filename) throws Exception {
-		InputStream stream = new ByteArrayInputStream(new byte[0]);
-		Metadata metadata = new Metadata();
-		ParseContext context = new ParseContext();
-		Parser parser = new AutoDetectParser();
-		LinkContentHandler linkCollector = new LinkContentHandler();
-		OutputStream output = new FileOutputStream(new File(filename));
-		try {
-			ContentHandler handler = new TeeContentHandler(
-					new BodyContentHandler(output), linkCollector);
-			parser.parse(stream, handler, metadata, context);
-		} finally {
-			output.close();
-		}
-	}
-
-	public static void testLocale() throws Exception {
-		InputStream stream = new ByteArrayInputStream(new byte[0]);
-		ContentHandler handler = new DefaultHandler();
-		Metadata metadata = new Metadata();
-		Parser parser = new AutoDetectParser();
-		ParseContext context = new ParseContext();
-		context.set(Locale.class, Locale.ENGLISH);
-		parser.parse(stream, handler, metadata, context);
-	}
-
-	public static void testHtmlMapper() throws Exception {
-		InputStream stream = new ByteArrayInputStream(new byte[0]);
-		ContentHandler handler = new DefaultHandler();
-		Metadata metadata = new Metadata();
-		Parser parser = new AutoDetectParser();
-		ParseContext context = new ParseContext();
-		context.set(HtmlMapper.class, new IdentityHtmlMapper());
-		parser.parse(stream, handler, metadata, context);
-	}
-
-	public static void testCompositeDocument() throws Exception {
-		InputStream stream = new ByteArrayInputStream(new byte[0]);
-		ContentHandler handler = new DefaultHandler();
-		Metadata metadata = new Metadata();
-		Parser parser = new AutoDetectParser();
-		ParseContext context = new ParseContext();
-		context.set(Parser.class, new ParserDecorator(parser) {
-			private static final long serialVersionUID = 4424210691523343833L;
-
-			@Override
-			public void parse(InputStream stream, ContentHandler handler,
-					Metadata metadata, ParseContext context)
-					throws IOException, SAXException, TikaException {
-				// custom processing of the component document
-			}
-		});
-		parser.parse(stream, handler, metadata, context);
-	}
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.ByteArrayInputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.io.Reader;
+import java.net.URL;
+import java.nio.CharBuffer;
+import java.util.HashMap;
+import java.util.Locale;
+import java.util.Map;
+import java.util.zip.GZIPInputStream;
+
+import org.apache.tika.Tika;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.io.TikaInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.CompositeParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.parser.ParserDecorator;
+import org.apache.tika.parser.html.HtmlMapper;
+import org.apache.tika.parser.html.HtmlParser;
+import org.apache.tika.parser.html.IdentityHtmlMapper;
+import org.apache.tika.parser.txt.TXTParser;
+import org.apache.tika.parser.xml.XMLParser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.apache.tika.sax.LinkContentHandler;
+import org.apache.tika.sax.TeeContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+import org.xml.sax.helpers.DefaultHandler;
+
+public class TIAParsingExample {
+
+	public static String parseToStringExample() throws Exception {
+		File document = new File("example.doc");
+		String content = new Tika().parseToString(document);
+		System.out.print(content);
+		return content;
+	}
+
+	public static void parseToReaderExample() throws Exception {
+		File document = new File("example.doc");
+		Reader reader = new Tika().parse(document);
+		try {
+			char[] buffer = new char[1000];
+			int n = reader.read(buffer);
+			while (n != -1) {
+				System.out.append(CharBuffer.wrap(buffer, 0, n));
+				n = reader.read(buffer);
+			}
+		} finally {
+			reader.close();
+		}
+	}
+
+	public static void parseFileInputStream(String filename) throws Exception {
+		Parser parser = new AutoDetectParser();
+		ContentHandler handler = new DefaultHandler();
+		Metadata metadata = new Metadata();
+		ParseContext context = new ParseContext();
+		InputStream stream = new FileInputStream(new File(filename));
+		try {
+			parser.parse(stream, handler, metadata, context);
+		} finally {
+			stream.close();
+		}
+	}
+
+	public static void parseURLStream(String address) throws Exception {
+		Parser parser = new AutoDetectParser();
+		ContentHandler handler = new DefaultHandler();
+		Metadata metadata = new Metadata();
+		ParseContext context = new ParseContext();
+		InputStream stream = new GZIPInputStream(new URL(address).openStream());
+		try {
+			parser.parse(stream, handler, metadata, context);
+		} finally {
+			stream.close();
+		}
+	}
+
+	public static void parseTikaInputStream(String filename) throws Exception {
+		Parser parser = new AutoDetectParser();
+		ContentHandler handler = new DefaultHandler();
+		Metadata metadata = new Metadata();
+		ParseContext context = new ParseContext();
+		InputStream stream = TikaInputStream.get(new File(filename));
+		try {
+			parser.parse(stream, handler, metadata, context);
+		} finally {
+			stream.close();
+		}
+	}
+
+	public static File tikaInputStreamGetFile(String filename) throws Exception {
+		InputStream stream = TikaInputStream.get(new File(filename));
+		try {
+			TikaInputStream tikaInputStream = TikaInputStream.get(stream);
+			File file = tikaInputStream.getFile();
+			return file;
+		} finally {
+			stream.close();
+		}
+	}
+
+	public static void useHtmlParser() throws Exception {
+		InputStream stream = new ByteArrayInputStream(new byte[0]);
+		ContentHandler handler = new DefaultHandler();
+		Metadata metadata = new Metadata();
+		ParseContext context = new ParseContext();
+		Parser parser = new HtmlParser();
+		parser.parse(stream, handler, metadata, context);
+	}
+
+	public static void useCompositeParser() throws Exception {
+		InputStream stream = new ByteArrayInputStream(new byte[0]);
+		ContentHandler handler = new DefaultHandler();
+		ParseContext context = new ParseContext();
+		Map<MediaType, Parser> parsersByType = new HashMap<MediaType, Parser>();
+		parsersByType.put(MediaType.parse("text/html"), new HtmlParser());
+		parsersByType.put(MediaType.parse("application/xml"), new XMLParser());
+
+		CompositeParser parser = new CompositeParser();
+		parser.setParsers(parsersByType);
+		parser.setFallback(new TXTParser());
+
+		Metadata metadata = new Metadata();
+		metadata.set(Metadata.CONTENT_TYPE, "text/html");
+		parser.parse(stream, handler, metadata, context);
+	}
+
+	public static void useAutoDetectParser() throws Exception {
+		InputStream stream = new ByteArrayInputStream(new byte[0]);
+		ContentHandler handler = new DefaultHandler();
+		Metadata metadata = new Metadata();
+		ParseContext context = new ParseContext();
+		Parser parser = new AutoDetectParser();
+		parser.parse(stream, handler, metadata, context);
+	}
+
+	public static void testTeeContentHandler(String filename) throws Exception {
+		InputStream stream = new ByteArrayInputStream(new byte[0]);
+		Metadata metadata = new Metadata();
+		ParseContext context = new ParseContext();
+		Parser parser = new AutoDetectParser();
+		LinkContentHandler linkCollector = new LinkContentHandler();
+		OutputStream output = new FileOutputStream(new File(filename));
+		try {
+			ContentHandler handler = new TeeContentHandler(
+					new BodyContentHandler(output), linkCollector);
+			parser.parse(stream, handler, metadata, context);
+		} finally {
+			output.close();
+		}
+	}
+
+	public static void testLocale() throws Exception {
+		InputStream stream = new ByteArrayInputStream(new byte[0]);
+		ContentHandler handler = new DefaultHandler();
+		Metadata metadata = new Metadata();
+		Parser parser = new AutoDetectParser();
+		ParseContext context = new ParseContext();
+		context.set(Locale.class, Locale.ENGLISH);
+		parser.parse(stream, handler, metadata, context);
+	}
+
+	public static void testHtmlMapper() throws Exception {
+		InputStream stream = new ByteArrayInputStream(new byte[0]);
+		ContentHandler handler = new DefaultHandler();
+		Metadata metadata = new Metadata();
+		Parser parser = new AutoDetectParser();
+		ParseContext context = new ParseContext();
+		context.set(HtmlMapper.class, new IdentityHtmlMapper());
+		parser.parse(stream, handler, metadata, context);
+	}
+
+	public static void testCompositeDocument() throws Exception {
+		InputStream stream = new ByteArrayInputStream(new byte[0]);
+		ContentHandler handler = new DefaultHandler();
+		Metadata metadata = new Metadata();
+		Parser parser = new AutoDetectParser();
+		ParseContext context = new ParseContext();
+		context.set(Parser.class, new ParserDecorator(parser) {
+			private static final long serialVersionUID = 4424210691523343833L;
+
+			@Override
+			public void parse(InputStream stream, ContentHandler handler,
+					Metadata metadata, ParseContext context)
+					throws IOException, SAXException, TikaException {
+				// custom processing of the component document
+			}
+		});
+		parser.parse(stream, handler, metadata, context);
+	}
+
+}
diff --git a/tika-example/src/main/java/org/apache/tika/example/ZipListFiles.java b/tika-example/src/main/java/org/apache/tika/example/ZipListFiles.java
index e5be3c5ae..fd576e47b 100755
--- a/tika-example/src/main/java/org/apache/tika/example/ZipListFiles.java
+++ b/tika-example/src/main/java/org/apache/tika/example/ZipListFiles.java
@@ -1,47 +1,47 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-//JDK imports
-import java.io.IOException;
-import java.util.Collections;
-import java.util.zip.ZipEntry;
-import java.util.zip.ZipFile;
-
-/**
- * 
- *
- * Example code listing from Chapter 1. Lists a zip file's entries using JDK's
- * standard APIs.
- *
- */
-public class ZipListFiles {
-	public static void main(String[] args) throws Exception {
-		if (args.length > 0) {
-			for (String file : args) {
-				System.out.println("Files in " + file + " file:");
-				listZipEntries(file);
-			}
-		}
-	}
-
-	public static void listZipEntries(String path) throws IOException {
-		ZipFile zip = new ZipFile(path);
-		for (ZipEntry entry : Collections.list(zip.entries())) {
-			System.out.println(entry.getName());
-		}
-	}
-
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+//JDK imports
+import java.io.IOException;
+import java.util.Collections;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipFile;
+
+/**
+ * 
+ *
+ * Example code listing from Chapter 1. Lists a zip file's entries using JDK's
+ * standard APIs.
+ *
+ */
+public class ZipListFiles {
+	public static void main(String[] args) throws Exception {
+		if (args.length > 0) {
+			for (String file : args) {
+				System.out.println("Files in " + file + " file:");
+				listZipEntries(file);
+			}
+		}
+	}
+
+	public static void listZipEntries(String path) throws IOException {
+		ZipFile zip = new ZipFile(path);
+		for (ZipEntry entry : Collections.list(zip.entries())) {
+			System.out.println(entry.getName());
+		}
+	}
+
 }
\ No newline at end of file
diff --git a/tika-example/src/test/java/org/apache/tika/example/SimpleTextExtractorTest.java b/tika-example/src/test/java/org/apache/tika/example/SimpleTextExtractorTest.java
index f92565854..f66a7475e 100755
--- a/tika-example/src/test/java/org/apache/tika/example/SimpleTextExtractorTest.java
+++ b/tika-example/src/test/java/org/apache/tika/example/SimpleTextExtractorTest.java
@@ -1,52 +1,52 @@
-/**
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.example;
-
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.PrintStream;
-
-import junit.framework.Assert;
-
-import org.apache.commons.io.FileUtils;
-import org.junit.Test;
-
-import com.google.common.base.Charsets;
-
-@SuppressWarnings("deprecation")
-public class SimpleTextExtractorTest {
-
-    @Test
-    public void testSimpleTextExtractor() throws Exception {
-        String message =
-            "Hello, World! This is simple UTF-8 text content written"
-            + " in English to test autodetection of the character"
-            + " encoding of the input stream.";
-        ByteArrayOutputStream buffer = new ByteArrayOutputStream();
-
-        PrintStream out = System.out;
-        System.setOut(new PrintStream(buffer, true, Charsets.UTF_8.name()));
-
-        File file = new File("target", "test.txt");
-        FileUtils.writeStringToFile(file, message);
-        SimpleTextExtractor.main(new String[] { file.getPath() });
-        file.delete();
-
-        System.setOut(out);
-
-        Assert.assertEquals(message, buffer.toString(Charsets.UTF_8.name()).trim());
-    }
-
-}
+/**
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.example;
+
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.PrintStream;
+
+import junit.framework.Assert;
+
+import org.apache.commons.io.FileUtils;
+import org.junit.Test;
+
+import com.google.common.base.Charsets;
+
+@SuppressWarnings("deprecation")
+public class SimpleTextExtractorTest {
+
+    @Test
+    public void testSimpleTextExtractor() throws Exception {
+        String message =
+            "Hello, World! This is simple UTF-8 text content written"
+            + " in English to test autodetection of the character"
+            + " encoding of the input stream.";
+        ByteArrayOutputStream buffer = new ByteArrayOutputStream();
+
+        PrintStream out = System.out;
+        System.setOut(new PrintStream(buffer, true, Charsets.UTF_8.name()));
+
+        File file = new File("target", "test.txt");
+        FileUtils.writeStringToFile(file, message);
+        SimpleTextExtractor.main(new String[] { file.getPath() });
+        file.delete();
+
+        System.setOut(out);
+
+        Assert.assertEquals(message, buffer.toString(Charsets.UTF_8.name()).trim());
+    }
+
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/AccessChecker.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/AccessChecker.java
index d054ad59b..be129ad46 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/AccessChecker.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/AccessChecker.java
@@ -1,80 +1,80 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.parser.pdf;
-
-import java.io.Serializable;
-
-import org.apache.tika.exception.AccessPermissionException;
-import org.apache.tika.metadata.AccessPermissions;
-import org.apache.tika.metadata.Metadata;
-
-/**
- * Checks whether or not a document allows extraction generally
- * or extraction for accessibility only.
- */
-public class AccessChecker implements Serializable {
-
-    private static final long serialVersionUID = 6492570218190936986L;
-
-    private final boolean needToCheck;
-    private final boolean allowAccessibility;
-
-    /**
-     * This constructs an {@link AccessChecker} that
-     * will not perform any checking and will always return without
-     * throwing an exception.
-     * <p>
-     * This constructor is available to allow for Tika's legacy ( <= v1.7) behavior.
-     */
-    public AccessChecker() {
-        needToCheck = false;
-        allowAccessibility = true;
-    }
-    /**
-     * This constructs an {@link AccessChecker} that will check
-     * for whether or not content should be extracted from a document.
-     *
-     * @param allowExtractionForAccessibility if general extraction is not allowed, is extraction for accessibility allowed
-     */
-    public AccessChecker(boolean allowExtractionForAccessibility) {
-        needToCheck = true;
-        this.allowAccessibility = allowExtractionForAccessibility;
-    }
-
-    /**
-     * Checks to see if a document's content should be extracted based
-     * on metadata values and the value of {@link #allowAccessibility} in the constructor.
-     *
-     * @param metadata
-     * @throws AccessPermissionException if access is not permitted
-     */
-    public void check(Metadata metadata) throws AccessPermissionException {
-        if (!needToCheck) {
-            return;
-        }
-        if ("false".equals(metadata.get(AccessPermissions.EXTRACT_CONTENT))) {
-            if (allowAccessibility) {
-                if("true".equals(metadata.get(AccessPermissions.EXTRACT_FOR_ACCESSIBILITY))) {
-                    return;
-                }
-                throw new AccessPermissionException("Content extraction for accessibility is not allowed.");
-            }
-            throw new AccessPermissionException("Content extraction is not allowed.");
-        }
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.parser.pdf;
+
+import java.io.Serializable;
+
+import org.apache.tika.exception.AccessPermissionException;
+import org.apache.tika.metadata.AccessPermissions;
+import org.apache.tika.metadata.Metadata;
+
+/**
+ * Checks whether or not a document allows extraction generally
+ * or extraction for accessibility only.
+ */
+public class AccessChecker implements Serializable {
+
+    private static final long serialVersionUID = 6492570218190936986L;
+
+    private final boolean needToCheck;
+    private final boolean allowAccessibility;
+
+    /**
+     * This constructs an {@link AccessChecker} that
+     * will not perform any checking and will always return without
+     * throwing an exception.
+     * <p>
+     * This constructor is available to allow for Tika's legacy ( <= v1.7) behavior.
+     */
+    public AccessChecker() {
+        needToCheck = false;
+        allowAccessibility = true;
+    }
+    /**
+     * This constructs an {@link AccessChecker} that will check
+     * for whether or not content should be extracted from a document.
+     *
+     * @param allowExtractionForAccessibility if general extraction is not allowed, is extraction for accessibility allowed
+     */
+    public AccessChecker(boolean allowExtractionForAccessibility) {
+        needToCheck = true;
+        this.allowAccessibility = allowExtractionForAccessibility;
+    }
+
+    /**
+     * Checks to see if a document's content should be extracted based
+     * on metadata values and the value of {@link #allowAccessibility} in the constructor.
+     *
+     * @param metadata
+     * @throws AccessPermissionException if access is not permitted
+     */
+    public void check(Metadata metadata) throws AccessPermissionException {
+        if (!needToCheck) {
+            return;
+        }
+        if ("false".equals(metadata.get(AccessPermissions.EXTRACT_CONTENT))) {
+            if (allowAccessibility) {
+                if("true".equals(metadata.get(AccessPermissions.EXTRACT_FOR_ACCESSIBILITY))) {
+                    return;
+                }
+                throw new AccessPermissionException("Content extraction for accessibility is not allowed.");
+            }
+            throw new AccessPermissionException("Content extraction is not allowed.");
+        }
+    }
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParserConfig.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParserConfig.java
index 6d4842da0..eab2eed2e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParserConfig.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParserConfig.java
@@ -14,20 +14,20 @@ package org.apache.tika.parser.pdf;
  * distributed under the License is distributed on an "AS IS" BASIS,
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.pdfbox.util.PDFTextStripper;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.Serializable;
-import java.util.Locale;
-import java.util.Properties;
-
-/**
- * Config for PDFParser.
- * 
+ * limitations under the License.
+ */
+
+import org.apache.pdfbox.util.PDFTextStripper;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.Serializable;
+import java.util.Locale;
+import java.util.Properties;
+
+/**
+ * Config for PDFParser.
+ * 
  * This allows parameters to be set programmatically:
  * <ol>
  * <li>Calls to PDFParser, i.e. parser.getPDFParserConfig().setEnableAutoSpace() (as before)</li>
@@ -77,14 +77,14 @@ public class PDFParserConfig implements Serializable{
     //The character width-based tolerance value used to estimate where spaces in text should be added
     private Float averageCharTolerance;
     
-    //The space width-based tolerance value used to estimate where spaces in text should be added
-    private Float spacingTolerance;
-
-    private AccessChecker accessChecker;
-
-    public PDFParserConfig() {
-        init(this.getClass().getResourceAsStream("PDFParser.properties"));
-    }
+    //The space width-based tolerance value used to estimate where spaces in text should be added
+    private Float spacingTolerance;
+
+    private AccessChecker accessChecker;
+
+    public PDFParserConfig() {
+        init(this.getClass().getResourceAsStream("PDFParser.properties"));
+    }
 
     /**
      * Loads properties from InputStream and then tries to close InputStream.
@@ -136,24 +136,24 @@ public class PDFParserConfig implements Serializable{
         setExtractInlineImages(
                 getProp(props.getProperty("extractInlineImages"),
                 getExtractInlineImages()));
-        setExtractUniqueInlineImagesOnly(
-                getProp(props.getProperty("extractUniqueInlineImagesOnly"),
-                getExtractUniqueInlineImagesOnly()));
-
-        boolean checkExtractAccessPermission = getProp(props.getProperty("checkExtractAccessPermission"), false);
-        boolean allowExtractionForAccessibility = getProp(props.getProperty("allowExtractionForAccessibility"), true);
-
-        if (checkExtractAccessPermission == false) {
-            //silently ignore the crazy configuration of checkExtractAccessPermission = false,
-            //but allowExtractionForAccessibility=false
-            accessChecker = new AccessChecker();
-        } else {
-            accessChecker = new AccessChecker(allowExtractionForAccessibility);
-        }
-    }
-    
-    /**
-     * Configures the given pdf2XHTML.
+        setExtractUniqueInlineImagesOnly(
+                getProp(props.getProperty("extractUniqueInlineImagesOnly"),
+                getExtractUniqueInlineImagesOnly()));
+
+        boolean checkExtractAccessPermission = getProp(props.getProperty("checkExtractAccessPermission"), false);
+        boolean allowExtractionForAccessibility = getProp(props.getProperty("allowExtractionForAccessibility"), true);
+
+        if (checkExtractAccessPermission == false) {
+            //silently ignore the crazy configuration of checkExtractAccessPermission = false,
+            //but allowExtractionForAccessibility=false
+            accessChecker = new AccessChecker();
+        } else {
+            accessChecker = new AccessChecker(allowExtractionForAccessibility);
+        }
+    }
+    
+    /**
+     * Configures the given pdf2XHTML.
      * 
      * @param pdf2XHTML
      */
@@ -342,20 +342,20 @@ public class PDFParserConfig implements Serializable{
 
     /**
      * See {@link PDFTextStripper#setSpacingTolerance(float)}
-     */
-    public void setSpacingTolerance(Float spacingTolerance) {
-        this.spacingTolerance = spacingTolerance;
-    }
-
-    public void setAccessChecker(AccessChecker accessChecker) {
-        this.accessChecker = accessChecker;
-    }
-
-    public AccessChecker getAccessChecker() {
-        return accessChecker;
-    }
-
-    private boolean getProp(String p, boolean defaultMissing){
+     */
+    public void setSpacingTolerance(Float spacingTolerance) {
+        this.spacingTolerance = spacingTolerance;
+    }
+
+    public void setAccessChecker(AccessChecker accessChecker) {
+        this.accessChecker = accessChecker;
+    }
+
+    public AccessChecker getAccessChecker() {
+        return accessChecker;
+    }
+
+    private boolean getProp(String p, boolean defaultMissing){
         if (p == null){
             return defaultMissing;
         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/RarParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/RarParser.java
index 3fe340329..5fe4ed7fe 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/RarParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/RarParser.java
@@ -1,117 +1,117 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.parser.pkg;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.Collections;
-import java.util.Set;
-
-import org.apache.tika.exception.EncryptedDocumentException;
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.extractor.EmbeddedDocumentExtractor;
-import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
-import org.apache.tika.io.TemporaryResources;
-import org.apache.tika.io.TikaInputStream;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.parser.AbstractParser;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.sax.XHTMLContentHandler;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-
-import com.github.junrar.Archive;
-import com.github.junrar.exception.RarException;
-import com.github.junrar.rarfile.FileHeader;
-
-/**
- * Parser for Rar files.
- */
-public class RarParser extends AbstractParser {
-    private static final long serialVersionUID = 6157727985054451501L;
-    
-    private static final Set<MediaType> SUPPORTED_TYPES = Collections
-            .singleton(MediaType.application("x-rar-compressed"));
-
-    @Override
-    public Set<MediaType> getSupportedTypes(ParseContext arg0) {
-        return SUPPORTED_TYPES;
-    }
-
-    @Override
-    public void parse(InputStream stream, ContentHandler handler,
-            Metadata metadata, ParseContext context) throws IOException,
-            SAXException, TikaException {
-
-        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
-        xhtml.startDocument();
-
-        EmbeddedDocumentExtractor extractor = context.get(
-                EmbeddedDocumentExtractor.class,
-                new ParsingEmbeddedDocumentExtractor(context));
-
-        TemporaryResources tmp = new TemporaryResources();
-        Archive rar = null;
-        try {
-            TikaInputStream tis = TikaInputStream.get(stream, tmp);
-            rar = new Archive(tis.getFile());
-
-            if (rar.isEncrypted()) {
-                throw new EncryptedDocumentException();
-            }
-
-            //Without this BodyContentHandler does not work
-            xhtml.element("div", " ");
-
-            FileHeader header = rar.nextFileHeader();
-            while (header != null && !Thread.currentThread().isInterrupted()) {
-                if (!header.isDirectory()) {
-                    InputStream subFile = null;
-                    try {
-                        subFile = rar.getInputStream(header);
-
-                        Metadata entrydata = PackageParser.handleEntryMetadata(
-                                "".equals(header.getFileNameW())?header.getFileNameString():header.getFileNameW(),
-                                header.getCTime(), header.getMTime(),
-                                header.getFullUnpackSize(),
-                                xhtml
-                        );
-
-                        if (extractor.shouldParseEmbedded(entrydata)) {
-                            extractor.parseEmbedded(subFile, handler, entrydata, true);
-                        }
-                    } finally {
-                        if (subFile != null)
-                            subFile.close();
-                    }
-                }
-
-                header = rar.nextFileHeader();
-            }
-
-        } catch (RarException e) {
-            throw new TikaException("RarParser Exception", e);
-        } finally {
-            if (rar != null)
-                rar.close();
-            tmp.close();
-        }
-
-        xhtml.endDocument();
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.pkg;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Collections;
+import java.util.Set;
+
+import org.apache.tika.exception.EncryptedDocumentException;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.extractor.EmbeddedDocumentExtractor;
+import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
+import org.apache.tika.io.TemporaryResources;
+import org.apache.tika.io.TikaInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+import com.github.junrar.Archive;
+import com.github.junrar.exception.RarException;
+import com.github.junrar.rarfile.FileHeader;
+
+/**
+ * Parser for Rar files.
+ */
+public class RarParser extends AbstractParser {
+    private static final long serialVersionUID = 6157727985054451501L;
+    
+    private static final Set<MediaType> SUPPORTED_TYPES = Collections
+            .singleton(MediaType.application("x-rar-compressed"));
+
+    @Override
+    public Set<MediaType> getSupportedTypes(ParseContext arg0) {
+        return SUPPORTED_TYPES;
+    }
+
+    @Override
+    public void parse(InputStream stream, ContentHandler handler,
+            Metadata metadata, ParseContext context) throws IOException,
+            SAXException, TikaException {
+
+        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
+        xhtml.startDocument();
+
+        EmbeddedDocumentExtractor extractor = context.get(
+                EmbeddedDocumentExtractor.class,
+                new ParsingEmbeddedDocumentExtractor(context));
+
+        TemporaryResources tmp = new TemporaryResources();
+        Archive rar = null;
+        try {
+            TikaInputStream tis = TikaInputStream.get(stream, tmp);
+            rar = new Archive(tis.getFile());
+
+            if (rar.isEncrypted()) {
+                throw new EncryptedDocumentException();
+            }
+
+            //Without this BodyContentHandler does not work
+            xhtml.element("div", " ");
+
+            FileHeader header = rar.nextFileHeader();
+            while (header != null && !Thread.currentThread().isInterrupted()) {
+                if (!header.isDirectory()) {
+                    InputStream subFile = null;
+                    try {
+                        subFile = rar.getInputStream(header);
+
+                        Metadata entrydata = PackageParser.handleEntryMetadata(
+                                "".equals(header.getFileNameW())?header.getFileNameString():header.getFileNameW(),
+                                header.getCTime(), header.getMTime(),
+                                header.getFullUnpackSize(),
+                                xhtml
+                        );
+
+                        if (extractor.shouldParseEmbedded(entrydata)) {
+                            extractor.parseEmbedded(subFile, handler, entrydata, true);
+                        }
+                    } finally {
+                        if (subFile != null)
+                            subFile.close();
+                    }
+                }
+
+                header = rar.nextFileHeader();
+            }
+
+        } catch (RarException e) {
+            throw new TikaException("RarParser Exception", e);
+        } finally {
+            if (rar != null)
+                rar.close();
+            tmp.close();
+        }
+
+        xhtml.endDocument();
+    }
+}
diff --git a/tika-parsers/src/main/resources/org/apache/tika/parser/pdf/PDFParser.properties b/tika-parsers/src/main/resources/org/apache/tika/parser/pdf/PDFParser.properties
index bdc23e54b..1585f2d8f 100644
--- a/tika-parsers/src/main/resources/org/apache/tika/parser/pdf/PDFParser.properties
+++ b/tika-parsers/src/main/resources/org/apache/tika/parser/pdf/PDFParser.properties
@@ -18,8 +18,8 @@ extractAnnotationText true
 sortByPosition	false
 suppressDuplicateOverlappingText	false
 useNonSequentialParser	false
-extractAcroFormContent	true
-extractInlineImages false
-extractUniqueInlineImagesOnly true
-checkExtractAccessPermission false
-allowExtractionForAccessibility true
+extractAcroFormContent	true
+extractInlineImages false
+extractUniqueInlineImagesOnly true
+checkExtractAccessPermission false
+allowExtractionForAccessibility true
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mock/MockParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mock/MockParserTest.java
index 32e9bc3ea..b1902eafd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mock/MockParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mock/MockParserTest.java
@@ -1,246 +1,246 @@
-package org.apache.tika.parser.mock;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import static junit.framework.TestCase.assertEquals;
-import static junit.framework.TestCase.assertTrue;
-import static org.junit.Assert.fail;
-
-import java.io.ByteArrayOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.PrintStream;
-import java.util.Date;
-
-import org.apache.tika.TikaTest;
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.io.IOUtils;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.AutoDetectParser;
-import org.apache.tika.parser.Parser;
-import org.junit.Test;
-
-public class MockParserTest extends TikaTest {
-    private final static String M = "/test-documents/mock/";
-    private final static Parser PARSER = new AutoDetectParser();
-
-    @Override
-    public XMLResult getXML(String path, Metadata m) throws Exception {
-        //note that this is specific to MockParserTest with addition of M to the path!
-        InputStream is = getResourceAsStream(M+path);
-        try {
-            return super.getXML(is, PARSER, m);
-        } finally {
-            IOUtils.closeQuietly(is);
-        }
-    }
-
-    @Test
-    public void testExample() throws Exception {
-        Metadata m = new Metadata();
-        PrintStream out = System.out;
-        PrintStream err = System.err;
-        ByteArrayOutputStream outBos = new ByteArrayOutputStream();
-        ByteArrayOutputStream errBos = new ByteArrayOutputStream();
-        PrintStream tmpOut = new PrintStream(outBos, true, IOUtils.UTF_8.toString());
-        PrintStream tmpErr = new PrintStream(errBos, true, IOUtils.UTF_8.toString());
-        System.setOut(tmpOut);
-        System.setErr(tmpErr);
-        try {
-            assertThrowable("example.xml", m, IOException.class, "not another IOException");
-            assertMockParser(m);
-        } finally {
-            System.setOut(out);
-            System.setErr(err);
-        }
-        String outString = new String(outBos.toByteArray(), IOUtils.UTF_8);
-        assertContains("writing to System.out", outString);
-
-        String errString = new String(errBos.toByteArray(), IOUtils.UTF_8);
-        assertContains("writing to System.err", errString);
-
-    }
-
-    @Test
-    public void testNothingBad() throws Exception {
-        Metadata m = new Metadata();
-        String content = getXML("nothing_bad.xml", m).xml;
-        assertEquals("Geoffrey Chaucer", m.get("author"));
-        assertContains("<p>And bathed every veyne in swich licour,</p>", content);
-        assertMockParser(m);
-    }
-
-    @Test
-    public void testNullPointer() throws Exception {
-        Metadata m = new Metadata();
-        assertThrowable("null_pointer.xml", m, NullPointerException.class, "another null pointer exception");
-        assertMockParser(m);
-    }
-
-    @Test
-    public void testNullPointerNoMsg() throws Exception {
-        Metadata m = new Metadata();
-        assertThrowable("null_pointer_no_msg.xml", m, NullPointerException.class, null);
-        assertMockParser(m);
-    }
-
-
-    @Test
-    public void testSleep() throws Exception {
-        long start = new Date().getTime();
-        Metadata m = new Metadata();
-        String content = getXML("sleep.xml", m).xml;
-        assertMockParser(m);
-        long elapsed = new Date().getTime()-start;
-        //should sleep for at least 3000
-        boolean enoughTimeHasElapsed = elapsed > 2000;
-        assertTrue("not enough time has not elapsed: "+elapsed, enoughTimeHasElapsed);
-        assertMockParser(m);
-    }
-
-    @Test
-    public void testHeavyHang() throws Exception {
-        long start = new Date().getTime();
-        Metadata m = new Metadata();
-
-        String content = getXML("heavy_hang.xml", m).xml;
-        assertMockParser(m);
-        long elapsed = new Date().getTime()-start;
-        //should sleep for at least 3000
-        boolean enoughTimeHasElapsed = elapsed > 2000;
-        assertTrue("not enough time has elapsed: "+elapsed, enoughTimeHasElapsed);
-        assertMockParser(m);
-    }
-
-    @Test
-    public void testFakeOOM() throws Exception {
-        Metadata m = new Metadata();
-        assertThrowable("fake_oom.xml", m, OutOfMemoryError.class, "not another oom");
-        assertMockParser(m);
-    }
-
-    @Test
-    public void testRealOOM() throws Exception {
-        //Note: we're not actually testing the diff between fake and real oom
-        //i.e. by creating child process and setting different -Xmx or
-        //memory profiling.
-        Metadata m = new Metadata();
-        assertThrowable("real_oom.xml", m, OutOfMemoryError.class, "Java heap space");
-        assertMockParser(m);
-    }
-
-    @Test
-    public void testInterruptibleSleep() {
-        //Without static initialization of the parser, it can take ~1 second after t.start()
-        //before the parser actually calls parse.  This is
-        //just the time it takes to instantiate and call AutoDetectParser, do the detection, etc.
-        //This is not thread creation overhead.
-        ParserRunnable r = new ParserRunnable("sleep_interruptible.xml");
-        Thread t = new Thread(r);
-        t.start();
-        long start = new Date().getTime();
-        try {
-            Thread.sleep(1000);
-        } catch (InterruptedException e) {
-            //swallow
-        }
-
-        t.interrupt();
-
-        try {
-            t.join(10000);
-        } catch (InterruptedException e) {
-            //swallow
-        }
-        long elapsed = new Date().getTime()-start;
-        boolean shortEnough = elapsed < 2000;//the xml file specifies 3000
-        assertTrue("elapsed (" + elapsed + " millis) was not short enough", shortEnough);
-    }
-
-    @Test
-    public void testNonInterruptibleSleep() {
-        ParserRunnable r = new ParserRunnable("sleep_not_interruptible.xml");
-        Thread t = new Thread(r);
-        t.start();
-        long start = new Date().getTime();
-        try {
-            //make sure that the thread has actually started
-            Thread.sleep(1000);
-        } catch (InterruptedException e) {
-            //swallow
-        }
-        t.interrupt();
-        try {
-            t.join(20000);
-        } catch (InterruptedException e) {
-            //swallow
-        }
-        long elapsed = new Date().getTime()-start;
-        boolean longEnough = elapsed > 3000;//the xml file specifies 3000, this sleeps 1000
-        assertTrue("elapsed ("+elapsed+" millis) was not long enough", longEnough);
-    }
-
-    private class ParserRunnable implements Runnable {
-        private final String path;
-        ParserRunnable(String path) {
-            this.path = path;
-        }
-        @Override
-        public void run() {
-            Metadata m = new Metadata();
-            try {
-                getXML(path, m);
-            } catch (Exception e) {
-                throw new RuntimeException(e);
-            } finally {
-                assertMockParser(m);
-            }
-        }
-    }
-
-    private void assertThrowable(String path, Metadata m, Class<? extends Throwable> expected, String message) {
-
-        try {
-            getXML(path, m);
-        } catch (Throwable t) {
-            //if this is a throwable wrapped in a TikaException, use the cause
-            if (t instanceof TikaException && t.getCause() != null) {
-                t = t.getCause();
-            }
-            if (! (t.getClass().isAssignableFrom(expected))){
-                fail(t.getClass() +" is not assignable from "+expected);
-            }
-            if (message != null) {
-                assertEquals(message, t.getMessage());
-            }
-        }
-    }
-
-    private void assertMockParser(Metadata m) {
-        String[] parsers = m.getValues("X-Parsed-By");
-        //make sure that it was actually parsed by mock.
-        boolean parsedByMock = false;
-        for (String parser : parsers) {
-            if (parser.equals("org.apache.tika.parser.mock.MockParser")) {
-                parsedByMock = true;
-                break;
-            }
-        }
-        assertTrue("mock parser should have been called", parsedByMock);
-    }
-}
+package org.apache.tika.parser.mock;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import static junit.framework.TestCase.assertEquals;
+import static junit.framework.TestCase.assertTrue;
+import static org.junit.Assert.fail;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.PrintStream;
+import java.util.Date;
+
+import org.apache.tika.TikaTest;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.io.IOUtils;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.Parser;
+import org.junit.Test;
+
+public class MockParserTest extends TikaTest {
+    private final static String M = "/test-documents/mock/";
+    private final static Parser PARSER = new AutoDetectParser();
+
+    @Override
+    public XMLResult getXML(String path, Metadata m) throws Exception {
+        //note that this is specific to MockParserTest with addition of M to the path!
+        InputStream is = getResourceAsStream(M+path);
+        try {
+            return super.getXML(is, PARSER, m);
+        } finally {
+            IOUtils.closeQuietly(is);
+        }
+    }
+
+    @Test
+    public void testExample() throws Exception {
+        Metadata m = new Metadata();
+        PrintStream out = System.out;
+        PrintStream err = System.err;
+        ByteArrayOutputStream outBos = new ByteArrayOutputStream();
+        ByteArrayOutputStream errBos = new ByteArrayOutputStream();
+        PrintStream tmpOut = new PrintStream(outBos, true, IOUtils.UTF_8.toString());
+        PrintStream tmpErr = new PrintStream(errBos, true, IOUtils.UTF_8.toString());
+        System.setOut(tmpOut);
+        System.setErr(tmpErr);
+        try {
+            assertThrowable("example.xml", m, IOException.class, "not another IOException");
+            assertMockParser(m);
+        } finally {
+            System.setOut(out);
+            System.setErr(err);
+        }
+        String outString = new String(outBos.toByteArray(), IOUtils.UTF_8);
+        assertContains("writing to System.out", outString);
+
+        String errString = new String(errBos.toByteArray(), IOUtils.UTF_8);
+        assertContains("writing to System.err", errString);
+
+    }
+
+    @Test
+    public void testNothingBad() throws Exception {
+        Metadata m = new Metadata();
+        String content = getXML("nothing_bad.xml", m).xml;
+        assertEquals("Geoffrey Chaucer", m.get("author"));
+        assertContains("<p>And bathed every veyne in swich licour,</p>", content);
+        assertMockParser(m);
+    }
+
+    @Test
+    public void testNullPointer() throws Exception {
+        Metadata m = new Metadata();
+        assertThrowable("null_pointer.xml", m, NullPointerException.class, "another null pointer exception");
+        assertMockParser(m);
+    }
+
+    @Test
+    public void testNullPointerNoMsg() throws Exception {
+        Metadata m = new Metadata();
+        assertThrowable("null_pointer_no_msg.xml", m, NullPointerException.class, null);
+        assertMockParser(m);
+    }
+
+
+    @Test
+    public void testSleep() throws Exception {
+        long start = new Date().getTime();
+        Metadata m = new Metadata();
+        String content = getXML("sleep.xml", m).xml;
+        assertMockParser(m);
+        long elapsed = new Date().getTime()-start;
+        //should sleep for at least 3000
+        boolean enoughTimeHasElapsed = elapsed > 2000;
+        assertTrue("not enough time has not elapsed: "+elapsed, enoughTimeHasElapsed);
+        assertMockParser(m);
+    }
+
+    @Test
+    public void testHeavyHang() throws Exception {
+        long start = new Date().getTime();
+        Metadata m = new Metadata();
+
+        String content = getXML("heavy_hang.xml", m).xml;
+        assertMockParser(m);
+        long elapsed = new Date().getTime()-start;
+        //should sleep for at least 3000
+        boolean enoughTimeHasElapsed = elapsed > 2000;
+        assertTrue("not enough time has elapsed: "+elapsed, enoughTimeHasElapsed);
+        assertMockParser(m);
+    }
+
+    @Test
+    public void testFakeOOM() throws Exception {
+        Metadata m = new Metadata();
+        assertThrowable("fake_oom.xml", m, OutOfMemoryError.class, "not another oom");
+        assertMockParser(m);
+    }
+
+    @Test
+    public void testRealOOM() throws Exception {
+        //Note: we're not actually testing the diff between fake and real oom
+        //i.e. by creating child process and setting different -Xmx or
+        //memory profiling.
+        Metadata m = new Metadata();
+        assertThrowable("real_oom.xml", m, OutOfMemoryError.class, "Java heap space");
+        assertMockParser(m);
+    }
+
+    @Test
+    public void testInterruptibleSleep() {
+        //Without static initialization of the parser, it can take ~1 second after t.start()
+        //before the parser actually calls parse.  This is
+        //just the time it takes to instantiate and call AutoDetectParser, do the detection, etc.
+        //This is not thread creation overhead.
+        ParserRunnable r = new ParserRunnable("sleep_interruptible.xml");
+        Thread t = new Thread(r);
+        t.start();
+        long start = new Date().getTime();
+        try {
+            Thread.sleep(1000);
+        } catch (InterruptedException e) {
+            //swallow
+        }
+
+        t.interrupt();
+
+        try {
+            t.join(10000);
+        } catch (InterruptedException e) {
+            //swallow
+        }
+        long elapsed = new Date().getTime()-start;
+        boolean shortEnough = elapsed < 2000;//the xml file specifies 3000
+        assertTrue("elapsed (" + elapsed + " millis) was not short enough", shortEnough);
+    }
+
+    @Test
+    public void testNonInterruptibleSleep() {
+        ParserRunnable r = new ParserRunnable("sleep_not_interruptible.xml");
+        Thread t = new Thread(r);
+        t.start();
+        long start = new Date().getTime();
+        try {
+            //make sure that the thread has actually started
+            Thread.sleep(1000);
+        } catch (InterruptedException e) {
+            //swallow
+        }
+        t.interrupt();
+        try {
+            t.join(20000);
+        } catch (InterruptedException e) {
+            //swallow
+        }
+        long elapsed = new Date().getTime()-start;
+        boolean longEnough = elapsed > 3000;//the xml file specifies 3000, this sleeps 1000
+        assertTrue("elapsed ("+elapsed+" millis) was not long enough", longEnough);
+    }
+
+    private class ParserRunnable implements Runnable {
+        private final String path;
+        ParserRunnable(String path) {
+            this.path = path;
+        }
+        @Override
+        public void run() {
+            Metadata m = new Metadata();
+            try {
+                getXML(path, m);
+            } catch (Exception e) {
+                throw new RuntimeException(e);
+            } finally {
+                assertMockParser(m);
+            }
+        }
+    }
+
+    private void assertThrowable(String path, Metadata m, Class<? extends Throwable> expected, String message) {
+
+        try {
+            getXML(path, m);
+        } catch (Throwable t) {
+            //if this is a throwable wrapped in a TikaException, use the cause
+            if (t instanceof TikaException && t.getCause() != null) {
+                t = t.getCause();
+            }
+            if (! (t.getClass().isAssignableFrom(expected))){
+                fail(t.getClass() +" is not assignable from "+expected);
+            }
+            if (message != null) {
+                assertEquals(message, t.getMessage());
+            }
+        }
+    }
+
+    private void assertMockParser(Metadata m) {
+        String[] parsers = m.getValues("X-Parsed-By");
+        //make sure that it was actually parsed by mock.
+        boolean parsedByMock = false;
+        for (String parser : parsers) {
+            if (parser.equals("org.apache.tika.parser.mock.MockParser")) {
+                parsedByMock = true;
+                break;
+            }
+        }
+        assertTrue("mock parser should have been called", parsedByMock);
+    }
+}
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/AccessCheckerTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/AccessCheckerTest.java
index 705de5d51..923dd5b5a 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/AccessCheckerTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/AccessCheckerTest.java
@@ -1,137 +1,137 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.parser.pdf;
-
-
-import static org.junit.Assert.assertTrue;
-
-import org.apache.tika.exception.AccessPermissionException;
-import org.apache.tika.metadata.AccessPermissions;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.metadata.PropertyTypeException;
-import org.junit.Test;
-
-public class AccessCheckerTest {
-
-    @Test
-    public void testLegacy() throws AccessPermissionException{
-
-        Metadata m = getMetadata(false, false);
-        //legacy behavior; don't bother checking
-        AccessChecker checker = new AccessChecker();
-        checker.check(m);
-        assertTrue("no exception", true);
-
-        m = getMetadata(false, true);
-        assertTrue("no exception", true);
-        checker.check(m);
-
-        m = getMetadata(true, true);
-        assertTrue("no exception", true);
-        checker.check(m);
-    }
-
-    @Test
-    public void testNoExtraction() {
-
-        Metadata m = null;
-        //allow nothing
-        AccessChecker checker = new AccessChecker(false);
-        boolean ex = false;
-        try {
-            m = getMetadata(false, false);
-            checker.check(m);
-        } catch (AccessPermissionException e) {
-            ex = true;
-        }
-        assertTrue("correct exception with no extraction, no extract for accessibility", ex);
-        ex = false;
-        try {
-            //document allows extraction for accessibility
-            m = getMetadata(false, true);
-            checker.check(m);
-        } catch (AccessPermissionException e) {
-            //but application is not an accessibility application
-            ex = true;
-        }
-        assertTrue("correct exception with no extraction, no extract for accessibility", ex);
-    }
-
-    @Test
-    public void testExtractOnlyForAccessibility() throws AccessPermissionException {
-        Metadata m = getMetadata(false, true);
-        //allow accessibility
-        AccessChecker checker = new AccessChecker(true);
-        checker.check(m);
-        assertTrue("no exception", true);
-        boolean ex = false;
-        try {
-            m = getMetadata(false, false);
-            checker.check(m);
-        } catch (AccessPermissionException e) {
-            ex = true;
-        }
-        assertTrue("correct exception", ex);
-    }
-
-    @Test
-    public void testCrazyExtractNotForAccessibility() throws AccessPermissionException {
-        Metadata m = getMetadata(true, false);
-        //allow accessibility
-        AccessChecker checker = new AccessChecker(true);
-        checker.check(m);
-        assertTrue("no exception", true);
-
-        //don't extract for accessibility
-        checker = new AccessChecker(false);
-        //if extract content is allowed, the checker shouldn't
-        //check the value of extract for accessibility
-        checker.check(m);
-        assertTrue("no exception", true);
-
-    }
-
-    @Test
-    public void testCantAddMultiplesToMetadata() {
-        Metadata m = new Metadata();
-        boolean ex = false;
-        m.add(AccessPermissions.EXTRACT_CONTENT, "true");
-        try {
-            m.add(AccessPermissions.EXTRACT_CONTENT, "false");
-        } catch (PropertyTypeException e) {
-            ex = true;
-        }
-        assertTrue("can't add multiple values", ex);
-
-        m = new Metadata();
-        ex = false;
-        m.add(AccessPermissions.EXTRACT_FOR_ACCESSIBILITY, "true");
-        try {
-            m.add(AccessPermissions.EXTRACT_FOR_ACCESSIBILITY, "false");
-        } catch (PropertyTypeException e) {
-            ex = true;
-        }
-        assertTrue("can't add multiple values", ex);
-    }
-
-    private Metadata getMetadata(boolean allowExtraction, boolean allowExtractionForAccessibility) {
-        Metadata m = new Metadata();
-        m.set(AccessPermissions.EXTRACT_CONTENT, Boolean.toString(allowExtraction));
-        m.set(AccessPermissions.EXTRACT_FOR_ACCESSIBILITY, Boolean.toString(allowExtractionForAccessibility));
-        return m;
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.pdf;
+
+
+import static org.junit.Assert.assertTrue;
+
+import org.apache.tika.exception.AccessPermissionException;
+import org.apache.tika.metadata.AccessPermissions;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.PropertyTypeException;
+import org.junit.Test;
+
+public class AccessCheckerTest {
+
+    @Test
+    public void testLegacy() throws AccessPermissionException{
+
+        Metadata m = getMetadata(false, false);
+        //legacy behavior; don't bother checking
+        AccessChecker checker = new AccessChecker();
+        checker.check(m);
+        assertTrue("no exception", true);
+
+        m = getMetadata(false, true);
+        assertTrue("no exception", true);
+        checker.check(m);
+
+        m = getMetadata(true, true);
+        assertTrue("no exception", true);
+        checker.check(m);
+    }
+
+    @Test
+    public void testNoExtraction() {
+
+        Metadata m = null;
+        //allow nothing
+        AccessChecker checker = new AccessChecker(false);
+        boolean ex = false;
+        try {
+            m = getMetadata(false, false);
+            checker.check(m);
+        } catch (AccessPermissionException e) {
+            ex = true;
+        }
+        assertTrue("correct exception with no extraction, no extract for accessibility", ex);
+        ex = false;
+        try {
+            //document allows extraction for accessibility
+            m = getMetadata(false, true);
+            checker.check(m);
+        } catch (AccessPermissionException e) {
+            //but application is not an accessibility application
+            ex = true;
+        }
+        assertTrue("correct exception with no extraction, no extract for accessibility", ex);
+    }
+
+    @Test
+    public void testExtractOnlyForAccessibility() throws AccessPermissionException {
+        Metadata m = getMetadata(false, true);
+        //allow accessibility
+        AccessChecker checker = new AccessChecker(true);
+        checker.check(m);
+        assertTrue("no exception", true);
+        boolean ex = false;
+        try {
+            m = getMetadata(false, false);
+            checker.check(m);
+        } catch (AccessPermissionException e) {
+            ex = true;
+        }
+        assertTrue("correct exception", ex);
+    }
+
+    @Test
+    public void testCrazyExtractNotForAccessibility() throws AccessPermissionException {
+        Metadata m = getMetadata(true, false);
+        //allow accessibility
+        AccessChecker checker = new AccessChecker(true);
+        checker.check(m);
+        assertTrue("no exception", true);
+
+        //don't extract for accessibility
+        checker = new AccessChecker(false);
+        //if extract content is allowed, the checker shouldn't
+        //check the value of extract for accessibility
+        checker.check(m);
+        assertTrue("no exception", true);
+
+    }
+
+    @Test
+    public void testCantAddMultiplesToMetadata() {
+        Metadata m = new Metadata();
+        boolean ex = false;
+        m.add(AccessPermissions.EXTRACT_CONTENT, "true");
+        try {
+            m.add(AccessPermissions.EXTRACT_CONTENT, "false");
+        } catch (PropertyTypeException e) {
+            ex = true;
+        }
+        assertTrue("can't add multiple values", ex);
+
+        m = new Metadata();
+        ex = false;
+        m.add(AccessPermissions.EXTRACT_FOR_ACCESSIBILITY, "true");
+        try {
+            m.add(AccessPermissions.EXTRACT_FOR_ACCESSIBILITY, "false");
+        } catch (PropertyTypeException e) {
+            ex = true;
+        }
+        assertTrue("can't add multiple values", ex);
+    }
+
+    private Metadata getMetadata(boolean allowExtraction, boolean allowExtractionForAccessibility) {
+        Metadata m = new Metadata();
+        m.set(AccessPermissions.EXTRACT_CONTENT, Boolean.toString(allowExtraction));
+        m.set(AccessPermissions.EXTRACT_FOR_ACCESSIBILITY, Boolean.toString(allowExtractionForAccessibility));
+        return m;
+    }
+}
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pkg/RarParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pkg/RarParserTest.java
index 596853cf5..f224120fd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pkg/RarParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pkg/RarParserTest.java
@@ -1,132 +1,132 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.parser.pkg;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
-
-import java.io.InputStream;
-
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.AutoDetectParser;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.sax.BodyContentHandler;
-import org.junit.Test;
-import org.xml.sax.ContentHandler;
-
-/**
- * Test case for parsing rar files.
- */
-public class RarParserTest extends AbstractPkgTest {
-
-    @Test
-    public void testRarParsing() throws Exception {
-        Parser parser = new AutoDetectParser(); // Should auto-detect!
-        ContentHandler handler = new BodyContentHandler();
-        Metadata metadata = new Metadata();
-
-        InputStream stream = RarParserTest.class.getResourceAsStream(
-                "/test-documents/test-documents.rar");
-        try {
-            parser.parse(stream, handler, metadata, recursingContext);
-        } finally {
-            stream.close();
-        }
-
-        assertEquals("application/x-rar-compressed", metadata.get(Metadata.CONTENT_TYPE));
-        String content = handler.toString();
-        assertContains("test-documents/testEXCEL.xls", content);
-        assertContains("Sample Excel Worksheet", content);
-        assertContains("test-documents/testHTML.html", content);
-        assertContains("Test Indexation Html", content);
-        assertContains("test-documents/testOpenOffice2.odt", content);
-        assertContains("This is a sample Open Office document", content);
-        assertContains("test-documents/testPDF.pdf", content);
-        assertContains("Apache Tika", content);
-        assertContains("test-documents/testPPT.ppt", content);
-        assertContains("Sample Powerpoint Slide", content);
-        assertContains("test-documents/testRTF.rtf", content);
-        assertContains("indexation Word", content);
-        assertContains("test-documents/testTXT.txt", content);
-        assertContains("Test d'indexation de Txt", content);
-        assertContains("test-documents/testWORD.doc", content);
-        assertContains("This is a sample Microsoft Word Document", content);
-        assertContains("test-documents/testXML.xml", content);
-        assertContains("Rida Benjelloun", content);
-    }
-
-    /**
-     * Tests that the ParseContext parser is correctly
-     *  fired for all the embedded entries.
-     */
-    @Test
-    public void testEmbedded() throws Exception {
-       Parser parser = new AutoDetectParser(); // Should auto-detect!
-       ContentHandler handler = new BodyContentHandler();
-       Metadata metadata = new Metadata();
-
-       InputStream stream = RarParserTest.class.getResourceAsStream(
-               "/test-documents/test-documents.rar");
-       try {
-           parser.parse(stream, handler, metadata, trackingContext);
-       } finally {
-           stream.close();
-       }
-       
-       // Should have found all 9 documents, but not the directory
-       assertEquals(9, tracker.filenames.size());
-       assertEquals(9, tracker.mediatypes.size());
-       assertEquals(9, tracker.modifiedAts.size());
-       
-       // Should have names but not content types, as rar doesn't
-       //  store the content types
-       assertEquals("test-documents/testEXCEL.xls", tracker.filenames.get(0));
-       assertEquals("test-documents/testHTML.html", tracker.filenames.get(1));
-       assertEquals("test-documents/testOpenOffice2.odt", tracker.filenames.get(2));
-       assertEquals("test-documents/testPDF.pdf", tracker.filenames.get(3));
-       assertEquals("test-documents/testPPT.ppt", tracker.filenames.get(4));
-       assertEquals("test-documents/testRTF.rtf", tracker.filenames.get(5));
-       assertEquals("test-documents/testTXT.txt", tracker.filenames.get(6));
-       assertEquals("test-documents/testWORD.doc", tracker.filenames.get(7));
-       assertEquals("test-documents/testXML.xml", tracker.filenames.get(8));
-       
-       for(String type : tracker.mediatypes) {
-          assertNull(type);
-       }
-       for(String crt : tracker.createdAts) {
-           assertNull(crt);
-       }
-       for(String mod : tracker.modifiedAts) {
-           assertNotNull(mod);
-           assertTrue("Modified at " + mod, mod.startsWith("20"));
-       }
-       
-       // Should have filenames in the content string
-       String content = handler.toString();
-       assertContains("test-documents/testHTML.html", content);
-       assertContains("test-documents/testEXCEL.xls", content);
-       assertContains("test-documents/testOpenOffice2.odt", content);
-       assertContains("test-documents/testPDF.pdf", content);
-       assertContains("test-documents/testPPT.ppt", content);
-       assertContains("test-documents/testRTF.rtf", content);
-       assertContains("test-documents/testTXT.txt", content);
-       assertContains("test-documents/testWORD.doc", content);
-       assertContains("test-documents/testXML.xml", content);
-    }
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.pkg;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
+
+import java.io.InputStream;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.junit.Test;
+import org.xml.sax.ContentHandler;
+
+/**
+ * Test case for parsing rar files.
+ */
+public class RarParserTest extends AbstractPkgTest {
+
+    @Test
+    public void testRarParsing() throws Exception {
+        Parser parser = new AutoDetectParser(); // Should auto-detect!
+        ContentHandler handler = new BodyContentHandler();
+        Metadata metadata = new Metadata();
+
+        InputStream stream = RarParserTest.class.getResourceAsStream(
+                "/test-documents/test-documents.rar");
+        try {
+            parser.parse(stream, handler, metadata, recursingContext);
+        } finally {
+            stream.close();
+        }
+
+        assertEquals("application/x-rar-compressed", metadata.get(Metadata.CONTENT_TYPE));
+        String content = handler.toString();
+        assertContains("test-documents/testEXCEL.xls", content);
+        assertContains("Sample Excel Worksheet", content);
+        assertContains("test-documents/testHTML.html", content);
+        assertContains("Test Indexation Html", content);
+        assertContains("test-documents/testOpenOffice2.odt", content);
+        assertContains("This is a sample Open Office document", content);
+        assertContains("test-documents/testPDF.pdf", content);
+        assertContains("Apache Tika", content);
+        assertContains("test-documents/testPPT.ppt", content);
+        assertContains("Sample Powerpoint Slide", content);
+        assertContains("test-documents/testRTF.rtf", content);
+        assertContains("indexation Word", content);
+        assertContains("test-documents/testTXT.txt", content);
+        assertContains("Test d'indexation de Txt", content);
+        assertContains("test-documents/testWORD.doc", content);
+        assertContains("This is a sample Microsoft Word Document", content);
+        assertContains("test-documents/testXML.xml", content);
+        assertContains("Rida Benjelloun", content);
+    }
+
+    /**
+     * Tests that the ParseContext parser is correctly
+     *  fired for all the embedded entries.
+     */
+    @Test
+    public void testEmbedded() throws Exception {
+       Parser parser = new AutoDetectParser(); // Should auto-detect!
+       ContentHandler handler = new BodyContentHandler();
+       Metadata metadata = new Metadata();
+
+       InputStream stream = RarParserTest.class.getResourceAsStream(
+               "/test-documents/test-documents.rar");
+       try {
+           parser.parse(stream, handler, metadata, trackingContext);
+       } finally {
+           stream.close();
+       }
+       
+       // Should have found all 9 documents, but not the directory
+       assertEquals(9, tracker.filenames.size());
+       assertEquals(9, tracker.mediatypes.size());
+       assertEquals(9, tracker.modifiedAts.size());
+       
+       // Should have names but not content types, as rar doesn't
+       //  store the content types
+       assertEquals("test-documents/testEXCEL.xls", tracker.filenames.get(0));
+       assertEquals("test-documents/testHTML.html", tracker.filenames.get(1));
+       assertEquals("test-documents/testOpenOffice2.odt", tracker.filenames.get(2));
+       assertEquals("test-documents/testPDF.pdf", tracker.filenames.get(3));
+       assertEquals("test-documents/testPPT.ppt", tracker.filenames.get(4));
+       assertEquals("test-documents/testRTF.rtf", tracker.filenames.get(5));
+       assertEquals("test-documents/testTXT.txt", tracker.filenames.get(6));
+       assertEquals("test-documents/testWORD.doc", tracker.filenames.get(7));
+       assertEquals("test-documents/testXML.xml", tracker.filenames.get(8));
+       
+       for(String type : tracker.mediatypes) {
+          assertNull(type);
+       }
+       for(String crt : tracker.createdAts) {
+           assertNull(crt);
+       }
+       for(String mod : tracker.modifiedAts) {
+           assertNotNull(mod);
+           assertTrue("Modified at " + mod, mod.startsWith("20"));
+       }
+       
+       // Should have filenames in the content string
+       String content = handler.toString();
+       assertContains("test-documents/testHTML.html", content);
+       assertContains("test-documents/testEXCEL.xls", content);
+       assertContains("test-documents/testOpenOffice2.odt", content);
+       assertContains("test-documents/testPDF.pdf", content);
+       assertContains("test-documents/testPPT.ppt", content);
+       assertContains("test-documents/testRTF.rtf", content);
+       assertContains("test-documents/testTXT.txt", content);
+       assertContains("test-documents/testWORD.doc", content);
+       assertContains("test-documents/testXML.xml", content);
+    }
 }
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/example.xml b/tika-parsers/src/test/resources/test-documents/mock/example.xml
index 585524cf9..df1a7624d 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/example.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/example.xml
@@ -1,51 +1,51 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <!-- this file offers all of the options as documentation
-    Parsing should stop at an IOException, of course
-    -->
-
-    <!-- action can be "add" or "set" -->
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <!-- element is the name of the sax event to write, p=paragraph
-        if the element is not specified, the default is <p> -->
-    <write element="p">some content</write>
-    <!-- write something to System.out -->
-    <print_out>writing to System.out</print_out>
-    <!-- write something to System.err -->
-    <print_err>writing to System.err</print_err>
-    <!-- hang
-        millis: how many milliseconds to pause.  The actual hang time will probably
-            be a bit longer than the value specified.        heavy: whether or not the hang should do something computationally expensive.
-            If the value is false, this just does a Thread.sleep(millis).
-            This attribute is optional, with default of heavy=false.
-        pulse_millis: (required if "heavy" is true), how often to check to see
-            whether the thread was interrupted or that the total hang time exceeded the millis
-        interruptible: whether or not the parser will check to see if its thread
-            has been interrupted; this attribute is optional with default of true
-    -->
-    <hang millis="100" heavy="true" pulse_millis="10" interruptible="true" />
-    <!-- throw an exception or error; optionally include a message or not -->
-    <throw class="java.io.IOException">not another IOException</throw>
-    <!-- perform a genuine OutOfMemoryError -->
-    <oom/>
+<?xml version="1.0" encoding="UTF-8" ?>
+
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <!-- this file offers all of the options as documentation
+    Parsing should stop at an IOException, of course
+    -->
+
+    <!-- action can be "add" or "set" -->
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <!-- element is the name of the sax event to write, p=paragraph
+        if the element is not specified, the default is <p> -->
+    <write element="p">some content</write>
+    <!-- write something to System.out -->
+    <print_out>writing to System.out</print_out>
+    <!-- write something to System.err -->
+    <print_err>writing to System.err</print_err>
+    <!-- hang
+        millis: how many milliseconds to pause.  The actual hang time will probably
+            be a bit longer than the value specified.        heavy: whether or not the hang should do something computationally expensive.
+            If the value is false, this just does a Thread.sleep(millis).
+            This attribute is optional, with default of heavy=false.
+        pulse_millis: (required if "heavy" is true), how often to check to see
+            whether the thread was interrupted or that the total hang time exceeded the millis
+        interruptible: whether or not the parser will check to see if its thread
+            has been interrupted; this attribute is optional with default of true
+    -->
+    <hang millis="100" heavy="true" pulse_millis="10" interruptible="true" />
+    <!-- throw an exception or error; optionally include a message or not -->
+    <throw class="java.io.IOException">not another IOException</throw>
+    <!-- perform a genuine OutOfMemoryError -->
+    <oom/>
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/fake_oom.xml b/tika-parsers/src/test/resources/test-documents/mock/fake_oom.xml
index 0c512b197..6f090d4e9 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/fake_oom.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/fake_oom.xml
@@ -1,25 +1,25 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <throw class="java.lang.OutOfMemoryError">not another oom</throw>
+<?xml version="1.0" encoding="UTF-8" ?>
+
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <throw class="java.lang.OutOfMemoryError">not another oom</throw>
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/heavy_hang.xml b/tika-parsers/src/test/resources/test-documents/mock/heavy_hang.xml
index 8be9a3bbb..df5bbfd48 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/heavy_hang.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/heavy_hang.xml
@@ -1,25 +1,25 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <write element="p">some content</write>
-    <hang millis="3000" heavy="true" pulse_millis="100" />
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <write element="p">some content</write>
+    <hang millis="3000" heavy="true" pulse_millis="100" />
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/nothing_bad.xml b/tika-parsers/src/test/resources/test-documents/mock/nothing_bad.xml
index c7ce67b0c..e3656a82e 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/nothing_bad.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/nothing_bad.xml
@@ -1,26 +1,26 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Geoffrey Chaucer</metadata>
-    <write element="p">Whan that Aprille with his shoures soote</write>
-    <write>The droghte of Marche hath perced to the roote,</write>
-    <write>And bathed every veyne in swich licour,</write>
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Geoffrey Chaucer</metadata>
+    <write element="p">Whan that Aprille with his shoures soote</write>
+    <write>The droghte of Marche hath perced to the roote,</write>
+    <write>And bathed every veyne in swich licour,</write>
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/null_pointer.xml b/tika-parsers/src/test/resources/test-documents/mock/null_pointer.xml
index 4b25210a8..4561c3a89 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/null_pointer.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/null_pointer.xml
@@ -1,25 +1,25 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <write element="p">some content</write>
-    <throw class="java.lang.NullPointerException">another null pointer exception</throw>
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <write element="p">some content</write>
+    <throw class="java.lang.NullPointerException">another null pointer exception</throw>
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/null_pointer_no_msg.xml b/tika-parsers/src/test/resources/test-documents/mock/null_pointer_no_msg.xml
index 3da2b7339..33f3f837c 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/null_pointer_no_msg.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/null_pointer_no_msg.xml
@@ -1,25 +1,25 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <write element="p">some content</write>
-    <throw class="java.lang.NullPointerException"/>
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <write element="p">some content</write>
+    <throw class="java.lang.NullPointerException"/>
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/real_oom.xml b/tika-parsers/src/test/resources/test-documents/mock/real_oom.xml
index c766d7110..168751a20 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/real_oom.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/real_oom.xml
@@ -1,24 +1,24 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <oom/>
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <oom/>
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/sleep.xml b/tika-parsers/src/test/resources/test-documents/mock/sleep.xml
index 07f5e3784..991cdc2ef 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/sleep.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/sleep.xml
@@ -1,25 +1,25 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <write element="p">some content</write>
-    <hang millis="3000" heavy="false"  />
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <write element="p">some content</write>
+    <hang millis="3000" heavy="false"  />
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/sleep_interruptible.xml b/tika-parsers/src/test/resources/test-documents/mock/sleep_interruptible.xml
index 7cd71eb79..8d84ead37 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/sleep_interruptible.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/sleep_interruptible.xml
@@ -1,25 +1,25 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <write element="p">some content</write>
-    <hang millis="3000" heavy="false" interruptible="true" />
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <write element="p">some content</write>
+    <hang millis="3000" heavy="false" interruptible="true" />
 </mock>
\ No newline at end of file
diff --git a/tika-parsers/src/test/resources/test-documents/mock/sleep_not_interruptible.xml b/tika-parsers/src/test/resources/test-documents/mock/sleep_not_interruptible.xml
index 9ddb885d4..7994095f7 100644
--- a/tika-parsers/src/test/resources/test-documents/mock/sleep_not_interruptible.xml
+++ b/tika-parsers/src/test/resources/test-documents/mock/sleep_not_interruptible.xml
@@ -1,25 +1,25 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
--->
-
-<mock>
-    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
-    <write element="p">some content</write>
-    <hang millis="3000" heavy="false" interruptible="false" />
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<mock>
+    <metadata action="add" name="author">Nikolai Lobachevsky</metadata>
+    <write element="p">some content</write>
+    <hang millis="3000" heavy="false" interruptible="false" />
 </mock>
\ No newline at end of file
diff --git a/tika-serialization/src/main/java/org/apache/tika/metadata/serialization/JsonMetadataBase.java b/tika-serialization/src/main/java/org/apache/tika/metadata/serialization/JsonMetadataBase.java
index 016012208..90bfca884 100644
--- a/tika-serialization/src/main/java/org/apache/tika/metadata/serialization/JsonMetadataBase.java
+++ b/tika-serialization/src/main/java/org/apache/tika/metadata/serialization/JsonMetadataBase.java
@@ -1,52 +1,52 @@
-package org.apache.tika.metadata.serialization;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Arrays;
-
-import com.google.gson.Gson;
-import com.google.gson.GsonBuilder;
-import org.apache.tika.metadata.Metadata;
-
-public class JsonMetadataBase {
-
-
-    static Gson defaultInit() {
-        GsonBuilder builder = new GsonBuilder();
-        builder.registerTypeHierarchyAdapter(Metadata.class, new JsonMetadataSerializer());
-        builder.registerTypeHierarchyAdapter(Metadata.class, new JsonMetadataDeserializer());
-        return builder.create();
-    }
-
-    static Gson prettyInit() {
-        GsonBuilder builder = new GsonBuilder();
-        builder.registerTypeHierarchyAdapter(Metadata.class, new SortedJsonMetadataSerializer());
-        builder.registerTypeHierarchyAdapter(Metadata.class, new JsonMetadataDeserializer());
-        builder.setPrettyPrinting();
-        return builder.create();
-    }
-
-    private static class SortedJsonMetadataSerializer extends JsonMetadataSerializer {
-        @Override
-        public String[] getNames(Metadata m) {
-            String[] names = m.names();
-            Arrays.sort(names, new PrettyMetadataKeyComparator());
-            return names;
-        }
-    }
-}
+package org.apache.tika.metadata.serialization;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Arrays;
+
+import com.google.gson.Gson;
+import com.google.gson.GsonBuilder;
+import org.apache.tika.metadata.Metadata;
+
+public class JsonMetadataBase {
+
+
+    static Gson defaultInit() {
+        GsonBuilder builder = new GsonBuilder();
+        builder.registerTypeHierarchyAdapter(Metadata.class, new JsonMetadataSerializer());
+        builder.registerTypeHierarchyAdapter(Metadata.class, new JsonMetadataDeserializer());
+        return builder.create();
+    }
+
+    static Gson prettyInit() {
+        GsonBuilder builder = new GsonBuilder();
+        builder.registerTypeHierarchyAdapter(Metadata.class, new SortedJsonMetadataSerializer());
+        builder.registerTypeHierarchyAdapter(Metadata.class, new JsonMetadataDeserializer());
+        builder.setPrettyPrinting();
+        return builder.create();
+    }
+
+    private static class SortedJsonMetadataSerializer extends JsonMetadataSerializer {
+        @Override
+        public String[] getNames(Metadata m) {
+            String[] names = m.names();
+            Arrays.sort(names, new PrettyMetadataKeyComparator());
+            return names;
+        }
+    }
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/HTMLHelper.java b/tika-server/src/main/java/org/apache/tika/server/HTMLHelper.java
index 3935850f9..da68a5088 100644
--- a/tika-server/src/main/java/org/apache/tika/server/HTMLHelper.java
+++ b/tika-server/src/main/java/org/apache/tika/server/HTMLHelper.java
@@ -21,22 +21,22 @@ import java.io.IOException;
 import java.io.InputStream;
 
 import org.apache.tika.io.IOUtils;
-
-/**
- * Helps produce user facing HTML output.
- * <p/>
- * TODO Decide if this would be better done as a MessageBodyWriter
- */
-public class HTMLHelper {
+
+/**
+ * Helps produce user facing HTML output.
+ * <p/>
+ * TODO Decide if this would be better done as a MessageBodyWriter
+ */
+public class HTMLHelper {
     private static final String PATH = "/tikaserver-template.html";
     private static final String TITLE_VAR = "[[TITLE]]";
-    private static final String BODY_VAR = "[[BODY]]";
-    private String PRE_BODY;
-    private String POST_BODY;
-
-    public HTMLHelper() {
-        InputStream htmlStr = getClass().getResourceAsStream(PATH);
-        if (htmlStr == null) {
+    private static final String BODY_VAR = "[[BODY]]";
+    private String PRE_BODY;
+    private String POST_BODY;
+
+    public HTMLHelper() {
+        InputStream htmlStr = getClass().getResourceAsStream(PATH);
+        if (htmlStr == null) {
             throw new IllegalArgumentException("Template Not Found - " + PATH);
         }
         try {
@@ -45,18 +45,18 @@ public class HTMLHelper {
             PRE_BODY = html.substring(0, bodyAt);
             POST_BODY = html.substring(bodyAt + BODY_VAR.length());
         } catch (IOException e) {
-            throw new IllegalStateException("Unable to read template");
-        }
-    }
-
-    /**
-     * Generates the HTML Header for the user facing page, adding
-     * in the given title as required
-     */
-    public void generateHeader(StringBuffer html, String title) {
-        html.append(PRE_BODY.replace(TITLE_VAR, title));
-    }
-
-    public void generateFooter(StringBuffer html) {
-        html.append(POST_BODY);
+            throw new IllegalStateException("Unable to read template");
+        }
+    }
+
+    /**
+     * Generates the HTML Header for the user facing page, adding
+     * in the given title as required
+     */
+    public void generateHeader(StringBuffer html, String title) {
+        html.append(PRE_BODY.replace(TITLE_VAR, title));
+    }
+
+    public void generateFooter(StringBuffer html) {
+        html.append(POST_BODY);
     }}
\ No newline at end of file
diff --git a/tika-server/src/main/java/org/apache/tika/server/RichTextContentHandler.java b/tika-server/src/main/java/org/apache/tika/server/RichTextContentHandler.java
index e8c03862a..81095a77f 100644
--- a/tika-server/src/main/java/org/apache/tika/server/RichTextContentHandler.java
+++ b/tika-server/src/main/java/org/apache/tika/server/RichTextContentHandler.java
@@ -14,34 +14,34 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-
-package org.apache.tika.server;
-
-import java.io.Writer;
-
-import org.apache.tika.sax.WriteOutContentHandler;
-import org.xml.sax.Attributes;
-import org.xml.sax.SAXException;
-
-public class RichTextContentHandler extends WriteOutContentHandler {
-    public RichTextContentHandler(Writer writer) {
-        super(writer);
-    }
-
-    @Override
-    public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException {
-        super.startElement(uri, localName, qName, attributes);
-
-        if ("img".equals(localName) && attributes.getValue("alt") != null) {
-            String nfo = "[image: " + attributes.getValue("alt") + ']';
-
-            characters(nfo.toCharArray(), 0, nfo.length());
-        }
-
-        if ("a".equals(localName) && attributes.getValue("name") != null) {
-            String nfo = "[bookmark: " + attributes.getValue("name") + ']';
-
-            characters(nfo.toCharArray(), 0, nfo.length());
-        }
-    }
-}
+
+package org.apache.tika.server;
+
+import java.io.Writer;
+
+import org.apache.tika.sax.WriteOutContentHandler;
+import org.xml.sax.Attributes;
+import org.xml.sax.SAXException;
+
+public class RichTextContentHandler extends WriteOutContentHandler {
+    public RichTextContentHandler(Writer writer) {
+        super(writer);
+    }
+
+    @Override
+    public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException {
+        super.startElement(uri, localName, qName, attributes);
+
+        if ("img".equals(localName) && attributes.getValue("alt") != null) {
+            String nfo = "[image: " + attributes.getValue("alt") + ']';
+
+            characters(nfo.toCharArray(), 0, nfo.length());
+        }
+
+        if ("a".equals(localName) && attributes.getValue("name") != null) {
+            String nfo = "[bookmark: " + attributes.getValue("name") + ']';
+
+            characters(nfo.toCharArray(), 0, nfo.length());
+        }
+    }
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaServerParseExceptionMapper.java b/tika-server/src/main/java/org/apache/tika/server/TikaServerParseExceptionMapper.java
index fe1d12ca0..21c28b6d7 100644
--- a/tika-server/src/main/java/org/apache/tika/server/TikaServerParseExceptionMapper.java
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaServerParseExceptionMapper.java
@@ -1,90 +1,90 @@
-package org.apache.tika.server;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import javax.ws.rs.WebApplicationException;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.ext.ExceptionMapper;
-import javax.ws.rs.ext.Provider;
-
-
-import java.io.IOException;
-import java.io.PrintWriter;
-import java.io.StringWriter;
-import java.io.Writer;
-
-import org.apache.poi.hwpf.OldWordFileFormatException;
-import org.apache.tika.exception.EncryptedDocumentException;
-import org.apache.tika.exception.TikaException;
-
-@Provider
-public class TikaServerParseExceptionMapper implements ExceptionMapper<TikaServerParseException> {
-
-    private final boolean returnStack;
-
-    public TikaServerParseExceptionMapper(boolean returnStack) {
-        this.returnStack = returnStack;
-    }
-
-    public Response toResponse(TikaServerParseException e) {
-        if (e.getMessage() != null &&
-                e.getMessage().equals(Response.Status.UNSUPPORTED_MEDIA_TYPE.toString())) {
-            return buildResponse(e, 415);
-        }
-        Throwable cause = e.getCause();
-        if (cause == null) {
-            return buildResponse(e, Response.Status.INTERNAL_SERVER_ERROR.getStatusCode());
-        } else {
-            if (cause instanceof EncryptedDocumentException) {
-                return buildResponse(cause, 422);
-            } else if (cause instanceof TikaException) {
-                //unsupported media type
-                Throwable causeOfCause = cause.getCause();
-                if (causeOfCause instanceof WebApplicationException) {
-                    return ((WebApplicationException) causeOfCause).getResponse();
-                }
-                return buildResponse(cause, 422);
-            } else if (cause instanceof IllegalStateException) {
-                return buildResponse(cause, 422);
-            } else if (cause instanceof OldWordFileFormatException) {
-                return buildResponse(cause, 422);
-            } else if (cause instanceof WebApplicationException) {
-                return ((WebApplicationException) e.getCause()).getResponse();
-            } else {
-                return buildResponse(e, 500);
-            }
-        }
-    }
-
-    private Response buildResponse(Throwable cause, int i) {
-        if (returnStack && cause != null) {
-            Writer result = new StringWriter();
-            PrintWriter writer = new PrintWriter(result);
-            cause.printStackTrace(writer);
-            writer.flush();
-            try {
-                result.flush();
-            } catch (IOException e) {
-                //something went seriously wrong
-                return Response.status(500).build();
-            }
-            return Response.status(i).entity(result.toString()).type("text/plain").build();
-        } else {
-            return Response.status(i).build();
-        }
-    }
-}
+package org.apache.tika.server;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import javax.ws.rs.WebApplicationException;
+import javax.ws.rs.core.Response;
+import javax.ws.rs.ext.ExceptionMapper;
+import javax.ws.rs.ext.Provider;
+
+
+import java.io.IOException;
+import java.io.PrintWriter;
+import java.io.StringWriter;
+import java.io.Writer;
+
+import org.apache.poi.hwpf.OldWordFileFormatException;
+import org.apache.tika.exception.EncryptedDocumentException;
+import org.apache.tika.exception.TikaException;
+
+@Provider
+public class TikaServerParseExceptionMapper implements ExceptionMapper<TikaServerParseException> {
+
+    private final boolean returnStack;
+
+    public TikaServerParseExceptionMapper(boolean returnStack) {
+        this.returnStack = returnStack;
+    }
+
+    public Response toResponse(TikaServerParseException e) {
+        if (e.getMessage() != null &&
+                e.getMessage().equals(Response.Status.UNSUPPORTED_MEDIA_TYPE.toString())) {
+            return buildResponse(e, 415);
+        }
+        Throwable cause = e.getCause();
+        if (cause == null) {
+            return buildResponse(e, Response.Status.INTERNAL_SERVER_ERROR.getStatusCode());
+        } else {
+            if (cause instanceof EncryptedDocumentException) {
+                return buildResponse(cause, 422);
+            } else if (cause instanceof TikaException) {
+                //unsupported media type
+                Throwable causeOfCause = cause.getCause();
+                if (causeOfCause instanceof WebApplicationException) {
+                    return ((WebApplicationException) causeOfCause).getResponse();
+                }
+                return buildResponse(cause, 422);
+            } else if (cause instanceof IllegalStateException) {
+                return buildResponse(cause, 422);
+            } else if (cause instanceof OldWordFileFormatException) {
+                return buildResponse(cause, 422);
+            } else if (cause instanceof WebApplicationException) {
+                return ((WebApplicationException) e.getCause()).getResponse();
+            } else {
+                return buildResponse(e, 500);
+            }
+        }
+    }
+
+    private Response buildResponse(Throwable cause, int i) {
+        if (returnStack && cause != null) {
+            Writer result = new StringWriter();
+            PrintWriter writer = new PrintWriter(result);
+            cause.printStackTrace(writer);
+            writer.flush();
+            try {
+                result.flush();
+            } catch (IOException e) {
+                //something went seriously wrong
+                return Response.status(500).build();
+            }
+            return Response.status(i).entity(result.toString()).type("text/plain").build();
+        } else {
+            return Response.status(i).build();
+        }
+    }
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/resource/DetectorResource.java b/tika-server/src/main/java/org/apache/tika/server/resource/DetectorResource.java
index 1fc74a818..e04c6dd73 100644
--- a/tika-server/src/main/java/org/apache/tika/server/resource/DetectorResource.java
+++ b/tika-server/src/main/java/org/apache/tika/server/resource/DetectorResource.java
@@ -1,72 +1,72 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server.resource;
-
-import javax.ws.rs.Consumes;
-import javax.ws.rs.PUT;
-import javax.ws.rs.Path;
-import javax.ws.rs.Produces;
-import javax.ws.rs.core.Context;
-import javax.ws.rs.core.HttpHeaders;
-import javax.ws.rs.core.UriInfo;
-
-import java.io.IOException;
-import java.io.InputStream;
-
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.io.TikaInputStream;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-
-@Path("/detect")
-public class DetectorResource {
-
-    private static final Log logger = LogFactory.getLog(DetectorResource.class
-            .getName());
-
-    private TikaConfig config = null;
-
-    public DetectorResource(TikaConfig config) {
-        this.config = config;
-    }
-
-    @PUT
-    @Path("stream")
-    @Consumes("*/*")
-    @Produces("text/plain")
-    public String detect(final InputStream is,
-                         @Context HttpHeaders httpHeaders, @Context final UriInfo info) {
-        Metadata met = new Metadata();
-        TikaInputStream tis = TikaInputStream.get(is);
-        String filename = TikaResource.detectFilename(httpHeaders
-                .getRequestHeaders());
-        logger.info("Detecting media type for Filename: " + filename);
-        met.add(Metadata.RESOURCE_NAME_KEY, filename);
-        try {
-            return this.config.getDetector().detect(tis, met).toString();
-        } catch (IOException e) {
-            logger.warn("Unable to detect MIME type for file. Reason: "
-                    + e.getMessage());
-            e.printStackTrace();
-            return MediaType.OCTET_STREAM.toString();
-        }
-    }
-
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server.resource;
+
+import javax.ws.rs.Consumes;
+import javax.ws.rs.PUT;
+import javax.ws.rs.Path;
+import javax.ws.rs.Produces;
+import javax.ws.rs.core.Context;
+import javax.ws.rs.core.HttpHeaders;
+import javax.ws.rs.core.UriInfo;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.io.TikaInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+
+@Path("/detect")
+public class DetectorResource {
+
+    private static final Log logger = LogFactory.getLog(DetectorResource.class
+            .getName());
+
+    private TikaConfig config = null;
+
+    public DetectorResource(TikaConfig config) {
+        this.config = config;
+    }
+
+    @PUT
+    @Path("stream")
+    @Consumes("*/*")
+    @Produces("text/plain")
+    public String detect(final InputStream is,
+                         @Context HttpHeaders httpHeaders, @Context final UriInfo info) {
+        Metadata met = new Metadata();
+        TikaInputStream tis = TikaInputStream.get(is);
+        String filename = TikaResource.detectFilename(httpHeaders
+                .getRequestHeaders());
+        logger.info("Detecting media type for Filename: " + filename);
+        met.add(Metadata.RESOURCE_NAME_KEY, filename);
+        try {
+            return this.config.getDetector().detect(tis, met).toString();
+        } catch (IOException e) {
+            logger.warn("Unable to detect MIME type for file. Reason: "
+                    + e.getMessage());
+            e.printStackTrace();
+            return MediaType.OCTET_STREAM.toString();
+        }
+    }
+
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/resource/RecursiveMetadataResource.java b/tika-server/src/main/java/org/apache/tika/server/resource/RecursiveMetadataResource.java
index 5c7eb569b..d81384533 100644
--- a/tika-server/src/main/java/org/apache/tika/server/resource/RecursiveMetadataResource.java
+++ b/tika-server/src/main/java/org/apache/tika/server/resource/RecursiveMetadataResource.java
@@ -1,94 +1,94 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server.resource;
-
-import javax.ws.rs.Consumes;
-import javax.ws.rs.POST;
-import javax.ws.rs.PUT;
-import javax.ws.rs.Path;
-import javax.ws.rs.Produces;
-import javax.ws.rs.core.Context;
-import javax.ws.rs.core.HttpHeaders;
-import javax.ws.rs.core.MultivaluedMap;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.core.UriInfo;
-
-import java.io.InputStream;
-
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
-import org.apache.cxf.jaxrs.ext.multipart.Attachment;
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.language.ProfilingHandler;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.AutoDetectParser;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.RecursiveParserWrapper;
-import org.apache.tika.sax.BasicContentHandlerFactory;
-import org.apache.tika.server.MetadataList;
-import org.xml.sax.helpers.DefaultHandler;
-
-@Path("/rmeta")
-public class RecursiveMetadataResource {
-    private static final Log logger = LogFactory.getLog(RecursiveMetadataResource.class);
-
-    private TikaConfig tikaConfig;
-
-    public RecursiveMetadataResource(TikaConfig tikaConfig) {
-        this.tikaConfig = tikaConfig;
-    }
-
-    @POST
-    @Consumes("multipart/form-data")
-    @Produces({"text/csv", "application/json"})
-    @Path("form")
-    public Response getMetadataFromMultipart(Attachment att, @Context UriInfo info) throws Exception {
-        return Response.ok(
-                parseMetadata(att.getObject(InputStream.class), att.getHeaders(), info)).build();
-    }
-
-    @PUT
-    @Produces("application/json")
-    public Response getMetadata(InputStream is, @Context HttpHeaders httpHeaders, @Context UriInfo info) throws Exception {
-        return Response.ok(
-                parseMetadata(is, httpHeaders.getRequestHeaders(), info)).build();
-    }
-
-	private MetadataList parseMetadata(InputStream is,
-			MultivaluedMap<String, String> httpHeaders, UriInfo info)
-			throws Exception {
-		final Metadata metadata = new Metadata();
-		final ParseContext context = new ParseContext();
-		AutoDetectParser parser = TikaResource.createParser(tikaConfig);
-		// TODO: parameterize choice of handler and max chars?
-		BasicContentHandlerFactory.HANDLER_TYPE type = BasicContentHandlerFactory.HANDLER_TYPE.TEXT;
-		RecursiveParserWrapper wrapper = new RecursiveParserWrapper(parser,
-				new BasicContentHandlerFactory(type, -1));
-		TikaResource.fillMetadata(parser, metadata, context, httpHeaders);
-		// no need to add parser to parse recursively
-		TikaResource.fillParseContext(context, httpHeaders, null);
-		TikaResource.logRequest(logger, info, metadata);
-		TikaResource.parse(wrapper, logger, info.getPath(), is,
-				new ProfilingHandler() {
-					public void endDocument() {
-						metadata.set("language", getLanguage().getLanguage());
-					}
-				}, metadata, context);
-		return new MetadataList(wrapper.getMetadata());
-	}
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server.resource;
+
+import javax.ws.rs.Consumes;
+import javax.ws.rs.POST;
+import javax.ws.rs.PUT;
+import javax.ws.rs.Path;
+import javax.ws.rs.Produces;
+import javax.ws.rs.core.Context;
+import javax.ws.rs.core.HttpHeaders;
+import javax.ws.rs.core.MultivaluedMap;
+import javax.ws.rs.core.Response;
+import javax.ws.rs.core.UriInfo;
+
+import java.io.InputStream;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.cxf.jaxrs.ext.multipart.Attachment;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.language.ProfilingHandler;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.RecursiveParserWrapper;
+import org.apache.tika.sax.BasicContentHandlerFactory;
+import org.apache.tika.server.MetadataList;
+import org.xml.sax.helpers.DefaultHandler;
+
+@Path("/rmeta")
+public class RecursiveMetadataResource {
+    private static final Log logger = LogFactory.getLog(RecursiveMetadataResource.class);
+
+    private TikaConfig tikaConfig;
+
+    public RecursiveMetadataResource(TikaConfig tikaConfig) {
+        this.tikaConfig = tikaConfig;
+    }
+
+    @POST
+    @Consumes("multipart/form-data")
+    @Produces({"text/csv", "application/json"})
+    @Path("form")
+    public Response getMetadataFromMultipart(Attachment att, @Context UriInfo info) throws Exception {
+        return Response.ok(
+                parseMetadata(att.getObject(InputStream.class), att.getHeaders(), info)).build();
+    }
+
+    @PUT
+    @Produces("application/json")
+    public Response getMetadata(InputStream is, @Context HttpHeaders httpHeaders, @Context UriInfo info) throws Exception {
+        return Response.ok(
+                parseMetadata(is, httpHeaders.getRequestHeaders(), info)).build();
+    }
+
+	private MetadataList parseMetadata(InputStream is,
+			MultivaluedMap<String, String> httpHeaders, UriInfo info)
+			throws Exception {
+		final Metadata metadata = new Metadata();
+		final ParseContext context = new ParseContext();
+		AutoDetectParser parser = TikaResource.createParser(tikaConfig);
+		// TODO: parameterize choice of handler and max chars?
+		BasicContentHandlerFactory.HANDLER_TYPE type = BasicContentHandlerFactory.HANDLER_TYPE.TEXT;
+		RecursiveParserWrapper wrapper = new RecursiveParserWrapper(parser,
+				new BasicContentHandlerFactory(type, -1));
+		TikaResource.fillMetadata(parser, metadata, context, httpHeaders);
+		// no need to add parser to parse recursively
+		TikaResource.fillParseContext(context, httpHeaders, null);
+		TikaResource.logRequest(logger, info, metadata);
+		TikaResource.parse(wrapper, logger, info.getPath(), is,
+				new ProfilingHandler() {
+					public void endDocument() {
+						metadata.set("language", getLanguage().getLanguage());
+					}
+				}, metadata, context);
+		return new MetadataList(wrapper.getMetadata());
+	}
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/resource/TikaDetectors.java b/tika-server/src/main/java/org/apache/tika/server/resource/TikaDetectors.java
index e2d8f5366..c076c85a4 100644
--- a/tika-server/src/main/java/org/apache/tika/server/resource/TikaDetectors.java
+++ b/tika-server/src/main/java/org/apache/tika/server/resource/TikaDetectors.java
@@ -1,128 +1,128 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.server.resource;
-
-import javax.ws.rs.GET;
-import javax.ws.rs.Path;
-import javax.ws.rs.Produces;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.detect.CompositeDetector;
-import org.apache.tika.detect.Detector;
-import org.apache.tika.server.HTMLHelper;
-import org.eclipse.jetty.util.ajax.JSON;
-
-/**
- * <p>Provides details of all the {@link Detector}s registered with
- * Apache Tika, similar to <em>--list-detectors</em> with the Tika CLI.
- */
-@Path("/detectors")
-public class TikaDetectors {
-    private TikaConfig tika;
-    private HTMLHelper html;
-
-    public TikaDetectors(TikaConfig tika) {
-        this.tika = tika;
-        this.html = new HTMLHelper();
-    }
-
-    @GET
-    @Produces("text/html")
-    public String getDectorsHTML() {
-        StringBuffer h = new StringBuffer();
-        html.generateHeader(h, "Detectors available to Apache Tika");
-        detectorAsHTML(tika.getDetector(), h, 2);
-        html.generateFooter(h);
-        return h.toString();
-    }
-
-    private void detectorAsHTML(Detector d, StringBuffer html, int level) {
-        html.append("<h");
-        html.append(level);
-        html.append(">");
-        String name = d.getClass().getName();
-        html.append(name.substring(name.lastIndexOf('.') + 1));
-        html.append("</h");
-        html.append(level);
-        html.append(">");
-        html.append("<p>Class: ");
-        html.append(name);
-        html.append("</p>");
-        if (d instanceof CompositeDetector) {
-            html.append("<p>Composite Detector</p>");
-            for (Detector cd : ((CompositeDetector) d).getDetectors()) {
-                detectorAsHTML(cd, html, level + 1);
-            }
-        }
-    }
-
-    @GET
-    @Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-    public String getDetectorsJSON() {
-        Map<String, Object> details = new HashMap<String, Object>();
-        detectorAsMap(tika.getDetector(), details);
-        return JSON.toString(details);
-    }
-
-    private void detectorAsMap(Detector d, Map<String, Object> details) {
-        details.put("name", d.getClass().getName());
-
-        boolean isComposite = (d instanceof CompositeDetector);
-        details.put("composite", isComposite);
-        if (isComposite) {
-            List<Map<String, Object>> c = new ArrayList<Map<String, Object>>();
-            for (Detector cd : ((CompositeDetector) d).getDetectors()) {
-                Map<String, Object> cdet = new HashMap<String, Object>();
-                detectorAsMap(cd, cdet);
-                c.add(cdet);
-            }
-            details.put("children", c);
-        }
-    }
-
-    @GET
-    @Produces("text/plain")
-    public String getDetectorsPlain() {
-        StringBuffer text = new StringBuffer();
-        renderDetector(tika.getDetector(), text, 0);
-        return text.toString();
-    }
-
-    private void renderDetector(Detector d, StringBuffer text, int indent) {
-        boolean isComposite = (d instanceof CompositeDetector);
-        String name = d.getClass().getName();
-
-        for (int i = 0; i < indent; i++) {
-            text.append("  ");
-        }
-        text.append(name);
-        if (isComposite) {
-            text.append(" (Composite Detector):\n");
-
-            List<Detector> subDetectors = ((CompositeDetector) d).getDetectors();
-            for (Detector sd : subDetectors) {
-                renderDetector(sd, text, indent + 1);
-            }
-        } else {
-            text.append("\n");        }
-    }
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.server.resource;
+
+import javax.ws.rs.GET;
+import javax.ws.rs.Path;
+import javax.ws.rs.Produces;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.detect.CompositeDetector;
+import org.apache.tika.detect.Detector;
+import org.apache.tika.server.HTMLHelper;
+import org.eclipse.jetty.util.ajax.JSON;
+
+/**
+ * <p>Provides details of all the {@link Detector}s registered with
+ * Apache Tika, similar to <em>--list-detectors</em> with the Tika CLI.
+ */
+@Path("/detectors")
+public class TikaDetectors {
+    private TikaConfig tika;
+    private HTMLHelper html;
+
+    public TikaDetectors(TikaConfig tika) {
+        this.tika = tika;
+        this.html = new HTMLHelper();
+    }
+
+    @GET
+    @Produces("text/html")
+    public String getDectorsHTML() {
+        StringBuffer h = new StringBuffer();
+        html.generateHeader(h, "Detectors available to Apache Tika");
+        detectorAsHTML(tika.getDetector(), h, 2);
+        html.generateFooter(h);
+        return h.toString();
+    }
+
+    private void detectorAsHTML(Detector d, StringBuffer html, int level) {
+        html.append("<h");
+        html.append(level);
+        html.append(">");
+        String name = d.getClass().getName();
+        html.append(name.substring(name.lastIndexOf('.') + 1));
+        html.append("</h");
+        html.append(level);
+        html.append(">");
+        html.append("<p>Class: ");
+        html.append(name);
+        html.append("</p>");
+        if (d instanceof CompositeDetector) {
+            html.append("<p>Composite Detector</p>");
+            for (Detector cd : ((CompositeDetector) d).getDetectors()) {
+                detectorAsHTML(cd, html, level + 1);
+            }
+        }
+    }
+
+    @GET
+    @Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+    public String getDetectorsJSON() {
+        Map<String, Object> details = new HashMap<String, Object>();
+        detectorAsMap(tika.getDetector(), details);
+        return JSON.toString(details);
+    }
+
+    private void detectorAsMap(Detector d, Map<String, Object> details) {
+        details.put("name", d.getClass().getName());
+
+        boolean isComposite = (d instanceof CompositeDetector);
+        details.put("composite", isComposite);
+        if (isComposite) {
+            List<Map<String, Object>> c = new ArrayList<Map<String, Object>>();
+            for (Detector cd : ((CompositeDetector) d).getDetectors()) {
+                Map<String, Object> cdet = new HashMap<String, Object>();
+                detectorAsMap(cd, cdet);
+                c.add(cdet);
+            }
+            details.put("children", c);
+        }
+    }
+
+    @GET
+    @Produces("text/plain")
+    public String getDetectorsPlain() {
+        StringBuffer text = new StringBuffer();
+        renderDetector(tika.getDetector(), text, 0);
+        return text.toString();
+    }
+
+    private void renderDetector(Detector d, StringBuffer text, int indent) {
+        boolean isComposite = (d instanceof CompositeDetector);
+        String name = d.getClass().getName();
+
+        for (int i = 0; i < indent; i++) {
+            text.append("  ");
+        }
+        text.append(name);
+        if (isComposite) {
+            text.append(" (Composite Detector):\n");
+
+            List<Detector> subDetectors = ((CompositeDetector) d).getDetectors();
+            for (Detector sd : subDetectors) {
+                renderDetector(sd, text, indent + 1);
+            }
+        } else {
+            text.append("\n");        }
+    }
 }
\ No newline at end of file
diff --git a/tika-server/src/main/java/org/apache/tika/server/resource/TikaMimeTypes.java b/tika-server/src/main/java/org/apache/tika/server/resource/TikaMimeTypes.java
index b62f6cf4b..bd1b143d6 100644
--- a/tika-server/src/main/java/org/apache/tika/server/resource/TikaMimeTypes.java
+++ b/tika-server/src/main/java/org/apache/tika/server/resource/TikaMimeTypes.java
@@ -1,177 +1,177 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.server.resource;
-
-import javax.ws.rs.GET;
-import javax.ws.rs.Path;
-import javax.ws.rs.Produces;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.SortedMap;
-import java.util.TreeMap;
-
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.mime.MediaTypeRegistry;
-import org.apache.tika.parser.CompositeParser;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.server.HTMLHelper;
-import org.eclipse.jetty.util.ajax.JSON;
-
-/**
- * <p>Provides details of all the mimetypes known to Apache Tika,
- * similar to <em>--list-supported-types</em> with the Tika CLI.
- */
-@Path("/mime-types")
-public class TikaMimeTypes {
-    private TikaConfig tika;
-    private HTMLHelper html;
-
-    public TikaMimeTypes(TikaConfig tika) {
-        this.tika = tika;
-        this.html = new HTMLHelper();
-    }
-
-    @GET
-    @Produces("text/html")
-    public String getMimeTypesHTML() {
-        StringBuffer h = new StringBuffer();
-        html.generateHeader(h, "Apache Tika Supported Mime Types");
-
-        // Get our types
-        List<MediaTypeDetails> types = getMediaTypes();
-
-        // Get the first type in each section
-        SortedMap<String, String> firstType = new TreeMap<String, String>();
-        for (MediaTypeDetails type : types) {
-            if (!firstType.containsKey(type.type.getType())) {
-                firstType.put(type.type.getType(), type.type.toString());
-            }
-        }
-        h.append("<ul>");
-        for (String section : firstType.keySet()) {
-            h.append("<li><a href=\"#").append(firstType.get(section)).append("\">").append(section).append("</a></li>\n");
-        }
-        h.append("</ul>");
-
-        // Output all of them
-        for (MediaTypeDetails type : types) {
-            h.append("<a name=\"").append(type.type).append("\"></a>\n");
-            h.append("<h2>").append(type.type).append("</h2>\n");
-
-            for (MediaType alias : type.aliases) {
-                h.append("<div>Alias: ").append(alias).append("</div>\n");
-            }
-            if (type.supertype != null) {
-                h.append("<div>Super Type: <a href=\"#").append(type.supertype).append("\">").append(type.supertype).append("</a></div>\n");
-            }
-
-            if (type.parser != null) {
-                h.append("<div>Parser: ").append(type.parser).append("</div>\n");
-            }
-        }
-
-        html.generateFooter(h);
-        return h.toString();
-    }
-
-    @GET
-    @Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-    public String getMimeTypesJSON() {
-        Map<String, Object> details = new HashMap<String, Object>();
-
-        for (MediaTypeDetails type : getMediaTypes()) {
-            Map<String, Object> typeDets = new HashMap<String, Object>();
-
-            typeDets.put("alias", type.aliases);
-            if (type.supertype != null) {
-                typeDets.put("supertype", type.supertype);
-            }
-            if (type.parser != null) {
-                typeDets.put("parser", type.parser);
-            }
-
-            details.put(type.type.toString(), typeDets);
-        }
-
-        return JSON.toString(details);
-    }
-
-    @GET
-    @Produces("text/plain")
-    public String getMimeTypesPlain() {
-        StringBuffer text = new StringBuffer();
-
-        for (MediaTypeDetails type : getMediaTypes()) {
-            text.append(type.type.toString());
-            text.append("\n");
-
-            for (MediaType alias : type.aliases) {
-                text.append("  alias:     ").append(alias).append("\n");
-            }
-            if (type.supertype != null) {
-                text.append("  supertype: ").append(type.supertype.toString()).append("\n");
-            }
-
-            if (type.parser != null) {
-                text.append("  parser:    ").append(type.parser).append("\n");
-            }
-        }
-
-        return text.toString();
-    }
-
-    protected List<MediaTypeDetails> getMediaTypes() {
-        MediaTypeRegistry registry = tika.getMediaTypeRegistry();
-        Map<MediaType, Parser> parsers = ((CompositeParser) tika.getParser()).getParsers();
-        List<MediaTypeDetails> types =
-                new ArrayList<TikaMimeTypes.MediaTypeDetails>(registry.getTypes().size());
-
-        for (MediaType type : registry.getTypes()) {
-            MediaTypeDetails details = new MediaTypeDetails();
-            details.type = type;
-            details.aliases = registry.getAliases(type).toArray(new MediaType[0]);
-
-            MediaType supertype = registry.getSupertype(type);
-            if (supertype != null && !MediaType.OCTET_STREAM.equals(supertype)) {
-                details.supertype = supertype;
-            }
-
-            Parser p = parsers.get(type);
-            if (p != null) {
-                if (p instanceof CompositeParser) {
-                    p = ((CompositeParser) p).getParsers().get(type);
-                }
-                details.parser = p.getClass().getName();
-            }
-
-            types.add(details);
-        }
-
-        return types;
-    }
-
-    private static class MediaTypeDetails {
-        private MediaType type;
-        private MediaType[] aliases;
-        private MediaType supertype;
-        private String parser;
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.server.resource;
+
+import javax.ws.rs.GET;
+import javax.ws.rs.Path;
+import javax.ws.rs.Produces;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.SortedMap;
+import java.util.TreeMap;
+
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.mime.MediaTypeRegistry;
+import org.apache.tika.parser.CompositeParser;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.server.HTMLHelper;
+import org.eclipse.jetty.util.ajax.JSON;
+
+/**
+ * <p>Provides details of all the mimetypes known to Apache Tika,
+ * similar to <em>--list-supported-types</em> with the Tika CLI.
+ */
+@Path("/mime-types")
+public class TikaMimeTypes {
+    private TikaConfig tika;
+    private HTMLHelper html;
+
+    public TikaMimeTypes(TikaConfig tika) {
+        this.tika = tika;
+        this.html = new HTMLHelper();
+    }
+
+    @GET
+    @Produces("text/html")
+    public String getMimeTypesHTML() {
+        StringBuffer h = new StringBuffer();
+        html.generateHeader(h, "Apache Tika Supported Mime Types");
+
+        // Get our types
+        List<MediaTypeDetails> types = getMediaTypes();
+
+        // Get the first type in each section
+        SortedMap<String, String> firstType = new TreeMap<String, String>();
+        for (MediaTypeDetails type : types) {
+            if (!firstType.containsKey(type.type.getType())) {
+                firstType.put(type.type.getType(), type.type.toString());
+            }
+        }
+        h.append("<ul>");
+        for (String section : firstType.keySet()) {
+            h.append("<li><a href=\"#").append(firstType.get(section)).append("\">").append(section).append("</a></li>\n");
+        }
+        h.append("</ul>");
+
+        // Output all of them
+        for (MediaTypeDetails type : types) {
+            h.append("<a name=\"").append(type.type).append("\"></a>\n");
+            h.append("<h2>").append(type.type).append("</h2>\n");
+
+            for (MediaType alias : type.aliases) {
+                h.append("<div>Alias: ").append(alias).append("</div>\n");
+            }
+            if (type.supertype != null) {
+                h.append("<div>Super Type: <a href=\"#").append(type.supertype).append("\">").append(type.supertype).append("</a></div>\n");
+            }
+
+            if (type.parser != null) {
+                h.append("<div>Parser: ").append(type.parser).append("</div>\n");
+            }
+        }
+
+        html.generateFooter(h);
+        return h.toString();
+    }
+
+    @GET
+    @Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+    public String getMimeTypesJSON() {
+        Map<String, Object> details = new HashMap<String, Object>();
+
+        for (MediaTypeDetails type : getMediaTypes()) {
+            Map<String, Object> typeDets = new HashMap<String, Object>();
+
+            typeDets.put("alias", type.aliases);
+            if (type.supertype != null) {
+                typeDets.put("supertype", type.supertype);
+            }
+            if (type.parser != null) {
+                typeDets.put("parser", type.parser);
+            }
+
+            details.put(type.type.toString(), typeDets);
+        }
+
+        return JSON.toString(details);
+    }
+
+    @GET
+    @Produces("text/plain")
+    public String getMimeTypesPlain() {
+        StringBuffer text = new StringBuffer();
+
+        for (MediaTypeDetails type : getMediaTypes()) {
+            text.append(type.type.toString());
+            text.append("\n");
+
+            for (MediaType alias : type.aliases) {
+                text.append("  alias:     ").append(alias).append("\n");
+            }
+            if (type.supertype != null) {
+                text.append("  supertype: ").append(type.supertype.toString()).append("\n");
+            }
+
+            if (type.parser != null) {
+                text.append("  parser:    ").append(type.parser).append("\n");
+            }
+        }
+
+        return text.toString();
+    }
+
+    protected List<MediaTypeDetails> getMediaTypes() {
+        MediaTypeRegistry registry = tika.getMediaTypeRegistry();
+        Map<MediaType, Parser> parsers = ((CompositeParser) tika.getParser()).getParsers();
+        List<MediaTypeDetails> types =
+                new ArrayList<TikaMimeTypes.MediaTypeDetails>(registry.getTypes().size());
+
+        for (MediaType type : registry.getTypes()) {
+            MediaTypeDetails details = new MediaTypeDetails();
+            details.type = type;
+            details.aliases = registry.getAliases(type).toArray(new MediaType[0]);
+
+            MediaType supertype = registry.getSupertype(type);
+            if (supertype != null && !MediaType.OCTET_STREAM.equals(supertype)) {
+                details.supertype = supertype;
+            }
+
+            Parser p = parsers.get(type);
+            if (p != null) {
+                if (p instanceof CompositeParser) {
+                    p = ((CompositeParser) p).getParsers().get(type);
+                }
+                details.parser = p.getClass().getName();
+            }
+
+            types.add(details);
+        }
+
+        return types;
+    }
+
+    private static class MediaTypeDetails {
+        private MediaType type;
+        private MediaType[] aliases;
+        private MediaType supertype;
+        private String parser;
+    }
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/resource/TikaParsers.java b/tika-server/src/main/java/org/apache/tika/server/resource/TikaParsers.java
index 8d436149e..f498d1ba4 100644
--- a/tika-server/src/main/java/org/apache/tika/server/resource/TikaParsers.java
+++ b/tika-server/src/main/java/org/apache/tika/server/resource/TikaParsers.java
@@ -1,235 +1,235 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.server.resource;
-
-import javax.ws.rs.GET;
-import javax.ws.rs.Path;
-import javax.ws.rs.Produces;
-
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.parser.CompositeParser;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.Parser;
-import org.apache.tika.parser.ParserDecorator;
-import org.apache.tika.server.HTMLHelper;
-import org.eclipse.jetty.util.ajax.JSON;
-
-/**
- * <p>Provides details of all the {@link Parser}s registered with
- * Apache Tika, similar to <em>--list-parsers</em> and
- * <em>--list-parser-details</em> within the Tika CLI.
- */
-@Path("/parsers")
-public class TikaParsers {
-    private static final ParseContext EMPTY_PC = new ParseContext();
-    private TikaConfig tika;
-    private HTMLHelper html;
-
-    public TikaParsers(TikaConfig tika) {
-        this.tika = tika;
-        this.html = new HTMLHelper();
-    }
-
-    @GET
-    @Path("/details")
-    @Produces("text/html")
-    public String getParserDetailsHTML() {
-        return getParsersHTML(true);
-    }
-
-    @GET
-    @Produces("text/html")
-    public String getParsersHTML() {
-        return getParsersHTML(false);
-    }
-
-    protected String getParsersHTML(boolean withMimeTypes) {
-        ParserDetails p = new ParserDetails(tika.getParser());
-
-        StringBuffer h = new StringBuffer();
-        html.generateHeader(h, "Parsers available to Apache Tika");
-        parserAsHTML(p, withMimeTypes, h, 2);
-        html.generateFooter(h);
-        return h.toString();
-    }
-
-    private void parserAsHTML(ParserDetails p, boolean withMimeTypes, StringBuffer html, int level) {
-        html.append("<h");
-        html.append(level);
-        html.append(">");
-        html.append(p.shortName);
-        html.append("</h");
-        html.append(level);
-        html.append(">");
-        html.append("<p>Class: ");
-        html.append(p.className);
-        html.append("</p>");
-        if (p.isDecorated) {
-            html.append("<p>Decorated Parser</p>");
-        }
-        if (p.isComposite) {
-            html.append("<p>Composite Parser</p>");
-            for (Parser cp : p.childParsers) {
-                parserAsHTML(new ParserDetails(cp), withMimeTypes, html, level + 1);
-            }
-        } else if (withMimeTypes) {
-            html.append("<p>Mime Types:");
-            html.append("<ul>");
-            for (MediaType mt : p.supportedTypes) {
-                html.append("<li>");
-                html.append(mt.toString());
-                html.append("</li>");
-            }
-            html.append("</ul>");
-            html.append("</p>");
-        }
-    }
-
-    @GET
-    @Path("/details")
-    @Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-    public String getParserDetailsJSON() {
-        return getParsersJSON(true);
-    }
-
-    @GET
-    @Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-    public String getParsersJSON() {
-        return getParsersJSON(false);
-    }
-
-    protected String getParsersJSON(boolean withMimeTypes) {
-        Map<String, Object> details = new HashMap<String, Object>();
-        parserAsMap(new ParserDetails(tika.getParser()), withMimeTypes, details);
-        return JSON.toString(details);
-    }
-
-    private void parserAsMap(ParserDetails p, boolean withMimeTypes, Map<String, Object> details) {
-        details.put("name", p.className);
-        details.put("composite", p.isComposite);
-        details.put("decorated", p.isDecorated);
-
-        if (p.isComposite) {
-            List<Map<String, Object>> c = new ArrayList<Map<String, Object>>();
-            for (Parser cp : p.childParsers) {
-                Map<String, Object> cdet = new HashMap<String, Object>();
-                parserAsMap(new ParserDetails(cp), withMimeTypes, cdet);
-                c.add(cdet);
-            }
-            details.put("children", c);
-        } else if (withMimeTypes) {
-            List<String> mts = new ArrayList<String>(p.supportedTypes.size());
-            for (MediaType mt : p.supportedTypes) {
-                mts.add(mt.toString());
-            }
-            details.put("supportedTypes", mts);
-        }
-    }
-
-    @GET
-    @Path("/details")
-    @Produces("text/plain")
-    public String getParserDetailssPlain() {
-        return getParsersPlain(true);
-    }
-
-    @GET
-    @Produces("text/plain")
-    public String getParsersPlain() {
-        return getParsersPlain(false);
-    }
-
-    protected String getParsersPlain(boolean withMimeTypes) {
-        StringBuffer text = new StringBuffer();
-        renderParser(new ParserDetails(tika.getParser()), withMimeTypes, text, "");
-        return text.toString();
-    }
-
-    private void renderParser(ParserDetails p, boolean withMimeTypes, StringBuffer text, String indent) {
-        String nextIndent = indent + "  ";
-
-        text.append(indent);
-        text.append(p.className);
-        if (p.isDecorated) {
-            text.append(" (Decorated Parser)");
-        }
-        if (p.isComposite) {
-            text.append(" (Composite Parser):\n");
-
-            for (Parser cp : p.childParsers) {
-                renderParser(new ParserDetails(cp), withMimeTypes, text, nextIndent);
-            }
-        } else {
-            text.append("\n");
-            if (withMimeTypes) {
-                for (MediaType mt : p.supportedTypes) {
-                    text.append(nextIndent);
-                    text.append("Supports: ");
-                    text.append(mt.toString());
-                    text.append("\n");
-                }
-            }
-        }
-    }
-
-    private static class ParserDetails {
-        private String className;
-        private String shortName;
-        private boolean isComposite;
-        private boolean isDecorated;
-        private Set<MediaType> supportedTypes;
-        private List<Parser> childParsers;
-
-        private ParserDetails(Parser p) {
-            if (p instanceof ParserDecorator) {
-                isDecorated = true;
-                p = ((ParserDecorator) p).getWrappedParser();
-            }
-
-            className = p.getClass().getName();
-            shortName = className.substring(className.lastIndexOf('.') + 1);
-
-            if (p instanceof CompositeParser) {
-                isComposite = true;
-                supportedTypes = Collections.emptySet();
-
-                // Get the unique set of child parsers
-                Set<Parser> children = new HashSet<Parser>(
-                        ((CompositeParser) p).getParsers(EMPTY_PC).values());
-                // Sort it by class name
-                childParsers = new ArrayList<Parser>(children);
-                Collections.sort(childParsers, new Comparator<Parser>() {                    @Override
-                    public int compare(Parser p1, Parser p2) {
-                        return p1.getClass().getName().compareTo(p2.getClass().getName());
-                    }
-                });
-            } else {
-                supportedTypes = p.getSupportedTypes(EMPTY_PC);
-            }
-        }
-    }
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.server.resource;
+
+import javax.ws.rs.GET;
+import javax.ws.rs.Path;
+import javax.ws.rs.Produces;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.CompositeParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.parser.ParserDecorator;
+import org.apache.tika.server.HTMLHelper;
+import org.eclipse.jetty.util.ajax.JSON;
+
+/**
+ * <p>Provides details of all the {@link Parser}s registered with
+ * Apache Tika, similar to <em>--list-parsers</em> and
+ * <em>--list-parser-details</em> within the Tika CLI.
+ */
+@Path("/parsers")
+public class TikaParsers {
+    private static final ParseContext EMPTY_PC = new ParseContext();
+    private TikaConfig tika;
+    private HTMLHelper html;
+
+    public TikaParsers(TikaConfig tika) {
+        this.tika = tika;
+        this.html = new HTMLHelper();
+    }
+
+    @GET
+    @Path("/details")
+    @Produces("text/html")
+    public String getParserDetailsHTML() {
+        return getParsersHTML(true);
+    }
+
+    @GET
+    @Produces("text/html")
+    public String getParsersHTML() {
+        return getParsersHTML(false);
+    }
+
+    protected String getParsersHTML(boolean withMimeTypes) {
+        ParserDetails p = new ParserDetails(tika.getParser());
+
+        StringBuffer h = new StringBuffer();
+        html.generateHeader(h, "Parsers available to Apache Tika");
+        parserAsHTML(p, withMimeTypes, h, 2);
+        html.generateFooter(h);
+        return h.toString();
+    }
+
+    private void parserAsHTML(ParserDetails p, boolean withMimeTypes, StringBuffer html, int level) {
+        html.append("<h");
+        html.append(level);
+        html.append(">");
+        html.append(p.shortName);
+        html.append("</h");
+        html.append(level);
+        html.append(">");
+        html.append("<p>Class: ");
+        html.append(p.className);
+        html.append("</p>");
+        if (p.isDecorated) {
+            html.append("<p>Decorated Parser</p>");
+        }
+        if (p.isComposite) {
+            html.append("<p>Composite Parser</p>");
+            for (Parser cp : p.childParsers) {
+                parserAsHTML(new ParserDetails(cp), withMimeTypes, html, level + 1);
+            }
+        } else if (withMimeTypes) {
+            html.append("<p>Mime Types:");
+            html.append("<ul>");
+            for (MediaType mt : p.supportedTypes) {
+                html.append("<li>");
+                html.append(mt.toString());
+                html.append("</li>");
+            }
+            html.append("</ul>");
+            html.append("</p>");
+        }
+    }
+
+    @GET
+    @Path("/details")
+    @Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+    public String getParserDetailsJSON() {
+        return getParsersJSON(true);
+    }
+
+    @GET
+    @Produces(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+    public String getParsersJSON() {
+        return getParsersJSON(false);
+    }
+
+    protected String getParsersJSON(boolean withMimeTypes) {
+        Map<String, Object> details = new HashMap<String, Object>();
+        parserAsMap(new ParserDetails(tika.getParser()), withMimeTypes, details);
+        return JSON.toString(details);
+    }
+
+    private void parserAsMap(ParserDetails p, boolean withMimeTypes, Map<String, Object> details) {
+        details.put("name", p.className);
+        details.put("composite", p.isComposite);
+        details.put("decorated", p.isDecorated);
+
+        if (p.isComposite) {
+            List<Map<String, Object>> c = new ArrayList<Map<String, Object>>();
+            for (Parser cp : p.childParsers) {
+                Map<String, Object> cdet = new HashMap<String, Object>();
+                parserAsMap(new ParserDetails(cp), withMimeTypes, cdet);
+                c.add(cdet);
+            }
+            details.put("children", c);
+        } else if (withMimeTypes) {
+            List<String> mts = new ArrayList<String>(p.supportedTypes.size());
+            for (MediaType mt : p.supportedTypes) {
+                mts.add(mt.toString());
+            }
+            details.put("supportedTypes", mts);
+        }
+    }
+
+    @GET
+    @Path("/details")
+    @Produces("text/plain")
+    public String getParserDetailssPlain() {
+        return getParsersPlain(true);
+    }
+
+    @GET
+    @Produces("text/plain")
+    public String getParsersPlain() {
+        return getParsersPlain(false);
+    }
+
+    protected String getParsersPlain(boolean withMimeTypes) {
+        StringBuffer text = new StringBuffer();
+        renderParser(new ParserDetails(tika.getParser()), withMimeTypes, text, "");
+        return text.toString();
+    }
+
+    private void renderParser(ParserDetails p, boolean withMimeTypes, StringBuffer text, String indent) {
+        String nextIndent = indent + "  ";
+
+        text.append(indent);
+        text.append(p.className);
+        if (p.isDecorated) {
+            text.append(" (Decorated Parser)");
+        }
+        if (p.isComposite) {
+            text.append(" (Composite Parser):\n");
+
+            for (Parser cp : p.childParsers) {
+                renderParser(new ParserDetails(cp), withMimeTypes, text, nextIndent);
+            }
+        } else {
+            text.append("\n");
+            if (withMimeTypes) {
+                for (MediaType mt : p.supportedTypes) {
+                    text.append(nextIndent);
+                    text.append("Supports: ");
+                    text.append(mt.toString());
+                    text.append("\n");
+                }
+            }
+        }
+    }
+
+    private static class ParserDetails {
+        private String className;
+        private String shortName;
+        private boolean isComposite;
+        private boolean isDecorated;
+        private Set<MediaType> supportedTypes;
+        private List<Parser> childParsers;
+
+        private ParserDetails(Parser p) {
+            if (p instanceof ParserDecorator) {
+                isDecorated = true;
+                p = ((ParserDecorator) p).getWrappedParser();
+            }
+
+            className = p.getClass().getName();
+            shortName = className.substring(className.lastIndexOf('.') + 1);
+
+            if (p instanceof CompositeParser) {
+                isComposite = true;
+                supportedTypes = Collections.emptySet();
+
+                // Get the unique set of child parsers
+                Set<Parser> children = new HashSet<Parser>(
+                        ((CompositeParser) p).getParsers(EMPTY_PC).values());
+                // Sort it by class name
+                childParsers = new ArrayList<Parser>(children);
+                Collections.sort(childParsers, new Comparator<Parser>() {                    @Override
+                    public int compare(Parser p1, Parser p2) {
+                        return p1.getClass().getName().compareTo(p2.getClass().getName());
+                    }
+                });
+            } else {
+                supportedTypes = p.getSupportedTypes(EMPTY_PC);
+            }
+        }
+    }
 }
\ No newline at end of file
diff --git a/tika-server/src/main/java/org/apache/tika/server/writer/TarWriter.java b/tika-server/src/main/java/org/apache/tika/server/writer/TarWriter.java
index 3b459c2b8..bb4dec48f 100644
--- a/tika-server/src/main/java/org/apache/tika/server/writer/TarWriter.java
+++ b/tika-server/src/main/java/org/apache/tika/server/writer/TarWriter.java
@@ -1,68 +1,68 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server.writer;
-
-import javax.ws.rs.Produces;
-import javax.ws.rs.WebApplicationException;
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.MultivaluedMap;
-import javax.ws.rs.ext.MessageBodyWriter;
-import javax.ws.rs.ext.Provider;
-
-import java.io.IOException;
-import java.io.OutputStream;
-import java.lang.annotation.Annotation;
-import java.lang.reflect.Type;
-import java.util.Map;
-
-import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
-import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;
-
-@Provider
-@Produces("application/x-tar")
-public class TarWriter implements MessageBodyWriter<Map<String, byte[]>> {
-    private static void tarStoreBuffer(TarArchiveOutputStream zip, String name, byte[] dataBuffer) throws IOException {
-        TarArchiveEntry entry = new TarArchiveEntry(name);
-
-        entry.setSize(dataBuffer.length);
-
-        zip.putArchiveEntry(entry);
-
-        zip.write(dataBuffer);
-
-        zip.closeArchiveEntry();
-    }
-
-    public boolean isWriteable(Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
-        return Map.class.isAssignableFrom(type);
-    }
-
-    public long getSize(Map<String, byte[]> stringMap, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
-        return -1;
-    }
-
-    public void writeTo(Map<String, byte[]> parts, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType, MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream) throws IOException, WebApplicationException {
-        TarArchiveOutputStream zip = new TarArchiveOutputStream(entityStream);
-
-        for (Map.Entry<String, byte[]> entry : parts.entrySet()) {
-            tarStoreBuffer(zip, entry.getKey(), entry.getValue());
-        }
-
-        zip.close();
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server.writer;
+
+import javax.ws.rs.Produces;
+import javax.ws.rs.WebApplicationException;
+import javax.ws.rs.core.MediaType;
+import javax.ws.rs.core.MultivaluedMap;
+import javax.ws.rs.ext.MessageBodyWriter;
+import javax.ws.rs.ext.Provider;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.lang.annotation.Annotation;
+import java.lang.reflect.Type;
+import java.util.Map;
+
+import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
+import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;
+
+@Provider
+@Produces("application/x-tar")
+public class TarWriter implements MessageBodyWriter<Map<String, byte[]>> {
+    private static void tarStoreBuffer(TarArchiveOutputStream zip, String name, byte[] dataBuffer) throws IOException {
+        TarArchiveEntry entry = new TarArchiveEntry(name);
+
+        entry.setSize(dataBuffer.length);
+
+        zip.putArchiveEntry(entry);
+
+        zip.write(dataBuffer);
+
+        zip.closeArchiveEntry();
+    }
+
+    public boolean isWriteable(Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+        return Map.class.isAssignableFrom(type);
+    }
+
+    public long getSize(Map<String, byte[]> stringMap, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+        return -1;
+    }
+
+    public void writeTo(Map<String, byte[]> parts, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType, MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream) throws IOException, WebApplicationException {
+        TarArchiveOutputStream zip = new TarArchiveOutputStream(entityStream);
+
+        for (Map.Entry<String, byte[]> entry : parts.entrySet()) {
+            tarStoreBuffer(zip, entry.getKey(), entry.getValue());
+        }
+
+        zip.close();
+    }
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/writer/TextMessageBodyWriter.java b/tika-server/src/main/java/org/apache/tika/server/writer/TextMessageBodyWriter.java
index 04570eb06..c4c106c74 100644
--- a/tika-server/src/main/java/org/apache/tika/server/writer/TextMessageBodyWriter.java
+++ b/tika-server/src/main/java/org/apache/tika/server/writer/TextMessageBodyWriter.java
@@ -1,75 +1,75 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server.writer;
-
-import javax.ws.rs.Produces;
-import javax.ws.rs.WebApplicationException;
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.MultivaluedMap;
-import javax.ws.rs.ext.MessageBodyWriter;
-import javax.ws.rs.ext.Provider;
-
-import java.io.IOException;
-import java.io.OutputStream;
-import java.io.OutputStreamWriter;
-import java.io.Writer;
-import java.lang.annotation.Annotation;
-import java.lang.reflect.Type;
-
-import org.apache.tika.io.IOUtils;
-import org.apache.tika.metadata.Metadata;
-
-/**
- * Returns simple text string for a particular metadata value.
- * This assumes that the metadata object only has one key;
- * if there is more than one key or no keys, this will throw a webapp exception.
- * <p/>
- * This will choose the first value returned for the one key.
- */
-@Provider
-@Produces(MediaType.TEXT_PLAIN)
-public class TextMessageBodyWriter implements MessageBodyWriter<Metadata> {
-
-    public boolean isWriteable(Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
-        return mediaType.equals(MediaType.TEXT_PLAIN_TYPE) && Metadata.class.isAssignableFrom(type);
-    }
-
-    public long getSize(Metadata data, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
-        return -1;
-    }
-
-    @Override
-    @SuppressWarnings("resource")
-    public void writeTo(Metadata metadata, Class<?> type, Type genericType, Annotation[] annotations,
-                        MediaType mediaType, MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream) throws IOException,
-            WebApplicationException {
-
-        if (metadata.names().length != 1) {
-            throw new WebApplicationException("Metadata object must only have one entry!");
-        }
-        Writer writer = new OutputStreamWriter(entityStream, IOUtils.UTF_8);
-
-        for (String name : metadata.names()) {
-            writer.write(metadata.get(name));
-        }
-
-        // Don't close, just flush the stream
-        writer.flush();
-    }
-}
-
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server.writer;
+
+import javax.ws.rs.Produces;
+import javax.ws.rs.WebApplicationException;
+import javax.ws.rs.core.MediaType;
+import javax.ws.rs.core.MultivaluedMap;
+import javax.ws.rs.ext.MessageBodyWriter;
+import javax.ws.rs.ext.Provider;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.io.OutputStreamWriter;
+import java.io.Writer;
+import java.lang.annotation.Annotation;
+import java.lang.reflect.Type;
+
+import org.apache.tika.io.IOUtils;
+import org.apache.tika.metadata.Metadata;
+
+/**
+ * Returns simple text string for a particular metadata value.
+ * This assumes that the metadata object only has one key;
+ * if there is more than one key or no keys, this will throw a webapp exception.
+ * <p/>
+ * This will choose the first value returned for the one key.
+ */
+@Provider
+@Produces(MediaType.TEXT_PLAIN)
+public class TextMessageBodyWriter implements MessageBodyWriter<Metadata> {
+
+    public boolean isWriteable(Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+        return mediaType.equals(MediaType.TEXT_PLAIN_TYPE) && Metadata.class.isAssignableFrom(type);
+    }
+
+    public long getSize(Metadata data, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+        return -1;
+    }
+
+    @Override
+    @SuppressWarnings("resource")
+    public void writeTo(Metadata metadata, Class<?> type, Type genericType, Annotation[] annotations,
+                        MediaType mediaType, MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream) throws IOException,
+            WebApplicationException {
+
+        if (metadata.names().length != 1) {
+            throw new WebApplicationException("Metadata object must only have one entry!");
+        }
+        Writer writer = new OutputStreamWriter(entityStream, IOUtils.UTF_8);
+
+        for (String name : metadata.names()) {
+            writer.write(metadata.get(name));
+        }
+
+        // Don't close, just flush the stream
+        writer.flush();
+    }
+}
+
diff --git a/tika-server/src/main/java/org/apache/tika/server/writer/ZipWriter.java b/tika-server/src/main/java/org/apache/tika/server/writer/ZipWriter.java
index c4adc5e16..24cae80c6 100644
--- a/tika-server/src/main/java/org/apache/tika/server/writer/ZipWriter.java
+++ b/tika-server/src/main/java/org/apache/tika/server/writer/ZipWriter.java
@@ -1,86 +1,86 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server.writer;
-
-import javax.ws.rs.Produces;
-import javax.ws.rs.WebApplicationException;
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.MultivaluedMap;
-import javax.ws.rs.ext.MessageBodyWriter;
-import javax.ws.rs.ext.Provider;
-
-import java.io.IOException;
-import java.io.OutputStream;
-import java.lang.annotation.Annotation;
-import java.lang.reflect.Type;
-import java.util.Map;
-import java.util.UUID;
-import java.util.zip.CRC32;
-import java.util.zip.ZipEntry;
-import java.util.zip.ZipException;
-import java.util.zip.ZipOutputStream;
-
-import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
-import org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;
-
-@Provider
-@Produces("application/zip")
-public class ZipWriter implements MessageBodyWriter<Map<String, byte[]>> {
-    private static void zipStoreBuffer(ZipArchiveOutputStream zip, String name, byte[] dataBuffer) throws IOException {
-        ZipEntry zipEntry = new ZipEntry(name != null ? name : UUID.randomUUID().toString());
-        zipEntry.setMethod(ZipOutputStream.STORED);
-
-        zipEntry.setSize(dataBuffer.length);
-        CRC32 crc32 = new CRC32();
-        crc32.update(dataBuffer);
-        zipEntry.setCrc(crc32.getValue());
-
-        try {
-            zip.putArchiveEntry(new ZipArchiveEntry(zipEntry));
-        } catch (ZipException ex) {
-            if (name != null) {
-                zipStoreBuffer(zip, "x-" + name, dataBuffer);
-                return;
-            }
-        }
-
-        zip.write(dataBuffer);
-
-        zip.closeArchiveEntry();
-    }
-
-    public boolean isWriteable(Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
-        return Map.class.isAssignableFrom(type);
-    }
-
-    public long getSize(Map<String, byte[]> stringMap, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
-        return -1;
-    }
-
-    public void writeTo(Map<String, byte[]> parts, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType, MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream) throws IOException, WebApplicationException {
-        ZipArchiveOutputStream zip = new ZipArchiveOutputStream(entityStream);
-
-        zip.setMethod(ZipArchiveOutputStream.STORED);
-
-        for (Map.Entry<String, byte[]> entry : parts.entrySet()) {
-            zipStoreBuffer(zip, entry.getKey(), entry.getValue());
-        }
-
-        zip.close();
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server.writer;
+
+import javax.ws.rs.Produces;
+import javax.ws.rs.WebApplicationException;
+import javax.ws.rs.core.MediaType;
+import javax.ws.rs.core.MultivaluedMap;
+import javax.ws.rs.ext.MessageBodyWriter;
+import javax.ws.rs.ext.Provider;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.lang.annotation.Annotation;
+import java.lang.reflect.Type;
+import java.util.Map;
+import java.util.UUID;
+import java.util.zip.CRC32;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipException;
+import java.util.zip.ZipOutputStream;
+
+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;
+
+@Provider
+@Produces("application/zip")
+public class ZipWriter implements MessageBodyWriter<Map<String, byte[]>> {
+    private static void zipStoreBuffer(ZipArchiveOutputStream zip, String name, byte[] dataBuffer) throws IOException {
+        ZipEntry zipEntry = new ZipEntry(name != null ? name : UUID.randomUUID().toString());
+        zipEntry.setMethod(ZipOutputStream.STORED);
+
+        zipEntry.setSize(dataBuffer.length);
+        CRC32 crc32 = new CRC32();
+        crc32.update(dataBuffer);
+        zipEntry.setCrc(crc32.getValue());
+
+        try {
+            zip.putArchiveEntry(new ZipArchiveEntry(zipEntry));
+        } catch (ZipException ex) {
+            if (name != null) {
+                zipStoreBuffer(zip, "x-" + name, dataBuffer);
+                return;
+            }
+        }
+
+        zip.write(dataBuffer);
+
+        zip.closeArchiveEntry();
+    }
+
+    public boolean isWriteable(Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+        return Map.class.isAssignableFrom(type);
+    }
+
+    public long getSize(Map<String, byte[]> stringMap, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+        return -1;
+    }
+
+    public void writeTo(Map<String, byte[]> parts, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType, MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream) throws IOException, WebApplicationException {
+        ZipArchiveOutputStream zip = new ZipArchiveOutputStream(entityStream);
+
+        zip.setMethod(ZipArchiveOutputStream.STORED);
+
+        for (Map.Entry<String, byte[]> entry : parts.entrySet()) {
+            zipStoreBuffer(zip, entry.getKey(), entry.getValue());
+        }
+
+        zip.close();
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java b/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
index 860bbd280..bf653ff5e 100644
--- a/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
+++ b/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
@@ -1,172 +1,172 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
-
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.Enumeration;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.commons.codec.digest.DigestUtils;
-import org.apache.commons.compress.archivers.ArchiveEntry;
-import org.apache.commons.compress.archivers.ArchiveInputStream;
-import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
-import org.apache.commons.compress.archivers.zip.ZipFile;
-import org.apache.cxf.binding.BindingFactoryManager;
-import org.apache.cxf.endpoint.Server;
-import org.apache.cxf.jaxrs.JAXRSBindingFactory;
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.tika.config.TikaConfig;
-import org.apache.tika.io.IOUtils;
-import org.apache.tika.server.resource.UnpackerResource;
-import org.junit.After;
-import org.junit.Before;
-
-public abstract class CXFTestBase {
-    protected static final String endPoint =
-            "http://localhost:" + TikaServerCli.DEFAULT_PORT;
-    protected Server server;
-    protected TikaConfig tika;
-
-    public static void assertContains(String needle, String haystack) {
-        assertTrue(needle + " not found in:\n" + haystack, haystack.contains(needle));
-    }
-
-    public static void assertNotFound(String needle, String haystack) {
-        assertFalse(needle + " unexpectedly found in:\n" + haystack, haystack.contains(needle));
-    }
-
-    protected static InputStream copy(InputStream in, int remaining) throws IOException {
-        ByteArrayOutputStream out = new ByteArrayOutputStream();
-        while (remaining > 0) {
-            byte[] bytes = new byte[remaining];
-            int n = in.read(bytes);
-            if (n <= 0) {
-                break;
-            }
-            out.write(bytes, 0, n);
-            remaining -= n;
-        }
-        return new ByteArrayInputStream(out.toByteArray());
-    }
-
-    @Before
-    public void setUp() {
-        this.tika = TikaConfig.getDefaultConfig();
-
-        JAXRSServerFactoryBean sf = new JAXRSServerFactoryBean();
-        setUpResources(sf);
-        setUpProviders(sf);
-        sf.setAddress(endPoint + "/");
-
-        BindingFactoryManager manager = sf.getBus().getExtension(
-                BindingFactoryManager.class
-        );
-
-        JAXRSBindingFactory factory = new JAXRSBindingFactory();
-        factory.setBus(sf.getBus());
-
-        manager.registerBindingFactory(
-                JAXRSBindingFactory.JAXRS_BINDING_ID,
-                factory
-        );
-
-        server = sf.create();
-    }
-
-    /**
-     * Have the test do {@link JAXRSServerFactoryBean#setResourceClasses(Class...)}
-     * and {@link JAXRSServerFactoryBean#setResourceProvider(Class, org.apache.cxf.jaxrs.lifecycle.ResourceProvider)}
-     */
-    protected abstract void setUpResources(JAXRSServerFactoryBean sf);
-
-    /**
-     * Have the test do {@link JAXRSServerFactoryBean#setProviders(java.util.List)}, if needed
-     */
-    protected abstract void setUpProviders(JAXRSServerFactoryBean sf);
-
-    @After
-    public void tearDown() throws Exception {
-        server.stop();
-        server.destroy();
-    }
-
-    protected String getStringFromInputStream(InputStream in) throws Exception {
-        return IOUtils.toString(in);
-    }
-
-    protected Map<String, String> readZipArchive(InputStream inputStream) throws IOException {
-        Map<String, String> data = new HashMap<String, String>();
-        File tempFile = writeTemporaryArchiveFile(inputStream, "zip");
-        ZipFile zip = new ZipFile(tempFile);
-        Enumeration<ZipArchiveEntry> entries = zip.getEntries();
-        while (entries.hasMoreElements()) {
-            ZipArchiveEntry entry = entries.nextElement();
-            ByteArrayOutputStream bos = new ByteArrayOutputStream();
-            IOUtils.copy(zip.getInputStream(entry), bos);
-            data.put(entry.getName(), DigestUtils.md5Hex(bos.toByteArray()));
-        }
-
-        zip.close();
-        tempFile.delete();
-        return data;
-    }
-
-    protected String readArchiveText(InputStream inputStream) throws IOException {
-        File tempFile = writeTemporaryArchiveFile(inputStream, "zip");
-        ZipFile zip = new ZipFile(tempFile);
-        zip.getEntry(UnpackerResource.TEXT_FILENAME);
-        ByteArrayOutputStream bos = new ByteArrayOutputStream();
-        IOUtils.copy(zip.getInputStream(zip.getEntry(UnpackerResource.TEXT_FILENAME)), bos);
-
-        zip.close();
-        tempFile.delete();
-        return bos.toString(IOUtils.UTF_8.name());
-    }
-
-    protected Map<String, String> readArchiveFromStream(ArchiveInputStream zip) throws IOException {
-        Map<String, String> data = new HashMap<String, String>();
-        while (true) {
-            ArchiveEntry entry = zip.getNextEntry();
-            if (entry == null) {
-                break;
-            }
-
-            ByteArrayOutputStream bos = new ByteArrayOutputStream();
-            IOUtils.copy(zip, bos);
-            data.put(entry.getName(), DigestUtils.md5Hex(bos.toByteArray()));
-        }
-
-        return data;
-    }
-
-    private File writeTemporaryArchiveFile(InputStream inputStream, String archiveType) throws IOException {
-        File tempFile = File.createTempFile("tmp-", "." + archiveType);
-        IOUtils.copy(inputStream, new FileOutputStream(tempFile));
-        return tempFile;
-    }
-
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Enumeration;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.commons.codec.digest.DigestUtils;
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipFile;
+import org.apache.cxf.binding.BindingFactoryManager;
+import org.apache.cxf.endpoint.Server;
+import org.apache.cxf.jaxrs.JAXRSBindingFactory;
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.io.IOUtils;
+import org.apache.tika.server.resource.UnpackerResource;
+import org.junit.After;
+import org.junit.Before;
+
+public abstract class CXFTestBase {
+    protected static final String endPoint =
+            "http://localhost:" + TikaServerCli.DEFAULT_PORT;
+    protected Server server;
+    protected TikaConfig tika;
+
+    public static void assertContains(String needle, String haystack) {
+        assertTrue(needle + " not found in:\n" + haystack, haystack.contains(needle));
+    }
+
+    public static void assertNotFound(String needle, String haystack) {
+        assertFalse(needle + " unexpectedly found in:\n" + haystack, haystack.contains(needle));
+    }
+
+    protected static InputStream copy(InputStream in, int remaining) throws IOException {
+        ByteArrayOutputStream out = new ByteArrayOutputStream();
+        while (remaining > 0) {
+            byte[] bytes = new byte[remaining];
+            int n = in.read(bytes);
+            if (n <= 0) {
+                break;
+            }
+            out.write(bytes, 0, n);
+            remaining -= n;
+        }
+        return new ByteArrayInputStream(out.toByteArray());
+    }
+
+    @Before
+    public void setUp() {
+        this.tika = TikaConfig.getDefaultConfig();
+
+        JAXRSServerFactoryBean sf = new JAXRSServerFactoryBean();
+        setUpResources(sf);
+        setUpProviders(sf);
+        sf.setAddress(endPoint + "/");
+
+        BindingFactoryManager manager = sf.getBus().getExtension(
+                BindingFactoryManager.class
+        );
+
+        JAXRSBindingFactory factory = new JAXRSBindingFactory();
+        factory.setBus(sf.getBus());
+
+        manager.registerBindingFactory(
+                JAXRSBindingFactory.JAXRS_BINDING_ID,
+                factory
+        );
+
+        server = sf.create();
+    }
+
+    /**
+     * Have the test do {@link JAXRSServerFactoryBean#setResourceClasses(Class...)}
+     * and {@link JAXRSServerFactoryBean#setResourceProvider(Class, org.apache.cxf.jaxrs.lifecycle.ResourceProvider)}
+     */
+    protected abstract void setUpResources(JAXRSServerFactoryBean sf);
+
+    /**
+     * Have the test do {@link JAXRSServerFactoryBean#setProviders(java.util.List)}, if needed
+     */
+    protected abstract void setUpProviders(JAXRSServerFactoryBean sf);
+
+    @After
+    public void tearDown() throws Exception {
+        server.stop();
+        server.destroy();
+    }
+
+    protected String getStringFromInputStream(InputStream in) throws Exception {
+        return IOUtils.toString(in);
+    }
+
+    protected Map<String, String> readZipArchive(InputStream inputStream) throws IOException {
+        Map<String, String> data = new HashMap<String, String>();
+        File tempFile = writeTemporaryArchiveFile(inputStream, "zip");
+        ZipFile zip = new ZipFile(tempFile);
+        Enumeration<ZipArchiveEntry> entries = zip.getEntries();
+        while (entries.hasMoreElements()) {
+            ZipArchiveEntry entry = entries.nextElement();
+            ByteArrayOutputStream bos = new ByteArrayOutputStream();
+            IOUtils.copy(zip.getInputStream(entry), bos);
+            data.put(entry.getName(), DigestUtils.md5Hex(bos.toByteArray()));
+        }
+
+        zip.close();
+        tempFile.delete();
+        return data;
+    }
+
+    protected String readArchiveText(InputStream inputStream) throws IOException {
+        File tempFile = writeTemporaryArchiveFile(inputStream, "zip");
+        ZipFile zip = new ZipFile(tempFile);
+        zip.getEntry(UnpackerResource.TEXT_FILENAME);
+        ByteArrayOutputStream bos = new ByteArrayOutputStream();
+        IOUtils.copy(zip.getInputStream(zip.getEntry(UnpackerResource.TEXT_FILENAME)), bos);
+
+        zip.close();
+        tempFile.delete();
+        return bos.toString(IOUtils.UTF_8.name());
+    }
+
+    protected Map<String, String> readArchiveFromStream(ArchiveInputStream zip) throws IOException {
+        Map<String, String> data = new HashMap<String, String>();
+        while (true) {
+            ArchiveEntry entry = zip.getNextEntry();
+            if (entry == null) {
+                break;
+            }
+
+            ByteArrayOutputStream bos = new ByteArrayOutputStream();
+            IOUtils.copy(zip, bos);
+            data.put(entry.getName(), DigestUtils.md5Hex(bos.toByteArray()));
+        }
+
+        return data;
+    }
+
+    private File writeTemporaryArchiveFile(InputStream inputStream, String archiveType) throws IOException {
+        File tempFile = File.createTempFile("tmp-", "." + archiveType);
+        IOUtils.copy(inputStream, new FileOutputStream(tempFile));
+        return tempFile;
+    }
+
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/DetectorResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/DetectorResourceTest.java
index 971c32988..faa9486a4 100644
--- a/tika-server/src/test/java/org/apache/tika/server/DetectorResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/DetectorResourceTest.java
@@ -1,107 +1,107 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.server.resource.DetectorResource;
-import org.apache.tika.server.writer.TarWriter;
-import org.apache.tika.server.writer.ZipWriter;
-import org.junit.Test;
-
-public class DetectorResourceTest extends CXFTestBase {
-
-    private static final String DETECT_PATH = "/detect";
-    private static final String DETECT_STREAM_PATH = DETECT_PATH + "/stream";
-    private static final String FOO_CSV = "foo.csv";
-    private static final String CDEC_CSV_NO_EXT = "CDEC_WEATHER_2010_03_02";
-
-    @Override
-    protected void setUpResources(JAXRSServerFactoryBean sf) {
-        sf.setResourceClasses(DetectorResource.class);
-        sf.setResourceProvider(DetectorResource.class,
-                new SingletonResourceProvider(new DetectorResource(tika)));
-
-    }
-
-    @Override
-    protected void setUpProviders(JAXRSServerFactoryBean sf) {
-        List<Object> providers = new ArrayList<Object>();
-        providers.add(new TarWriter());
-        providers.add(new ZipWriter());
-        providers.add(new TikaServerParseExceptionMapper(false));
-        sf.setProviders(providers);
-
-    }
-
-    @Test
-    public void testDetectCsvWithExt() throws Exception {
-        String url = endPoint + DETECT_STREAM_PATH;
-        Response response = WebClient
-                .create(endPoint + DETECT_STREAM_PATH)
-                .type("text/csv")
-                .accept("*/*")
-                .header("Content-Disposition",
-                        "attachment; filename=" + FOO_CSV)
-                .put(ClassLoader.getSystemResourceAsStream(FOO_CSV));
-        assertNotNull(response);
-        String readMime = getStringFromInputStream((InputStream) response
-                .getEntity());
-        assertEquals("text/csv", readMime);
-
-    }
-
-    @Test
-    public void testDetectCsvNoExt() throws Exception {
-        String url = endPoint + DETECT_STREAM_PATH;
-        Response response = WebClient
-                .create(endPoint + DETECT_STREAM_PATH)
-                .type("text/csv")
-                .accept("*/*")
-                .header("Content-Disposition",
-                        "attachment; filename=" + CDEC_CSV_NO_EXT)
-                .put(ClassLoader.getSystemResourceAsStream(CDEC_CSV_NO_EXT));
-        assertNotNull(response);
-        String readMime = getStringFromInputStream((InputStream) response
-                .getEntity());
-        assertEquals("text/plain", readMime);
-
-        // now trick it by adding .csv to the end
-        response = WebClient
-                .create(endPoint + DETECT_STREAM_PATH)
-                .type("text/csv")
-                .accept("*/*")
-                .header("Content-Disposition",
-                        "attachment; filename=" + CDEC_CSV_NO_EXT + ".csv")
-                .put(ClassLoader.getSystemResourceAsStream(CDEC_CSV_NO_EXT));
-        assertNotNull(response);
-        readMime = getStringFromInputStream((InputStream) response.getEntity());
-        assertEquals("text/csv", readMime);
-
-    }
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.server.resource.DetectorResource;
+import org.apache.tika.server.writer.TarWriter;
+import org.apache.tika.server.writer.ZipWriter;
+import org.junit.Test;
+
+public class DetectorResourceTest extends CXFTestBase {
+
+    private static final String DETECT_PATH = "/detect";
+    private static final String DETECT_STREAM_PATH = DETECT_PATH + "/stream";
+    private static final String FOO_CSV = "foo.csv";
+    private static final String CDEC_CSV_NO_EXT = "CDEC_WEATHER_2010_03_02";
+
+    @Override
+    protected void setUpResources(JAXRSServerFactoryBean sf) {
+        sf.setResourceClasses(DetectorResource.class);
+        sf.setResourceProvider(DetectorResource.class,
+                new SingletonResourceProvider(new DetectorResource(tika)));
+
+    }
+
+    @Override
+    protected void setUpProviders(JAXRSServerFactoryBean sf) {
+        List<Object> providers = new ArrayList<Object>();
+        providers.add(new TarWriter());
+        providers.add(new ZipWriter());
+        providers.add(new TikaServerParseExceptionMapper(false));
+        sf.setProviders(providers);
+
+    }
+
+    @Test
+    public void testDetectCsvWithExt() throws Exception {
+        String url = endPoint + DETECT_STREAM_PATH;
+        Response response = WebClient
+                .create(endPoint + DETECT_STREAM_PATH)
+                .type("text/csv")
+                .accept("*/*")
+                .header("Content-Disposition",
+                        "attachment; filename=" + FOO_CSV)
+                .put(ClassLoader.getSystemResourceAsStream(FOO_CSV));
+        assertNotNull(response);
+        String readMime = getStringFromInputStream((InputStream) response
+                .getEntity());
+        assertEquals("text/csv", readMime);
+
+    }
+
+    @Test
+    public void testDetectCsvNoExt() throws Exception {
+        String url = endPoint + DETECT_STREAM_PATH;
+        Response response = WebClient
+                .create(endPoint + DETECT_STREAM_PATH)
+                .type("text/csv")
+                .accept("*/*")
+                .header("Content-Disposition",
+                        "attachment; filename=" + CDEC_CSV_NO_EXT)
+                .put(ClassLoader.getSystemResourceAsStream(CDEC_CSV_NO_EXT));
+        assertNotNull(response);
+        String readMime = getStringFromInputStream((InputStream) response
+                .getEntity());
+        assertEquals("text/plain", readMime);
+
+        // now trick it by adding .csv to the end
+        response = WebClient
+                .create(endPoint + DETECT_STREAM_PATH)
+                .type("text/csv")
+                .accept("*/*")
+                .header("Content-Disposition",
+                        "attachment; filename=" + CDEC_CSV_NO_EXT + ".csv")
+                .put(ClassLoader.getSystemResourceAsStream(CDEC_CSV_NO_EXT));
+        assertNotNull(response);
+        readMime = getStringFromInputStream((InputStream) response.getEntity());
+        assertEquals("text/csv", readMime);
+
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/LanguageResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/LanguageResourceTest.java
index 81f69253d..5c3c87176 100644
--- a/tika-server/src/test/java/org/apache/tika/server/LanguageResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/LanguageResourceTest.java
@@ -1,109 +1,109 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.server.resource.LanguageResource;
-import org.apache.tika.server.writer.TarWriter;
-import org.apache.tika.server.writer.ZipWriter;
-import org.junit.Test;
-
-public class LanguageResourceTest extends CXFTestBase {
-
-	private static final String LANG_PATH = "/language";
-	private static final String LANG_STREAM_PATH = LANG_PATH + "/stream";
-	private static final String LANG_STRING_PATH = LANG_PATH + "/string";
-	private static final String ENGLISH_STRING = "This is English!";
-	private static final String FRENCH_STRING = "comme i comme a";
-
-	@Override
-	protected void setUpResources(JAXRSServerFactoryBean sf) {
-		sf.setResourceClasses(LanguageResource.class);
-		sf.setResourceProvider(LanguageResource.class,
-				new SingletonResourceProvider(new LanguageResource(tika)));
-
-	}
-
-	@Override
-	protected void setUpProviders(JAXRSServerFactoryBean sf) {
-		List<Object> providers = new ArrayList<Object>();
-		providers.add(new TarWriter());
-		providers.add(new ZipWriter());
-		providers.add(new TikaServerParseExceptionMapper(false));
-		sf.setProviders(providers);
-
-	}
-
-	@Test
-	public void testDetectEnglishString() throws Exception {
-		String url = endPoint + LANG_STRING_PATH;
-		Response response = WebClient.create(url).type("text/plain")
-				.accept("text/plain").put(ENGLISH_STRING);
-		assertNotNull(response);
-		String readLang = getStringFromInputStream((InputStream) response
-				.getEntity());
-		assertEquals("en", readLang);
-	}
-
-	@Test
-	public void testDetectFrenchString() throws Exception {
-		String url = endPoint + LANG_STRING_PATH;
-		Response response = WebClient.create(url).type("text/plain")
-				.accept("text/plain").put(FRENCH_STRING);
-		assertNotNull(response);
-		String readLang = getStringFromInputStream((InputStream) response
-				.getEntity());
-		assertEquals("fr", readLang);
-	}
-
-	@Test
-	public void testDetectEnglishFile() throws Exception {
-		String url = endPoint + LANG_STREAM_PATH;
-		Response response = WebClient.create(url).type("text/plain")
-				.accept("text/plain")
-				.put(ClassLoader.getSystemResourceAsStream("english.txt"));
-		assertNotNull(response);
-		String readLang = getStringFromInputStream((InputStream) response
-				.getEntity());
-		assertEquals("en", readLang);
-	}
-
-	@Test
-	public void testDetectFrenchFile() throws Exception {
-		String url = endPoint + LANG_STREAM_PATH;
-		Response response = WebClient.create(url).type("text/plain")
-				.accept("text/plain")
-				.put(ClassLoader.getSystemResourceAsStream("french.txt"));
-		assertNotNull(response);
-		String readLang = getStringFromInputStream((InputStream) response
-				.getEntity());
-		assertEquals("fr", readLang);
-	}
-
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.server.resource.LanguageResource;
+import org.apache.tika.server.writer.TarWriter;
+import org.apache.tika.server.writer.ZipWriter;
+import org.junit.Test;
+
+public class LanguageResourceTest extends CXFTestBase {
+
+	private static final String LANG_PATH = "/language";
+	private static final String LANG_STREAM_PATH = LANG_PATH + "/stream";
+	private static final String LANG_STRING_PATH = LANG_PATH + "/string";
+	private static final String ENGLISH_STRING = "This is English!";
+	private static final String FRENCH_STRING = "comme i comme a";
+
+	@Override
+	protected void setUpResources(JAXRSServerFactoryBean sf) {
+		sf.setResourceClasses(LanguageResource.class);
+		sf.setResourceProvider(LanguageResource.class,
+				new SingletonResourceProvider(new LanguageResource(tika)));
+
+	}
+
+	@Override
+	protected void setUpProviders(JAXRSServerFactoryBean sf) {
+		List<Object> providers = new ArrayList<Object>();
+		providers.add(new TarWriter());
+		providers.add(new ZipWriter());
+		providers.add(new TikaServerParseExceptionMapper(false));
+		sf.setProviders(providers);
+
+	}
+
+	@Test
+	public void testDetectEnglishString() throws Exception {
+		String url = endPoint + LANG_STRING_PATH;
+		Response response = WebClient.create(url).type("text/plain")
+				.accept("text/plain").put(ENGLISH_STRING);
+		assertNotNull(response);
+		String readLang = getStringFromInputStream((InputStream) response
+				.getEntity());
+		assertEquals("en", readLang);
+	}
+
+	@Test
+	public void testDetectFrenchString() throws Exception {
+		String url = endPoint + LANG_STRING_PATH;
+		Response response = WebClient.create(url).type("text/plain")
+				.accept("text/plain").put(FRENCH_STRING);
+		assertNotNull(response);
+		String readLang = getStringFromInputStream((InputStream) response
+				.getEntity());
+		assertEquals("fr", readLang);
+	}
+
+	@Test
+	public void testDetectEnglishFile() throws Exception {
+		String url = endPoint + LANG_STREAM_PATH;
+		Response response = WebClient.create(url).type("text/plain")
+				.accept("text/plain")
+				.put(ClassLoader.getSystemResourceAsStream("english.txt"));
+		assertNotNull(response);
+		String readLang = getStringFromInputStream((InputStream) response
+				.getEntity());
+		assertEquals("en", readLang);
+	}
+
+	@Test
+	public void testDetectFrenchFile() throws Exception {
+		String url = endPoint + LANG_STREAM_PATH;
+		Response response = WebClient.create(url).type("text/plain")
+				.accept("text/plain")
+				.put(ClassLoader.getSystemResourceAsStream("french.txt"));
+		assertNotNull(response);
+		String readLang = getStringFromInputStream((InputStream) response
+				.getEntity());
+		assertEquals("fr", readLang);
+	}
+
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/StackTraceOffTest.java b/tika-server/src/test/java/org/apache/tika/server/StackTraceOffTest.java
index 6e664e5c9..a2a67abb8 100644
--- a/tika-server/src/test/java/org/apache/tika/server/StackTraceOffTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/StackTraceOffTest.java
@@ -1,150 +1,150 @@
-package org.apache.tika.server;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- * <p/>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p/>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.ResourceProvider;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.server.resource.DetectorResource;
-import org.apache.tika.server.resource.MetadataResource;
-import org.apache.tika.server.resource.RecursiveMetadataResource;
-import org.apache.tika.server.resource.TikaResource;
-import org.apache.tika.server.resource.UnpackerResource;
-import org.apache.tika.server.writer.CSVMessageBodyWriter;
-import org.apache.tika.server.writer.JSONMessageBodyWriter;
-import org.apache.tika.server.writer.TextMessageBodyWriter;
-import org.apache.tika.server.writer.XMPMessageBodyWriter;
-import org.junit.Assert;
-import org.junit.Test;
-
-
-/**
- * Test to make sure that no stack traces are returned
- * when the stack trace param is set to false.
- */
-public class StackTraceOffTest extends CXFTestBase {
-    public static final String TEST_NULL = "mock/null_pointer.xml";
-    public static final String TEST_PASSWORD_PROTECTED = "password.xls";
-
-    private static final String[] PATHS = new String[]{
-            "/tika",
-            "/rmeta",
-            "/unpack",
-            "/meta",
-    };
-    private static final int UNPROCESSEABLE = 422;
-
-    @Override
-    protected void setUpResources(JAXRSServerFactoryBean sf) {
-        List<ResourceProvider> rCoreProviders = new ArrayList<ResourceProvider>();
-        rCoreProviders.add(new SingletonResourceProvider(new MetadataResource(tika)));
-        rCoreProviders.add(new SingletonResourceProvider(new RecursiveMetadataResource(tika)));
-        rCoreProviders.add(new SingletonResourceProvider(new DetectorResource(tika)));
-        rCoreProviders.add(new SingletonResourceProvider(new TikaResource(tika)));
-        rCoreProviders.add(new SingletonResourceProvider(new UnpackerResource(tika)));
-        sf.setResourceProviders(rCoreProviders);
-    }
-
-    @Override
-    protected void setUpProviders(JAXRSServerFactoryBean sf) {
-        List<Object> providers = new ArrayList<Object>();
-        providers.add(new TikaServerParseExceptionMapper(false));
-        providers.add(new JSONMessageBodyWriter());
-        providers.add(new CSVMessageBodyWriter());
-        providers.add(new XMPMessageBodyWriter());
-        providers.add(new TextMessageBodyWriter());
-        sf.setProviders(providers);
-    }
-
-    @Test
-    public void testEncrypted() throws Exception {
-        for (String path : PATHS) {
-            Response response = WebClient
-                    .create(endPoint + path)
-                    .accept("*/*")
-                    .header("Content-Disposition",
-                            "attachment; filename=" + TEST_PASSWORD_PROTECTED)
-                    .put(ClassLoader.getSystemResourceAsStream(TEST_PASSWORD_PROTECTED));
-            assertNotNull("null response: " + path, response);
-            assertEquals("unprocessable: " + path, UNPROCESSEABLE, response.getStatus());
-            String msg = getStringFromInputStream((InputStream) response
-                    .getEntity());
-            assertEquals("should be empty: " + path, "", msg);
-        }
-    }
-
-    @Test
-    public void testNullPointerOnTika() throws Exception {
-        for (String path : PATHS) {
-            Response response = WebClient
-                    .create(endPoint + path)
-                    .accept("*/*")
-                    .put(ClassLoader.getSystemResourceAsStream(TEST_NULL));
-            assertNotNull("null response: " + path, response);
-            assertEquals("unprocessable: " + path, UNPROCESSEABLE, response.getStatus());
-            String msg = getStringFromInputStream((InputStream) response
-                    .getEntity());
-            assertEquals("should be empty: " + path, "", msg);
-        }
-    }
-
-    @Test
-    public void test415() throws Exception {
-        //no stack traces for 415
-        for (String path : PATHS) {
-            Response response = WebClient
-                    .create(endPoint + path)
-                    .type("blechdeblah/deblechdeblah")
-                    .accept("*/*")
-                    .header("Content-Disposition",
-                            "attachment; filename=null_pointer.evil")
-                    .put(ClassLoader.getSystemResourceAsStream(TEST_NULL));
-            assertNotNull("null response: " + path, response);
-            assertEquals("bad type: " + path, 415, response.getStatus());
-            String msg = getStringFromInputStream((InputStream) response
-                    .getEntity());
-            assertEquals("should be empty: " + path, "", msg);
-        }
-    }
-
-    //For now, make sure that non-complete document
-    //still returns BAD_REQUEST.  We may want to
-    //make MetadataResource return the same types of parse
-    //exceptions as the others...
-    @Test
-    public void testMeta() throws Exception {
-        InputStream stream = ClassLoader.getSystemResourceAsStream(TikaResourceTest.TEST_DOC);
-
-        Response response = WebClient.create(endPoint + "/meta" + "/Author").type("application/msword")
-                .accept(MediaType.TEXT_PLAIN).put(copy(stream, 8000));
-        Assert.assertEquals(Response.Status.BAD_REQUEST.getStatusCode(), response.getStatus());
-        String msg = getStringFromInputStream((InputStream) response.getEntity());
-        assertEquals("Failed to get metadata field Author", msg);
-    }
-}
+package org.apache.tika.server;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+
+import javax.ws.rs.core.MediaType;
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.ResourceProvider;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.server.resource.DetectorResource;
+import org.apache.tika.server.resource.MetadataResource;
+import org.apache.tika.server.resource.RecursiveMetadataResource;
+import org.apache.tika.server.resource.TikaResource;
+import org.apache.tika.server.resource.UnpackerResource;
+import org.apache.tika.server.writer.CSVMessageBodyWriter;
+import org.apache.tika.server.writer.JSONMessageBodyWriter;
+import org.apache.tika.server.writer.TextMessageBodyWriter;
+import org.apache.tika.server.writer.XMPMessageBodyWriter;
+import org.junit.Assert;
+import org.junit.Test;
+
+
+/**
+ * Test to make sure that no stack traces are returned
+ * when the stack trace param is set to false.
+ */
+public class StackTraceOffTest extends CXFTestBase {
+    public static final String TEST_NULL = "mock/null_pointer.xml";
+    public static final String TEST_PASSWORD_PROTECTED = "password.xls";
+
+    private static final String[] PATHS = new String[]{
+            "/tika",
+            "/rmeta",
+            "/unpack",
+            "/meta",
+    };
+    private static final int UNPROCESSEABLE = 422;
+
+    @Override
+    protected void setUpResources(JAXRSServerFactoryBean sf) {
+        List<ResourceProvider> rCoreProviders = new ArrayList<ResourceProvider>();
+        rCoreProviders.add(new SingletonResourceProvider(new MetadataResource(tika)));
+        rCoreProviders.add(new SingletonResourceProvider(new RecursiveMetadataResource(tika)));
+        rCoreProviders.add(new SingletonResourceProvider(new DetectorResource(tika)));
+        rCoreProviders.add(new SingletonResourceProvider(new TikaResource(tika)));
+        rCoreProviders.add(new SingletonResourceProvider(new UnpackerResource(tika)));
+        sf.setResourceProviders(rCoreProviders);
+    }
+
+    @Override
+    protected void setUpProviders(JAXRSServerFactoryBean sf) {
+        List<Object> providers = new ArrayList<Object>();
+        providers.add(new TikaServerParseExceptionMapper(false));
+        providers.add(new JSONMessageBodyWriter());
+        providers.add(new CSVMessageBodyWriter());
+        providers.add(new XMPMessageBodyWriter());
+        providers.add(new TextMessageBodyWriter());
+        sf.setProviders(providers);
+    }
+
+    @Test
+    public void testEncrypted() throws Exception {
+        for (String path : PATHS) {
+            Response response = WebClient
+                    .create(endPoint + path)
+                    .accept("*/*")
+                    .header("Content-Disposition",
+                            "attachment; filename=" + TEST_PASSWORD_PROTECTED)
+                    .put(ClassLoader.getSystemResourceAsStream(TEST_PASSWORD_PROTECTED));
+            assertNotNull("null response: " + path, response);
+            assertEquals("unprocessable: " + path, UNPROCESSEABLE, response.getStatus());
+            String msg = getStringFromInputStream((InputStream) response
+                    .getEntity());
+            assertEquals("should be empty: " + path, "", msg);
+        }
+    }
+
+    @Test
+    public void testNullPointerOnTika() throws Exception {
+        for (String path : PATHS) {
+            Response response = WebClient
+                    .create(endPoint + path)
+                    .accept("*/*")
+                    .put(ClassLoader.getSystemResourceAsStream(TEST_NULL));
+            assertNotNull("null response: " + path, response);
+            assertEquals("unprocessable: " + path, UNPROCESSEABLE, response.getStatus());
+            String msg = getStringFromInputStream((InputStream) response
+                    .getEntity());
+            assertEquals("should be empty: " + path, "", msg);
+        }
+    }
+
+    @Test
+    public void test415() throws Exception {
+        //no stack traces for 415
+        for (String path : PATHS) {
+            Response response = WebClient
+                    .create(endPoint + path)
+                    .type("blechdeblah/deblechdeblah")
+                    .accept("*/*")
+                    .header("Content-Disposition",
+                            "attachment; filename=null_pointer.evil")
+                    .put(ClassLoader.getSystemResourceAsStream(TEST_NULL));
+            assertNotNull("null response: " + path, response);
+            assertEquals("bad type: " + path, 415, response.getStatus());
+            String msg = getStringFromInputStream((InputStream) response
+                    .getEntity());
+            assertEquals("should be empty: " + path, "", msg);
+        }
+    }
+
+    //For now, make sure that non-complete document
+    //still returns BAD_REQUEST.  We may want to
+    //make MetadataResource return the same types of parse
+    //exceptions as the others...
+    @Test
+    public void testMeta() throws Exception {
+        InputStream stream = ClassLoader.getSystemResourceAsStream(TikaResourceTest.TEST_DOC);
+
+        Response response = WebClient.create(endPoint + "/meta" + "/Author").type("application/msword")
+                .accept(MediaType.TEXT_PLAIN).put(copy(stream, 8000));
+        Assert.assertEquals(Response.Status.BAD_REQUEST.getStatusCode(), response.getStatus());
+        String msg = getStringFromInputStream((InputStream) response.getEntity());
+        assertEquals("Failed to get metadata field Author", msg);
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/StackTraceTest.java b/tika-server/src/test/java/org/apache/tika/server/StackTraceTest.java
index f3a9ce2e3..15139e690 100644
--- a/tika-server/src/test/java/org/apache/tika/server/StackTraceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/StackTraceTest.java
@@ -1,146 +1,146 @@
-package org.apache.tika.server;
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- * <p/>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p/>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.ResourceProvider;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.server.resource.DetectorResource;
-import org.apache.tika.server.resource.MetadataResource;
-import org.apache.tika.server.resource.RecursiveMetadataResource;
-import org.apache.tika.server.resource.TikaResource;
-import org.apache.tika.server.resource.UnpackerResource;
-import org.apache.tika.server.writer.CSVMessageBodyWriter;
-import org.apache.tika.server.writer.JSONMessageBodyWriter;
-import org.apache.tika.server.writer.TextMessageBodyWriter;
-import org.apache.tika.server.writer.XMPMessageBodyWriter;
-import org.junit.Assert;
-import org.junit.Test;
-
-public class StackTraceTest extends CXFTestBase {
-    public static final String TEST_NULL = "mock/null_pointer.xml";
-    public static final String TEST_PASSWORD_PROTECTED = "password.xls";
-
-    private static final String[] PATHS = new String[]{
-            "/tika",
-            "/rmeta",
-            "/unpack",
-            "/meta",
-    };
-    private static final int UNPROCESSEABLE = 422;
-
-    @Override
-    protected void setUpResources(JAXRSServerFactoryBean sf) {
-        List<ResourceProvider> rCoreProviders = new ArrayList<ResourceProvider>();
-        rCoreProviders.add(new SingletonResourceProvider(new MetadataResource(tika)));
-        rCoreProviders.add(new SingletonResourceProvider(new RecursiveMetadataResource(tika)));
-        rCoreProviders.add(new SingletonResourceProvider(new DetectorResource(tika)));
-        rCoreProviders.add(new SingletonResourceProvider(new TikaResource(tika)));
-        rCoreProviders.add(new SingletonResourceProvider(new UnpackerResource(tika)));
-        sf.setResourceProviders(rCoreProviders);
-    }
-
-    @Override
-    protected void setUpProviders(JAXRSServerFactoryBean sf) {
-        List<Object> providers = new ArrayList<Object>();
-        providers.add(new TikaServerParseExceptionMapper(true));
-        providers.add(new JSONMessageBodyWriter());
-        providers.add(new CSVMessageBodyWriter());
-        providers.add(new XMPMessageBodyWriter());
-        providers.add(new TextMessageBodyWriter());
-        sf.setProviders(providers);
-    }
-
-    @Test
-    public void testEncrypted() throws Exception {
-        for (String path : PATHS) {
-            Response response = WebClient
-                    .create(endPoint + path)
-                    .accept("*/*")
-                    .header("Content-Disposition",
-                            "attachment; filename=" + TEST_PASSWORD_PROTECTED)
-                    .put(ClassLoader.getSystemResourceAsStream(TEST_PASSWORD_PROTECTED));
-            assertNotNull("null response: " + path, response);
-            assertEquals("unprocessable: " + path, UNPROCESSEABLE, response.getStatus());
-            String msg = getStringFromInputStream((InputStream) response
-                    .getEntity());
-            assertContains("org.apache.tika.exception.EncryptedDocumentException",
-                    msg);
-        }
-    }
-
-    @Test
-    public void testNullPointerOnTika() throws Exception {
-        for (String path : PATHS) {
-            Response response = WebClient
-                    .create(endPoint + path)
-                    .accept("*/*")
-                    .put(ClassLoader.getSystemResourceAsStream(TEST_NULL));
-            assertNotNull("null response: " + path, response);
-            assertEquals("unprocessable: " + path, UNPROCESSEABLE, response.getStatus());
-            String msg = getStringFromInputStream((InputStream) response
-                    .getEntity());
-            assertContains("Caused by: java.lang.NullPointerException: null pointer message",
-                    msg);
-        }
-    }
-
-    @Test
-    public void test415() throws Exception {
-        //no stack traces for 415
-        for (String path : PATHS) {
-            Response response = WebClient
-                    .create(endPoint + path)
-                    .type("blechdeblah/deblechdeblah")
-                    .accept("*/*")
-                    .header("Content-Disposition",
-                            "attachment; filename=null_pointer.evil")
-                    .put(ClassLoader.getSystemResourceAsStream(TEST_NULL));
-            assertNotNull("null response: " + path, response);
-            assertEquals("bad type: " + path, 415, response.getStatus());
-            String msg = getStringFromInputStream((InputStream) response
-                    .getEntity());
-            assertEquals("should be empty: " + path, "", msg);
-        }
-    }
-
-    //For now, make sure that non-complete document
-    //still returns BAD_REQUEST.  We may want to
-    //make MetadataResource return the same types of parse
-    //exceptions as the others...
-    @Test
-    public void testMeta() throws Exception {
-        InputStream stream = ClassLoader.getSystemResourceAsStream(TikaResourceTest.TEST_DOC);
-
-        Response response = WebClient.create(endPoint + "/meta" + "/Author").type("application/msword")
-                .accept(MediaType.TEXT_PLAIN).put(copy(stream, 8000));
-        Assert.assertEquals(Response.Status.BAD_REQUEST.getStatusCode(), response.getStatus());
-        String msg = getStringFromInputStream((InputStream) response.getEntity());
-        assertEquals("Failed to get metadata field Author", msg);
-    }
-}
+package org.apache.tika.server;
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ * <p/>
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * <p/>
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+
+import javax.ws.rs.core.MediaType;
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.ResourceProvider;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.server.resource.DetectorResource;
+import org.apache.tika.server.resource.MetadataResource;
+import org.apache.tika.server.resource.RecursiveMetadataResource;
+import org.apache.tika.server.resource.TikaResource;
+import org.apache.tika.server.resource.UnpackerResource;
+import org.apache.tika.server.writer.CSVMessageBodyWriter;
+import org.apache.tika.server.writer.JSONMessageBodyWriter;
+import org.apache.tika.server.writer.TextMessageBodyWriter;
+import org.apache.tika.server.writer.XMPMessageBodyWriter;
+import org.junit.Assert;
+import org.junit.Test;
+
+public class StackTraceTest extends CXFTestBase {
+    public static final String TEST_NULL = "mock/null_pointer.xml";
+    public static final String TEST_PASSWORD_PROTECTED = "password.xls";
+
+    private static final String[] PATHS = new String[]{
+            "/tika",
+            "/rmeta",
+            "/unpack",
+            "/meta",
+    };
+    private static final int UNPROCESSEABLE = 422;
+
+    @Override
+    protected void setUpResources(JAXRSServerFactoryBean sf) {
+        List<ResourceProvider> rCoreProviders = new ArrayList<ResourceProvider>();
+        rCoreProviders.add(new SingletonResourceProvider(new MetadataResource(tika)));
+        rCoreProviders.add(new SingletonResourceProvider(new RecursiveMetadataResource(tika)));
+        rCoreProviders.add(new SingletonResourceProvider(new DetectorResource(tika)));
+        rCoreProviders.add(new SingletonResourceProvider(new TikaResource(tika)));
+        rCoreProviders.add(new SingletonResourceProvider(new UnpackerResource(tika)));
+        sf.setResourceProviders(rCoreProviders);
+    }
+
+    @Override
+    protected void setUpProviders(JAXRSServerFactoryBean sf) {
+        List<Object> providers = new ArrayList<Object>();
+        providers.add(new TikaServerParseExceptionMapper(true));
+        providers.add(new JSONMessageBodyWriter());
+        providers.add(new CSVMessageBodyWriter());
+        providers.add(new XMPMessageBodyWriter());
+        providers.add(new TextMessageBodyWriter());
+        sf.setProviders(providers);
+    }
+
+    @Test
+    public void testEncrypted() throws Exception {
+        for (String path : PATHS) {
+            Response response = WebClient
+                    .create(endPoint + path)
+                    .accept("*/*")
+                    .header("Content-Disposition",
+                            "attachment; filename=" + TEST_PASSWORD_PROTECTED)
+                    .put(ClassLoader.getSystemResourceAsStream(TEST_PASSWORD_PROTECTED));
+            assertNotNull("null response: " + path, response);
+            assertEquals("unprocessable: " + path, UNPROCESSEABLE, response.getStatus());
+            String msg = getStringFromInputStream((InputStream) response
+                    .getEntity());
+            assertContains("org.apache.tika.exception.EncryptedDocumentException",
+                    msg);
+        }
+    }
+
+    @Test
+    public void testNullPointerOnTika() throws Exception {
+        for (String path : PATHS) {
+            Response response = WebClient
+                    .create(endPoint + path)
+                    .accept("*/*")
+                    .put(ClassLoader.getSystemResourceAsStream(TEST_NULL));
+            assertNotNull("null response: " + path, response);
+            assertEquals("unprocessable: " + path, UNPROCESSEABLE, response.getStatus());
+            String msg = getStringFromInputStream((InputStream) response
+                    .getEntity());
+            assertContains("Caused by: java.lang.NullPointerException: null pointer message",
+                    msg);
+        }
+    }
+
+    @Test
+    public void test415() throws Exception {
+        //no stack traces for 415
+        for (String path : PATHS) {
+            Response response = WebClient
+                    .create(endPoint + path)
+                    .type("blechdeblah/deblechdeblah")
+                    .accept("*/*")
+                    .header("Content-Disposition",
+                            "attachment; filename=null_pointer.evil")
+                    .put(ClassLoader.getSystemResourceAsStream(TEST_NULL));
+            assertNotNull("null response: " + path, response);
+            assertEquals("bad type: " + path, 415, response.getStatus());
+            String msg = getStringFromInputStream((InputStream) response
+                    .getEntity());
+            assertEquals("should be empty: " + path, "", msg);
+        }
+    }
+
+    //For now, make sure that non-complete document
+    //still returns BAD_REQUEST.  We may want to
+    //make MetadataResource return the same types of parse
+    //exceptions as the others...
+    @Test
+    public void testMeta() throws Exception {
+        InputStream stream = ClassLoader.getSystemResourceAsStream(TikaResourceTest.TEST_DOC);
+
+        Response response = WebClient.create(endPoint + "/meta" + "/Author").type("application/msword")
+                .accept(MediaType.TEXT_PLAIN).put(copy(stream, 8000));
+        Assert.assertEquals(Response.Status.BAD_REQUEST.getStatusCode(), response.getStatus());
+        String msg = getStringFromInputStream((InputStream) response.getEntity());
+        assertEquals("Failed to get metadata field Author", msg);
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/TikaDetectorsTest.java b/tika-server/src/test/java/org/apache/tika/server/TikaDetectorsTest.java
index 2228ab5f0..e77c17310 100644
--- a/tika-server/src/test/java/org/apache/tika/server/TikaDetectorsTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/TikaDetectorsTest.java
@@ -1,142 +1,142 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.Map;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.mime.MimeTypes;
-import org.apache.tika.parser.microsoft.POIFSContainerDetector;
-import org.apache.tika.parser.pkg.ZipContainerDetector;
-import org.apache.tika.server.resource.TikaDetectors;
-import org.eclipse.jetty.util.ajax.JSON;
-import org.gagravarr.tika.OggDetector;
-import org.junit.Test;
-
-public class TikaDetectorsTest extends CXFTestBase {
-    private static final String DETECTORS_PATH = "/detectors";
-
-    @Override
-    protected void setUpResources(JAXRSServerFactoryBean sf) {
-        sf.setResourceClasses(TikaDetectors.class);
-        sf.setResourceProvider(
-                TikaDetectors.class,
-                new SingletonResourceProvider(new TikaDetectors(tika))
-        );
-    }
-
-    @Override
-    protected void setUpProviders(JAXRSServerFactoryBean sf) {
-    }
-
-    @Test
-    public void testGetPlainText() throws Exception {
-        Response response = WebClient
-                .create(endPoint + DETECTORS_PATH)
-                .type("text/plain")
-                .accept("text/plain")
-                .get();
-
-        String text = getStringFromInputStream((InputStream) response.getEntity());
-        assertContains("org.apache.tika.detect.DefaultDetector (Composite Detector)", text);
-        assertContains(OggDetector.class.getName(), text);
-        assertContains(POIFSContainerDetector.class.getName(), text);
-        assertContains(ZipContainerDetector.class.getName(), text);
-        assertContains(MimeTypes.class.getName(), text);
-    }
-
-    @Test
-    public void testGetHTML() throws Exception {
-        Response response = WebClient
-                .create(endPoint + DETECTORS_PATH)
-                .type("text/html")
-                .accept("text/html")
-                .get();
-
-        String text = getStringFromInputStream((InputStream) response.getEntity());
-        assertContains("<h2>DefaultDetector</h2>", text);
-        assertContains("Composite", text);
-
-        assertContains("<h3>OggDetector", text);
-        assertContains("<h3>POIFSContainerDetector", text);
-        assertContains("<h3>MimeTypes", text);
-
-        assertContains(OggDetector.class.getName(), text);
-        assertContains(POIFSContainerDetector.class.getName(), text);
-        assertContains(ZipContainerDetector.class.getName(), text);
-        assertContains(MimeTypes.class.getName(), text);
-    }
-
-    @Test
-    @SuppressWarnings("unchecked")
-    public void testGetJSON() throws Exception {
-        Response response = WebClient
-                .create(endPoint + DETECTORS_PATH)
-                .type(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-                .accept(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-                .get();
-
-        String jsonStr = getStringFromInputStream((InputStream) response.getEntity());
-        Map<String, Map<String, Object>> json = (Map<String, Map<String, Object>>) JSON.parse(jsonStr);
-
-        // Should have a nested structure
-        assertTrue(json.containsKey("name"));
-        assertTrue(json.containsKey("composite"));
-        assertTrue(json.containsKey("children"));
-        assertEquals("org.apache.tika.detect.DefaultDetector", json.get("name"));
-        assertEquals(Boolean.TRUE, json.get("composite"));
-
-        // At least 4 child detectors, none of them composite
-        Object[] children = (Object[]) (Object) json.get("children");
-        assertTrue(children.length >= 4);
-        boolean hasOgg = false, hasPOIFS = false, hasZIP = false, hasMime = false;
-        for (Object o : children) {
-            Map<String, Object> d = (Map<String, Object>) o;
-            assertTrue(d.containsKey("name"));
-            assertTrue(d.containsKey("composite"));
-            assertEquals(Boolean.FALSE, d.get("composite"));
-            assertEquals(false, d.containsKey("children"));
-
-            String name = (String) d.get("name");
-            if (OggDetector.class.getName().equals(name)) {
-                hasOgg = true;
-            }
-            if (POIFSContainerDetector.class.getName().equals(name)) {
-                hasPOIFS = true;
-            }
-            if (ZipContainerDetector.class.getName().equals(name)) {
-                hasZIP = true;
-            }
-            if (MimeTypes.class.getName().equals(name)) {
-                hasMime = true;
-            }
-        }
-        assertTrue(hasOgg);
-        assertTrue(hasPOIFS);
-        assertTrue(hasZIP);
-        assertTrue(hasMime);
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.Map;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.mime.MimeTypes;
+import org.apache.tika.parser.microsoft.POIFSContainerDetector;
+import org.apache.tika.parser.pkg.ZipContainerDetector;
+import org.apache.tika.server.resource.TikaDetectors;
+import org.eclipse.jetty.util.ajax.JSON;
+import org.gagravarr.tika.OggDetector;
+import org.junit.Test;
+
+public class TikaDetectorsTest extends CXFTestBase {
+    private static final String DETECTORS_PATH = "/detectors";
+
+    @Override
+    protected void setUpResources(JAXRSServerFactoryBean sf) {
+        sf.setResourceClasses(TikaDetectors.class);
+        sf.setResourceProvider(
+                TikaDetectors.class,
+                new SingletonResourceProvider(new TikaDetectors(tika))
+        );
+    }
+
+    @Override
+    protected void setUpProviders(JAXRSServerFactoryBean sf) {
+    }
+
+    @Test
+    public void testGetPlainText() throws Exception {
+        Response response = WebClient
+                .create(endPoint + DETECTORS_PATH)
+                .type("text/plain")
+                .accept("text/plain")
+                .get();
+
+        String text = getStringFromInputStream((InputStream) response.getEntity());
+        assertContains("org.apache.tika.detect.DefaultDetector (Composite Detector)", text);
+        assertContains(OggDetector.class.getName(), text);
+        assertContains(POIFSContainerDetector.class.getName(), text);
+        assertContains(ZipContainerDetector.class.getName(), text);
+        assertContains(MimeTypes.class.getName(), text);
+    }
+
+    @Test
+    public void testGetHTML() throws Exception {
+        Response response = WebClient
+                .create(endPoint + DETECTORS_PATH)
+                .type("text/html")
+                .accept("text/html")
+                .get();
+
+        String text = getStringFromInputStream((InputStream) response.getEntity());
+        assertContains("<h2>DefaultDetector</h2>", text);
+        assertContains("Composite", text);
+
+        assertContains("<h3>OggDetector", text);
+        assertContains("<h3>POIFSContainerDetector", text);
+        assertContains("<h3>MimeTypes", text);
+
+        assertContains(OggDetector.class.getName(), text);
+        assertContains(POIFSContainerDetector.class.getName(), text);
+        assertContains(ZipContainerDetector.class.getName(), text);
+        assertContains(MimeTypes.class.getName(), text);
+    }
+
+    @Test
+    @SuppressWarnings("unchecked")
+    public void testGetJSON() throws Exception {
+        Response response = WebClient
+                .create(endPoint + DETECTORS_PATH)
+                .type(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+                .accept(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+                .get();
+
+        String jsonStr = getStringFromInputStream((InputStream) response.getEntity());
+        Map<String, Map<String, Object>> json = (Map<String, Map<String, Object>>) JSON.parse(jsonStr);
+
+        // Should have a nested structure
+        assertTrue(json.containsKey("name"));
+        assertTrue(json.containsKey("composite"));
+        assertTrue(json.containsKey("children"));
+        assertEquals("org.apache.tika.detect.DefaultDetector", json.get("name"));
+        assertEquals(Boolean.TRUE, json.get("composite"));
+
+        // At least 4 child detectors, none of them composite
+        Object[] children = (Object[]) (Object) json.get("children");
+        assertTrue(children.length >= 4);
+        boolean hasOgg = false, hasPOIFS = false, hasZIP = false, hasMime = false;
+        for (Object o : children) {
+            Map<String, Object> d = (Map<String, Object>) o;
+            assertTrue(d.containsKey("name"));
+            assertTrue(d.containsKey("composite"));
+            assertEquals(Boolean.FALSE, d.get("composite"));
+            assertEquals(false, d.containsKey("children"));
+
+            String name = (String) d.get("name");
+            if (OggDetector.class.getName().equals(name)) {
+                hasOgg = true;
+            }
+            if (POIFSContainerDetector.class.getName().equals(name)) {
+                hasPOIFS = true;
+            }
+            if (ZipContainerDetector.class.getName().equals(name)) {
+                hasZIP = true;
+            }
+            if (MimeTypes.class.getName().equals(name)) {
+                hasMime = true;
+            }
+        }
+        assertTrue(hasOgg);
+        assertTrue(hasPOIFS);
+        assertTrue(hasZIP);
+        assertTrue(hasMime);
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/TikaMimeTypesTest.java b/tika-server/src/test/java/org/apache/tika/server/TikaMimeTypesTest.java
index b0650b778..eb5a622d3 100644
--- a/tika-server/src/test/java/org/apache/tika/server/TikaMimeTypesTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/TikaMimeTypesTest.java
@@ -1,121 +1,121 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.Map;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.server.resource.TikaMimeTypes;
-import org.eclipse.jetty.util.ajax.JSON;
-import org.junit.Test;
-
-public class TikaMimeTypesTest extends CXFTestBase {
-    private static final String MIMETYPES_PATH = "/mime-types";
-
-    @Override
-    protected void setUpResources(JAXRSServerFactoryBean sf) {
-        sf.setResourceClasses(TikaMimeTypes.class);
-        sf.setResourceProvider(
-                TikaMimeTypes.class,
-                new SingletonResourceProvider(new TikaMimeTypes(tika))
-        );
-    }
-
-    @Override
-    protected void setUpProviders(JAXRSServerFactoryBean sf) {
-    }
-
-    @Test
-    public void testGetPlainText() throws Exception {
-        Response response = WebClient
-                .create(endPoint + MIMETYPES_PATH)
-                .type("text/plain")
-                .accept("text/plain")
-                .get();
-
-        String text = getStringFromInputStream((InputStream) response.getEntity());
-        assertContains("text/plain", text);
-        assertContains("application/xml", text);
-        assertContains("video/x-ogm", text);
-
-        assertContains("supertype: video/ogg", text);
-
-        assertContains("alias:     image/bmp", text);
-    }
-
-    @Test
-    public void testGetHTML() throws Exception {
-        Response response = WebClient
-                .create(endPoint + MIMETYPES_PATH)
-                .type("text/html")
-                .accept("text/html")
-                .get();
-
-        String text = getStringFromInputStream((InputStream) response.getEntity());
-        assertContains("text/plain", text);
-        assertContains("application/xml", text);
-        assertContains("video/x-ogm", text);
-
-        assertContains("<h2>text/plain", text);
-        assertContains("name=\"text/plain", text);
-
-        assertContains("Super Type: <a href=\"#video/ogg\">video/ogg", text);
-
-        assertContains("Alias: image/bmp", text);
-    }
-
-    @Test
-    @SuppressWarnings("unchecked")
-    public void testGetJSON() throws Exception {
-        Response response = WebClient
-                .create(endPoint + MIMETYPES_PATH)
-                .type(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-                .accept(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-                .get();
-
-        String jsonStr = getStringFromInputStream((InputStream) response.getEntity());
-        Map<String, Map<String, Object>> json = (Map<String, Map<String, Object>>) JSON.parse(jsonStr);
-
-        assertEquals(true, json.containsKey("text/plain"));
-        assertEquals(true, json.containsKey("application/xml"));
-        assertEquals(true, json.containsKey("video/x-ogm"));
-        assertEquals(true, json.containsKey("image/x-ms-bmp"));
-
-        Map<String, Object> bmp = json.get("image/x-ms-bmp");
-        assertEquals(true, bmp.containsKey("alias"));
-        Object[] aliases = (Object[]) bmp.get("alias");
-        assertEquals(1, aliases.length);
-        assertEquals("image/bmp", aliases[0]);
-
-        String whichParser = bmp.get("parser").toString();
-        assertTrue("Which parser", whichParser.equals("org.apache.tika.parser.ocr.TesseractOCRParser") ||
-                whichParser.equals("org.apache.tika.parser.image.ImageParser"));
-
-        Map<String, Object> ogm = json.get("video/x-ogm");
-        assertEquals("video/ogg", ogm.get("supertype"));
-        assertEquals("org.gagravarr.tika.OggParser", ogm.get("parser"));
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.Map;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.server.resource.TikaMimeTypes;
+import org.eclipse.jetty.util.ajax.JSON;
+import org.junit.Test;
+
+public class TikaMimeTypesTest extends CXFTestBase {
+    private static final String MIMETYPES_PATH = "/mime-types";
+
+    @Override
+    protected void setUpResources(JAXRSServerFactoryBean sf) {
+        sf.setResourceClasses(TikaMimeTypes.class);
+        sf.setResourceProvider(
+                TikaMimeTypes.class,
+                new SingletonResourceProvider(new TikaMimeTypes(tika))
+        );
+    }
+
+    @Override
+    protected void setUpProviders(JAXRSServerFactoryBean sf) {
+    }
+
+    @Test
+    public void testGetPlainText() throws Exception {
+        Response response = WebClient
+                .create(endPoint + MIMETYPES_PATH)
+                .type("text/plain")
+                .accept("text/plain")
+                .get();
+
+        String text = getStringFromInputStream((InputStream) response.getEntity());
+        assertContains("text/plain", text);
+        assertContains("application/xml", text);
+        assertContains("video/x-ogm", text);
+
+        assertContains("supertype: video/ogg", text);
+
+        assertContains("alias:     image/bmp", text);
+    }
+
+    @Test
+    public void testGetHTML() throws Exception {
+        Response response = WebClient
+                .create(endPoint + MIMETYPES_PATH)
+                .type("text/html")
+                .accept("text/html")
+                .get();
+
+        String text = getStringFromInputStream((InputStream) response.getEntity());
+        assertContains("text/plain", text);
+        assertContains("application/xml", text);
+        assertContains("video/x-ogm", text);
+
+        assertContains("<h2>text/plain", text);
+        assertContains("name=\"text/plain", text);
+
+        assertContains("Super Type: <a href=\"#video/ogg\">video/ogg", text);
+
+        assertContains("Alias: image/bmp", text);
+    }
+
+    @Test
+    @SuppressWarnings("unchecked")
+    public void testGetJSON() throws Exception {
+        Response response = WebClient
+                .create(endPoint + MIMETYPES_PATH)
+                .type(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+                .accept(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+                .get();
+
+        String jsonStr = getStringFromInputStream((InputStream) response.getEntity());
+        Map<String, Map<String, Object>> json = (Map<String, Map<String, Object>>) JSON.parse(jsonStr);
+
+        assertEquals(true, json.containsKey("text/plain"));
+        assertEquals(true, json.containsKey("application/xml"));
+        assertEquals(true, json.containsKey("video/x-ogm"));
+        assertEquals(true, json.containsKey("image/x-ms-bmp"));
+
+        Map<String, Object> bmp = json.get("image/x-ms-bmp");
+        assertEquals(true, bmp.containsKey("alias"));
+        Object[] aliases = (Object[]) bmp.get("alias");
+        assertEquals(1, aliases.length);
+        assertEquals("image/bmp", aliases[0]);
+
+        String whichParser = bmp.get("parser").toString();
+        assertTrue("Which parser", whichParser.equals("org.apache.tika.parser.ocr.TesseractOCRParser") ||
+                whichParser.equals("org.apache.tika.parser.image.ImageParser"));
+
+        Map<String, Object> ogm = json.get("video/x-ogm");
+        assertEquals("video/ogg", ogm.get("supertype"));
+        assertEquals("org.gagravarr.tika.OggParser", ogm.get("parser"));
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/TikaParsersTest.java b/tika-server/src/test/java/org/apache/tika/server/TikaParsersTest.java
index d612ffb2c..d8a319bf6 100644
--- a/tika-server/src/test/java/org/apache/tika/server/TikaParsersTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/TikaParsersTest.java
@@ -1,182 +1,182 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.Map;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.parser.microsoft.ooxml.OOXMLParser;
-import org.apache.tika.parser.pdf.PDFParser;
-import org.apache.tika.parser.pkg.PackageParser;
-import org.apache.tika.server.resource.TikaParsers;
-import org.eclipse.jetty.util.ajax.JSON;
-import org.gagravarr.tika.OpusParser;
-import org.junit.Test;
-
-public class TikaParsersTest extends CXFTestBase {
-    private static final String PARSERS_SUMMARY_PATH = "/parsers";
-    private static final String PARSERS_DETAILS_PATH = "/parsers/details";
-
-    @Override
-    protected void setUpResources(JAXRSServerFactoryBean sf) {
-        sf.setResourceClasses(TikaParsers.class);
-        sf.setResourceProvider(
-                TikaParsers.class,
-                new SingletonResourceProvider(new TikaParsers(tika))
-        );
-    }
-
-    @Override
-    protected void setUpProviders(JAXRSServerFactoryBean sf) {
-    }
-
-    protected String getPath(boolean withDetails) {
-        return withDetails ? PARSERS_DETAILS_PATH : PARSERS_SUMMARY_PATH;
-    }
-
-    @Test
-    public void testGetPlainText() throws Exception {
-        for (boolean details : new boolean[]{false, true}) {
-            Response response = WebClient
-                    .create(endPoint + getPath(details))
-                    .type("text/plain")
-                    .accept("text/plain")
-                    .get();
-
-            String text = getStringFromInputStream((InputStream) response.getEntity());
-            assertContains("org.apache.tika.parser.DefaultParser (Composite Parser)", text);
-            assertContains(OpusParser.class.getName(), text);
-            assertContains(PackageParser.class.getName(), text);
-            assertContains(OOXMLParser.class.getName(), text);
-
-            if (details) {
-                // Should have the mimetypes they handle
-                assertContains("text/plain", text);
-                assertContains("application/pdf", text);
-                assertContains("audio/ogg", text);
-            } else {
-                // Shouldn't do
-                assertNotFound("text/plain", text);
-                assertNotFound("application/pdf", text);
-                assertNotFound("audio/ogg", text);
-            }
-        }
-    }
-
-    @Test
-    public void testGetHTML() throws Exception {
-        for (boolean details : new boolean[]{false, true}) {
-            Response response = WebClient
-                    .create(endPoint + getPath(details))
-                    .type("text/html")
-                    .accept("text/html")
-                    .get();
-
-            String text = getStringFromInputStream((InputStream) response.getEntity());
-            assertContains("<h2>DefaultParser</h2>", text);
-            assertContains("Composite", text);
-
-            assertContains("<h3>OpusParser", text);
-            assertContains("<h3>PackageParser", text);
-            assertContains("<h3>OOXMLParser", text);
-
-            assertContains(OpusParser.class.getName(), text);
-            assertContains(PackageParser.class.getName(), text);
-            assertContains(OOXMLParser.class.getName(), text);
-
-            if (details) {
-                // Should have the mimetypes they handle
-                assertContains("<li>text/plain", text);
-                assertContains("<li>application/pdf", text);
-                assertContains("<li>audio/ogg", text);
-            } else {
-                // Shouldn't do
-                assertNotFound("text/plain", text);
-                assertNotFound("application/pdf", text);
-                assertNotFound("audio/ogg", text);
-            }
-        }
-    }
-
-    @Test
-    @SuppressWarnings("unchecked")
-    public void testGetJSON() throws Exception {
-        for (boolean details : new boolean[]{false, true}) {
-            Response response = WebClient
-                    .create(endPoint + getPath(details))
-                    .type(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-                    .accept(javax.ws.rs.core.MediaType.APPLICATION_JSON)
-                    .get();
-
-            String jsonStr = getStringFromInputStream((InputStream) response.getEntity());
-            Map<String, Map<String, Object>> json = (Map<String, Map<String, Object>>) JSON.parse(jsonStr);
-
-            // Should have a nested structure
-            assertEquals(true, json.containsKey("name"));
-            assertEquals(true, json.containsKey("composite"));
-            assertEquals(true, json.containsKey("children"));
-            assertEquals("org.apache.tika.parser.DefaultParser", json.get("name"));
-            assertEquals(Boolean.TRUE, json.get("composite"));
-
-            // At least 20 child parsers which aren't composite
-            Object[] children = (Object[]) (Object) json.get("children");
-            assertTrue(children.length >= 20);
-            boolean hasOpus = false, hasOOXML = false, hasPDF = false, hasZip = false;
-            int nonComposite = 0;
-            for (Object o : children) {
-                Map<String, Object> d = (Map<String, Object>) o;
-                assertEquals(true, d.containsKey("name"));
-                assertEquals(true, d.containsKey("composite"));
-                assertEquals(Boolean.FALSE, d.get("composite"));
-                assertEquals(false, d.containsKey("children"));
-
-                if (d.get("composite") == Boolean.FALSE) nonComposite++;
-
-                // Will only have mime types if requested
-                assertEquals(details, d.containsKey("supportedTypes"));
-
-                String name = (String) d.get("name");
-                if (OpusParser.class.getName().equals(name)) {
-                    hasOpus = true;
-                }
-                if (OOXMLParser.class.getName().equals(name)) {
-                    hasOOXML = true;
-                }
-                if (PDFParser.class.getName().equals(name)) {
-                    hasPDF = true;
-                }
-                if (PackageParser.class.getName().equals(name)) {
-                    hasZip = true;
-                }
-            }
-            assertEquals(true, hasOpus);
-            assertEquals(true, hasOOXML);
-            assertEquals(true, hasPDF);
-            assertEquals(true, hasZip);
-            assertTrue(nonComposite > 20);
-        }
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.Map;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.parser.microsoft.ooxml.OOXMLParser;
+import org.apache.tika.parser.pdf.PDFParser;
+import org.apache.tika.parser.pkg.PackageParser;
+import org.apache.tika.server.resource.TikaParsers;
+import org.eclipse.jetty.util.ajax.JSON;
+import org.gagravarr.tika.OpusParser;
+import org.junit.Test;
+
+public class TikaParsersTest extends CXFTestBase {
+    private static final String PARSERS_SUMMARY_PATH = "/parsers";
+    private static final String PARSERS_DETAILS_PATH = "/parsers/details";
+
+    @Override
+    protected void setUpResources(JAXRSServerFactoryBean sf) {
+        sf.setResourceClasses(TikaParsers.class);
+        sf.setResourceProvider(
+                TikaParsers.class,
+                new SingletonResourceProvider(new TikaParsers(tika))
+        );
+    }
+
+    @Override
+    protected void setUpProviders(JAXRSServerFactoryBean sf) {
+    }
+
+    protected String getPath(boolean withDetails) {
+        return withDetails ? PARSERS_DETAILS_PATH : PARSERS_SUMMARY_PATH;
+    }
+
+    @Test
+    public void testGetPlainText() throws Exception {
+        for (boolean details : new boolean[]{false, true}) {
+            Response response = WebClient
+                    .create(endPoint + getPath(details))
+                    .type("text/plain")
+                    .accept("text/plain")
+                    .get();
+
+            String text = getStringFromInputStream((InputStream) response.getEntity());
+            assertContains("org.apache.tika.parser.DefaultParser (Composite Parser)", text);
+            assertContains(OpusParser.class.getName(), text);
+            assertContains(PackageParser.class.getName(), text);
+            assertContains(OOXMLParser.class.getName(), text);
+
+            if (details) {
+                // Should have the mimetypes they handle
+                assertContains("text/plain", text);
+                assertContains("application/pdf", text);
+                assertContains("audio/ogg", text);
+            } else {
+                // Shouldn't do
+                assertNotFound("text/plain", text);
+                assertNotFound("application/pdf", text);
+                assertNotFound("audio/ogg", text);
+            }
+        }
+    }
+
+    @Test
+    public void testGetHTML() throws Exception {
+        for (boolean details : new boolean[]{false, true}) {
+            Response response = WebClient
+                    .create(endPoint + getPath(details))
+                    .type("text/html")
+                    .accept("text/html")
+                    .get();
+
+            String text = getStringFromInputStream((InputStream) response.getEntity());
+            assertContains("<h2>DefaultParser</h2>", text);
+            assertContains("Composite", text);
+
+            assertContains("<h3>OpusParser", text);
+            assertContains("<h3>PackageParser", text);
+            assertContains("<h3>OOXMLParser", text);
+
+            assertContains(OpusParser.class.getName(), text);
+            assertContains(PackageParser.class.getName(), text);
+            assertContains(OOXMLParser.class.getName(), text);
+
+            if (details) {
+                // Should have the mimetypes they handle
+                assertContains("<li>text/plain", text);
+                assertContains("<li>application/pdf", text);
+                assertContains("<li>audio/ogg", text);
+            } else {
+                // Shouldn't do
+                assertNotFound("text/plain", text);
+                assertNotFound("application/pdf", text);
+                assertNotFound("audio/ogg", text);
+            }
+        }
+    }
+
+    @Test
+    @SuppressWarnings("unchecked")
+    public void testGetJSON() throws Exception {
+        for (boolean details : new boolean[]{false, true}) {
+            Response response = WebClient
+                    .create(endPoint + getPath(details))
+                    .type(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+                    .accept(javax.ws.rs.core.MediaType.APPLICATION_JSON)
+                    .get();
+
+            String jsonStr = getStringFromInputStream((InputStream) response.getEntity());
+            Map<String, Map<String, Object>> json = (Map<String, Map<String, Object>>) JSON.parse(jsonStr);
+
+            // Should have a nested structure
+            assertEquals(true, json.containsKey("name"));
+            assertEquals(true, json.containsKey("composite"));
+            assertEquals(true, json.containsKey("children"));
+            assertEquals("org.apache.tika.parser.DefaultParser", json.get("name"));
+            assertEquals(Boolean.TRUE, json.get("composite"));
+
+            // At least 20 child parsers which aren't composite
+            Object[] children = (Object[]) (Object) json.get("children");
+            assertTrue(children.length >= 20);
+            boolean hasOpus = false, hasOOXML = false, hasPDF = false, hasZip = false;
+            int nonComposite = 0;
+            for (Object o : children) {
+                Map<String, Object> d = (Map<String, Object>) o;
+                assertEquals(true, d.containsKey("name"));
+                assertEquals(true, d.containsKey("composite"));
+                assertEquals(Boolean.FALSE, d.get("composite"));
+                assertEquals(false, d.containsKey("children"));
+
+                if (d.get("composite") == Boolean.FALSE) nonComposite++;
+
+                // Will only have mime types if requested
+                assertEquals(details, d.containsKey("supportedTypes"));
+
+                String name = (String) d.get("name");
+                if (OpusParser.class.getName().equals(name)) {
+                    hasOpus = true;
+                }
+                if (OOXMLParser.class.getName().equals(name)) {
+                    hasOOXML = true;
+                }
+                if (PDFParser.class.getName().equals(name)) {
+                    hasPDF = true;
+                }
+                if (PackageParser.class.getName().equals(name)) {
+                    hasZip = true;
+                }
+            }
+            assertEquals(true, hasOpus);
+            assertEquals(true, hasOOXML);
+            assertEquals(true, hasPDF);
+            assertEquals(true, hasZip);
+            assertTrue(nonComposite > 20);
+        }
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/TikaVersionTest.java b/tika-server/src/test/java/org/apache/tika/server/TikaVersionTest.java
index 64ea69186..256ebe4b5 100644
--- a/tika-server/src/test/java/org/apache/tika/server/TikaVersionTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/TikaVersionTest.java
@@ -1,60 +1,60 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import static org.junit.Assert.assertEquals;
-
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.Tika;
-import org.apache.tika.server.resource.TikaVersion;
-import org.junit.Test;
-
-public class TikaVersionTest extends CXFTestBase {
-    protected static final String VERSION_PATH = "/version";
-
-    @Override
-    protected void setUpResources(JAXRSServerFactoryBean sf) {
-        sf.setResourceClasses(TikaVersion.class);
-        sf.setResourceProvider(
-                TikaVersion.class,
-                new SingletonResourceProvider(new TikaVersion(tika))
-        );
-    }
-
-    @Override
-    protected void setUpProviders(JAXRSServerFactoryBean sf) {
-    }
-
-    @Test
-    public void testGetVersion() throws Exception {
-        Response response = WebClient
-                .create(endPoint + VERSION_PATH)
-                .type("text/plain")
-                .accept("text/plain")
-                .get();
-
-        assertEquals(new Tika().toString(),
-                getStringFromInputStream((InputStream) response.getEntity()));
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import static org.junit.Assert.assertEquals;
+
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.Tika;
+import org.apache.tika.server.resource.TikaVersion;
+import org.junit.Test;
+
+public class TikaVersionTest extends CXFTestBase {
+    protected static final String VERSION_PATH = "/version";
+
+    @Override
+    protected void setUpResources(JAXRSServerFactoryBean sf) {
+        sf.setResourceClasses(TikaVersion.class);
+        sf.setResourceProvider(
+                TikaVersion.class,
+                new SingletonResourceProvider(new TikaVersion(tika))
+        );
+    }
+
+    @Override
+    protected void setUpProviders(JAXRSServerFactoryBean sf) {
+    }
+
+    @Test
+    public void testGetVersion() throws Exception {
+        Response response = WebClient
+                .create(endPoint + VERSION_PATH)
+                .type("text/plain")
+                .accept("text/plain")
+                .get();
+
+        assertEquals(new Tika().toString(),
+                getStringFromInputStream((InputStream) response.getEntity()));
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/TikaWelcomeTest.java b/tika-server/src/test/java/org/apache/tika/server/TikaWelcomeTest.java
index eb9c7b264..0a0418567 100644
--- a/tika-server/src/test/java/org/apache/tika/server/TikaWelcomeTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/TikaWelcomeTest.java
@@ -1,112 +1,112 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.ResourceProvider;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.Tika;
-import org.apache.tika.server.resource.DetectorResource;
-import org.apache.tika.server.resource.MetadataResource;
-import org.apache.tika.server.resource.TikaVersion;
-import org.apache.tika.server.resource.TikaWelcome;
-import org.junit.Test;
-
-public class TikaWelcomeTest extends CXFTestBase {
-    protected static final String WELCOME_PATH = "/";
-    private static final String VERSION_PATH = TikaVersionTest.VERSION_PATH;
-    protected static final String PATH_RESOURCE = "/detect/stream"; // TIKA-1567
-    protected static final String PATH_RESOURCE_2 = "/meta/form"; //TIKA-1567
-
-    @Override
-    protected void setUpResources(JAXRSServerFactoryBean sf) {
-        List<ResourceProvider> rpsCore =
-	    new ArrayList<ResourceProvider>();
-	rpsCore.add(new SingletonResourceProvider(new TikaVersion(tika)));
-	rpsCore.add(new SingletonResourceProvider(new DetectorResource(tika)));
-	rpsCore.add(new SingletonResourceProvider(new MetadataResource(tika)));
-        List<ResourceProvider> all = new ArrayList<ResourceProvider>(rpsCore);
-        all.add(new SingletonResourceProvider(new TikaWelcome(tika, rpsCore)));
-        sf.setResourceProviders(all);
-    }
-
-    @Override
-    protected void setUpProviders(JAXRSServerFactoryBean sf) {
-    }
-
-    @Test
-    public void testGetHTMLWelcome() throws Exception {
-        String html  = WebClient
-                .create(endPoint + WELCOME_PATH)
-                .type("text/html")
-                .accept("text/html")
-                .get(String.class);
-
-
-        assertContains(new Tika().toString(), html);
-        assertContains("href=\"http", html);
-
-        // Check our details were found
-        assertContains("GET", html);
-        assertContains(WELCOME_PATH, html);
-        assertContains("text/plain", html);
-
-        // Check that the Tika Version details come through too
-        assertContains(VERSION_PATH, html);
-    }
-
-    @Test
-    public void testGetTextWelcome() throws Exception {
-        Response response = WebClient
-                .create(endPoint + WELCOME_PATH)
-                .type("text/plain")
-                .accept("text/plain")
-                .get();
-
-        String text = getStringFromInputStream((InputStream) response.getEntity());
-        assertContains(new Tika().toString(), text);
-
-        // Check our details were found
-        assertContains("GET " + WELCOME_PATH, text);
-        assertContains("=> text/plain", text);
-
-        // Check that the Tika Version details come through too
-        assertContains("GET " + VERSION_PATH, text);
-    }
-
-
-    @Test
-    public void testProperPathWelcome() throws Exception{
-         Response response = WebClient
-	     .create(endPoint + WELCOME_PATH)
-             .type("text/html")
-             .accept("text/html")
-             .get();
-
-         String html = getStringFromInputStream((InputStream) response.getEntity());
-         assertContains(PATH_RESOURCE, html);
-         assertContains(PATH_RESOURCE_2, html);
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.ResourceProvider;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.Tika;
+import org.apache.tika.server.resource.DetectorResource;
+import org.apache.tika.server.resource.MetadataResource;
+import org.apache.tika.server.resource.TikaVersion;
+import org.apache.tika.server.resource.TikaWelcome;
+import org.junit.Test;
+
+public class TikaWelcomeTest extends CXFTestBase {
+    protected static final String WELCOME_PATH = "/";
+    private static final String VERSION_PATH = TikaVersionTest.VERSION_PATH;
+    protected static final String PATH_RESOURCE = "/detect/stream"; // TIKA-1567
+    protected static final String PATH_RESOURCE_2 = "/meta/form"; //TIKA-1567
+
+    @Override
+    protected void setUpResources(JAXRSServerFactoryBean sf) {
+        List<ResourceProvider> rpsCore =
+	    new ArrayList<ResourceProvider>();
+	rpsCore.add(new SingletonResourceProvider(new TikaVersion(tika)));
+	rpsCore.add(new SingletonResourceProvider(new DetectorResource(tika)));
+	rpsCore.add(new SingletonResourceProvider(new MetadataResource(tika)));
+        List<ResourceProvider> all = new ArrayList<ResourceProvider>(rpsCore);
+        all.add(new SingletonResourceProvider(new TikaWelcome(tika, rpsCore)));
+        sf.setResourceProviders(all);
+    }
+
+    @Override
+    protected void setUpProviders(JAXRSServerFactoryBean sf) {
+    }
+
+    @Test
+    public void testGetHTMLWelcome() throws Exception {
+        String html  = WebClient
+                .create(endPoint + WELCOME_PATH)
+                .type("text/html")
+                .accept("text/html")
+                .get(String.class);
+
+
+        assertContains(new Tika().toString(), html);
+        assertContains("href=\"http", html);
+
+        // Check our details were found
+        assertContains("GET", html);
+        assertContains(WELCOME_PATH, html);
+        assertContains("text/plain", html);
+
+        // Check that the Tika Version details come through too
+        assertContains(VERSION_PATH, html);
+    }
+
+    @Test
+    public void testGetTextWelcome() throws Exception {
+        Response response = WebClient
+                .create(endPoint + WELCOME_PATH)
+                .type("text/plain")
+                .accept("text/plain")
+                .get();
+
+        String text = getStringFromInputStream((InputStream) response.getEntity());
+        assertContains(new Tika().toString(), text);
+
+        // Check our details were found
+        assertContains("GET " + WELCOME_PATH, text);
+        assertContains("=> text/plain", text);
+
+        // Check that the Tika Version details come through too
+        assertContains("GET " + VERSION_PATH, text);
+    }
+
+
+    @Test
+    public void testProperPathWelcome() throws Exception{
+         Response response = WebClient
+	     .create(endPoint + WELCOME_PATH)
+             .type("text/html")
+             .accept("text/html")
+             .get();
+
+         String html = getStringFromInputStream((InputStream) response.getEntity());
+         assertContains(PATH_RESOURCE, html);
+         assertContains(PATH_RESOURCE_2, html);
+    }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/TranslateResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/TranslateResourceTest.java
index 91dfab5ca..6e46852f3 100644
--- a/tika-server/src/test/java/org/apache/tika/server/TranslateResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/TranslateResourceTest.java
@@ -1,86 +1,86 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-
-import javax.ws.rs.core.Response;
-
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.client.WebClient;
-import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-import org.apache.tika.server.resource.TranslateResource;
-import org.apache.tika.server.writer.TarWriter;
-import org.apache.tika.server.writer.ZipWriter;
-import org.junit.Test;
-
-public class TranslateResourceTest extends CXFTestBase {
-
-	private static final String TRANSLATE_PATH = "/translate";
-	private static final String TRANSLATE_ALL_PATH = TRANSLATE_PATH + "/all";
-	private static final String TRANSLATE_TXT = "This won't translate";
-	private static final String LINGO_PATH = "/org.apache.tika.language.translate.Lingo24Translator";
-	private static final String SRCDEST = "/es/en";
-	private static final String DEST = "/en";
-
-	@Override
-	protected void setUpResources(JAXRSServerFactoryBean sf) {
-		sf.setResourceClasses(TranslateResource.class);
-		sf.setResourceProvider(TranslateResource.class,
-				new SingletonResourceProvider(new TranslateResource(tika)));
-
-	}
-
-	@Override
-	protected void setUpProviders(JAXRSServerFactoryBean sf) {
-		List<Object> providers = new ArrayList<Object>();
-		providers.add(new TarWriter());
-		providers.add(new ZipWriter());
-		providers.add(new TikaServerParseExceptionMapper(false));
-		sf.setProviders(providers);
-
-	}
-
-	@Test
-	public void testTranslateFull() throws Exception {
-		String url = endPoint + TRANSLATE_ALL_PATH + LINGO_PATH + SRCDEST;
-		Response response = WebClient.create(url).type("text/plain")
-				.accept("*/*").put(TRANSLATE_TXT);
-		assertNotNull(response);
-		String translated = getStringFromInputStream((InputStream) response
-				.getEntity());
-		assertEquals(TRANSLATE_TXT, translated);
-	}
-	
-	@Test
-	public void testTranslateAutoLang() throws Exception{
-		String url = endPoint + TRANSLATE_ALL_PATH + LINGO_PATH + DEST;
-		Response response = WebClient.create(url).type("text/plain")
-				.accept("*/*").put(TRANSLATE_TXT);
-		assertNotNull(response);
-		String translated = getStringFromInputStream((InputStream) response
-				.getEntity());
-		assertEquals(TRANSLATE_TXT, translated);		
-	}
-
-}
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+
+import javax.ws.rs.core.Response;
+
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.server.resource.TranslateResource;
+import org.apache.tika.server.writer.TarWriter;
+import org.apache.tika.server.writer.ZipWriter;
+import org.junit.Test;
+
+public class TranslateResourceTest extends CXFTestBase {
+
+	private static final String TRANSLATE_PATH = "/translate";
+	private static final String TRANSLATE_ALL_PATH = TRANSLATE_PATH + "/all";
+	private static final String TRANSLATE_TXT = "This won't translate";
+	private static final String LINGO_PATH = "/org.apache.tika.language.translate.Lingo24Translator";
+	private static final String SRCDEST = "/es/en";
+	private static final String DEST = "/en";
+
+	@Override
+	protected void setUpResources(JAXRSServerFactoryBean sf) {
+		sf.setResourceClasses(TranslateResource.class);
+		sf.setResourceProvider(TranslateResource.class,
+				new SingletonResourceProvider(new TranslateResource(tika)));
+
+	}
+
+	@Override
+	protected void setUpProviders(JAXRSServerFactoryBean sf) {
+		List<Object> providers = new ArrayList<Object>();
+		providers.add(new TarWriter());
+		providers.add(new ZipWriter());
+		providers.add(new TikaServerParseExceptionMapper(false));
+		sf.setProviders(providers);
+
+	}
+
+	@Test
+	public void testTranslateFull() throws Exception {
+		String url = endPoint + TRANSLATE_ALL_PATH + LINGO_PATH + SRCDEST;
+		Response response = WebClient.create(url).type("text/plain")
+				.accept("*/*").put(TRANSLATE_TXT);
+		assertNotNull(response);
+		String translated = getStringFromInputStream((InputStream) response
+				.getEntity());
+		assertEquals(TRANSLATE_TXT, translated);
+	}
+	
+	@Test
+	public void testTranslateAutoLang() throws Exception{
+		String url = endPoint + TRANSLATE_ALL_PATH + LINGO_PATH + DEST;
+		Response response = WebClient.create(url).type("text/plain")
+				.accept("*/*").put(TRANSLATE_TXT);
+		assertNotNull(response);
+		String translated = getStringFromInputStream((InputStream) response
+				.getEntity());
+		assertEquals(TRANSLATE_TXT, translated);		
+	}
+
+}
